{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e008c054",
   "metadata": {},
   "source": [
    "Step 1: Loading Data\n",
    "For this tutorial, we’ll use the dataset of papers published in NIPS conference. The NIPS conference (Neural Information Processing Systems) is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
    "\n",
    "Let’s start by looking at the content of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36121c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(\"./NIPS Papers.zip\", \"r\") as zip_ref:\n",
    "    # Extract the file to a temporary directory\n",
    "    zip_ref.extractall(\"temp\")\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "papers = pd.read_csv(\"temp/NIPS Papers/papers.csv\")\n",
    "\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba68ea4",
   "metadata": {},
   "source": [
    "Step 2: Data Cleaning\n",
    "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810b4545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>Simplified Rules and Theoretical Analysis for\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6024</th>\n",
       "      <td>Using hippocampal 'place cells' for\\nnavigatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>From Batch to Transductive Online Learning\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Information Bottleneck for\\nGaussian Variables...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>A Constructive RBF Network\\nfor Writer Adaptat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_text\n",
       "2389  Simplified Rules and Theoretical Analysis for\\...\n",
       "6024  Using hippocampal 'place cells' for\\nnavigatio...\n",
       "1932  From Batch to Transductive Online Learning\\n\\n...\n",
       "1603  Information Bottleneck for\\nGaussian Variables...\n",
       "282   A Constructive RBF Network\\nfor Writer Adaptat..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the columns\n",
    "papers = papers.drop(columns=['id', 'title', 'abstract', \n",
    "                              'event_type', 'pdf_name', 'year'], axis=1)\n",
    "\n",
    "# sample only 100 papers\n",
    "papers = papers.sample(100)\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19a8eb",
   "metadata": {},
   "source": [
    "Remove punctuation/lower casing\n",
    "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655015d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389    simplified rules and theoretical analysis for\\...\n",
       "6024    using hippocampal 'place cells' for\\nnavigatio...\n",
       "1932    from batch to transductive online learning\\n\\n...\n",
       "1603    information bottleneck for\\ngaussian variables...\n",
       "282     a constructive rbf network\\nfor writer adaptat...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8f11d",
   "metadata": {},
   "source": [
    "Tokenize words and further clean-up text\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a6affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simplified', 'rules', 'and', 'theoretical', 'analysis', 'for', 'information', 'bottleneck', 'optimization', 'and', 'pca', 'with', 'spiking', 'neurons', 'lars', 'buesing', 'wolfgang', 'maass', 'institute', 'for', 'theoretical', 'computer', 'science', 'graz', 'university', 'of', 'technology', 'graz', 'austria', 'larsmaass']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd729dee",
   "metadata": {},
   "source": [
    "Step 3: Phrase Modeling: Bigram and Trigram Models\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring. Some examples in our example are: 'back_bumper', 'oil_leakage', 'maryland_college_park' etc.\n",
    "\n",
    "Gensim's Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold.\n",
    "\n",
    "The higher the values of these param, the harder it is for words to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24bab02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5d38d",
   "metadata": {},
   "source": [
    "Remove Stopwords, Make Bigrams and Lemmatize\n",
    "The phrase models are ready. Let’s define the functions to remove the stopwords, make trigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28db68b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/damlasenturk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "175ddc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9792d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/damlasenturk/miniconda3/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0729028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simplify', 'rule', 'theoretical', 'analysis', 'information_bottleneck', 'optimization', 'pca', 'spiking_neuron', 'lar', 'buese', 'technology', 'abstract', 'show', 'suitable', 'assumption', 'primarily', 'linearization', 'simple', 'perspicuous', 'online', 'learning', 'rule', 'optimization', 'spiking_neuron', 'derive', 'rule', 'perform', 'common', 'benchmark', 'task']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6240f49",
   "metadata": {},
   "source": [
    "Step 4: Data transformation: Corpus and Dictionary\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c21dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 1), (3, 4), (4, 2), (5, 1), (6, 2), (7, 1), (8, 1), (9, 4), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 10), (18, 1), (19, 1), (20, 1), (21, 9), (22, 3), (23, 2), (24, 4), (25, 1), (26, 1), (27, 5), (28, 2), (29, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5b1fa",
   "metadata": {},
   "source": [
    "Step 5: Base Model\n",
    "We have everything required to train the base LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we'll use default for the base model).\n",
    "\n",
    "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
    "\n",
    "passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c95aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c52a4a",
   "metadata": {},
   "source": [
    "The above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
    "\n",
    "You can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ff2760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.025*\"model\" + 0.012*\"use\" + 0.011*\"network\" + 0.010*\"graph\" + 0.010*\"set\" '\n",
      "  '+ 0.008*\"learn\" + 0.007*\"give\" + 0.007*\"structure\" + 0.007*\"datum\" + '\n",
      "  '0.007*\"distribution\"'),\n",
      " (1,\n",
      "  '0.023*\"model\" + 0.010*\"influence\" + 0.010*\"use\" + 0.009*\"graph\" + '\n",
      "  '0.009*\"parameter\" + 0.009*\"function\" + 0.008*\"set\" + 0.008*\"result\" + '\n",
      "  '0.008*\"cluster\" + 0.008*\"time\"'),\n",
      " (2,\n",
      "  '0.009*\"method\" + 0.009*\"feature\" + 0.008*\"set\" + 0.008*\"training\" + '\n",
      "  '0.008*\"use\" + 0.007*\"figure\" + 0.007*\"system\" + 0.006*\"neural\" + '\n",
      "  '0.006*\"learn\" + 0.006*\"rate\"'),\n",
      " (3,\n",
      "  '0.011*\"network\" + 0.010*\"cluster\" + 0.010*\"game\" + 0.009*\"player\" + '\n",
      "  '0.008*\"noise\" + 0.008*\"point\" + 0.008*\"value\" + 0.008*\"set\" + 0.007*\"use\" + '\n",
      "  '0.006*\"learn\"'),\n",
      " (4,\n",
      "  '0.008*\"model\" + 0.008*\"use\" + 0.008*\"point\" + 0.008*\"datum\" + '\n",
      "  '0.007*\"result\" + 0.007*\"problem\" + 0.007*\"cluster\" + 0.007*\"order\" + '\n",
      "  '0.006*\"error\" + 0.006*\"number\"'),\n",
      " (5,\n",
      "  '0.010*\"use\" + 0.010*\"problem\" + 0.010*\"function\" + 0.009*\"example\" + '\n",
      "  '0.009*\"learn\" + 0.008*\"set\" + 0.008*\"model\" + 0.008*\"method\" + '\n",
      "  '0.007*\"optimal\" + 0.006*\"solution\"'),\n",
      " (6,\n",
      "  '0.019*\"graph\" + 0.013*\"network\" + 0.013*\"time\" + 0.013*\"number\" + '\n",
      "  '0.012*\"set\" + 0.012*\"learn\" + 0.011*\"matrix\" + 0.010*\"edge\" + '\n",
      "  '0.009*\"bayesian\" + 0.008*\"kernel\"'),\n",
      " (7,\n",
      "  '0.011*\"model\" + 0.010*\"sample\" + 0.009*\"set\" + 0.009*\"use\" + '\n",
      "  '0.009*\"distribution\" + 0.007*\"network\" + 0.007*\"function\" + 0.006*\"learn\" + '\n",
      "  '0.006*\"parameter\" + 0.005*\"experiment\"'),\n",
      " (8,\n",
      "  '0.010*\"function\" + 0.007*\"input\" + 0.007*\"weight\" + 0.007*\"result\" + '\n",
      "  '0.006*\"set\" + 0.006*\"object\" + 0.006*\"use\" + 0.006*\"show\" + 0.006*\"neuron\" '\n",
      "  '+ 0.006*\"cell\"'),\n",
      " (9,\n",
      "  '0.014*\"model\" + 0.014*\"learn\" + 0.010*\"task\" + 0.010*\"use\" + 0.009*\"set\" + '\n",
      "  '0.009*\"method\" + 0.006*\"input\" + 0.006*\"datum\" + 0.006*\"sample\" + '\n",
      "  '0.006*\"distribution\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f8420",
   "metadata": {},
   "source": [
    "Compute Model Perplexity and Coherence Score\n",
    "Let's calculate the baseline coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3ba2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.2715528592528609\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ba13b",
   "metadata": {},
   "source": [
    "Step 6: Hyperparameter tuning¶\n",
    "First, let's differentiate between model hyperparameters and model parameters :\n",
    "\n",
    "Model hyperparameters can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
    "\n",
    "Model parameters can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
    "\n",
    "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters:\n",
    "\n",
    "Number of Topics (K)\n",
    "Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "Dirichlet hyperparameter beta: Word-Topic Density\n",
    "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use C_v as our choice of metric for performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "309e04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b52f6d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|██▋                                     | 36/540 [17:13<4:01:11, 28.71s/it]\u001b[A\n",
      "\n",
      "  0%|                                         | 1/540 [00:12<1:54:18, 12.73s/it]\u001b[A\n",
      "  0%|▏                                        | 2/540 [00:24<1:46:35, 11.89s/it]\u001b[A\n",
      "  1%|▏                                        | 3/540 [00:35<1:46:34, 11.91s/it]\u001b[A\n",
      "  1%|▎                                        | 4/540 [00:47<1:45:24, 11.80s/it]\u001b[A\n",
      "  1%|▍                                        | 5/540 [00:59<1:44:16, 11.69s/it]\u001b[A\n",
      "  1%|▍                                        | 6/540 [01:10<1:43:37, 11.64s/it]\u001b[A\n",
      "  1%|▌                                        | 7/540 [01:22<1:44:38, 11.78s/it]\u001b[A\n",
      "  1%|▌                                        | 8/540 [01:34<1:44:11, 11.75s/it]\u001b[A\n",
      "  2%|▋                                        | 9/540 [01:46<1:43:54, 11.74s/it]\u001b[A\n",
      "  2%|▋                                       | 10/540 [01:57<1:43:03, 11.67s/it]\u001b[A\n",
      "  2%|▊                                       | 11/540 [02:09<1:42:48, 11.66s/it]\u001b[A\n",
      "  2%|▉                                       | 12/540 [02:20<1:42:07, 11.60s/it]\u001b[A\n",
      "  2%|▉                                       | 13/540 [02:31<1:40:52, 11.48s/it]\u001b[A\n",
      "  3%|█                                       | 14/540 [02:43<1:40:22, 11.45s/it]\u001b[A\n",
      "  3%|█                                       | 15/540 [02:54<1:39:56, 11.42s/it]\u001b[A\n",
      "  3%|█▏                                      | 16/540 [03:06<1:40:44, 11.53s/it]\u001b[A\n",
      "  3%|█▎                                      | 17/540 [03:18<1:41:13, 11.61s/it]\u001b[A\n",
      "  3%|█▎                                      | 18/540 [03:30<1:43:18, 11.87s/it]\u001b[A\n",
      "  4%|█▍                                      | 19/540 [03:42<1:42:06, 11.76s/it]\u001b[A\n",
      "  4%|█▍                                      | 20/540 [03:53<1:41:49, 11.75s/it]\u001b[A\n",
      "  4%|█▌                                      | 21/540 [04:05<1:41:07, 11.69s/it]\u001b[A\n",
      "  4%|█▋                                      | 22/540 [04:16<1:39:43, 11.55s/it]\u001b[A\n",
      "  4%|█▋                                      | 23/540 [04:28<1:38:59, 11.49s/it]\u001b[A\n",
      "  4%|█▊                                      | 24/540 [04:39<1:38:14, 11.42s/it]\u001b[A\n",
      "  5%|█▊                                      | 25/540 [04:51<1:39:25, 11.58s/it]\u001b[A\n",
      "  5%|█▉                                      | 26/540 [05:03<1:39:33, 11.62s/it]\u001b[A\n",
      "  5%|██                                      | 27/540 [05:14<1:40:02, 11.70s/it]\u001b[A\n",
      "  5%|██                                      | 28/540 [05:28<1:44:50, 12.29s/it]\u001b[A\n",
      "  5%|██▏                                     | 29/540 [05:40<1:44:43, 12.30s/it]\u001b[A\n",
      "  6%|██▏                                     | 30/540 [05:53<1:45:19, 12.39s/it]\u001b[A\n",
      "  6%|██▎                                     | 31/540 [06:05<1:44:05, 12.27s/it]\u001b[A\n",
      "  6%|██▎                                     | 32/540 [06:16<1:41:08, 11.95s/it]\u001b[A\n",
      "  6%|██▍                                     | 33/540 [06:28<1:40:03, 11.84s/it]\u001b[A\n",
      "  6%|██▌                                     | 34/540 [06:39<1:38:25, 11.67s/it]\u001b[A\n",
      "  6%|██▌                                     | 35/540 [06:50<1:36:45, 11.50s/it]\u001b[A\n",
      "  7%|██▋                                     | 36/540 [07:01<1:35:46, 11.40s/it]\u001b[A\n",
      "  7%|██▋                                     | 37/540 [07:12<1:34:57, 11.33s/it]\u001b[A\n",
      "  7%|██▊                                     | 38/540 [07:24<1:35:44, 11.44s/it]\u001b[A\n",
      "  7%|██▉                                     | 39/540 [07:36<1:36:50, 11.60s/it]\u001b[A\n",
      "  7%|██▉                                     | 40/540 [07:47<1:35:36, 11.47s/it]\u001b[A\n",
      "  8%|███                                     | 41/540 [07:59<1:34:54, 11.41s/it]\u001b[A\n",
      "  8%|███                                     | 42/540 [08:11<1:36:38, 11.64s/it]\u001b[A\n",
      "  8%|███▏                                    | 43/540 [08:22<1:36:04, 11.60s/it]\u001b[A\n",
      "  8%|███▎                                    | 44/540 [08:34<1:35:09, 11.51s/it]\u001b[A\n",
      "  8%|███▎                                    | 45/540 [08:45<1:34:03, 11.40s/it]\u001b[A\n",
      "  9%|███▍                                    | 46/540 [08:56<1:33:07, 11.31s/it]\u001b[A\n",
      "  9%|███▍                                    | 47/540 [09:07<1:33:30, 11.38s/it]\u001b[A\n",
      "  9%|███▌                                    | 48/540 [09:19<1:33:13, 11.37s/it]\u001b[A\n",
      "  9%|███▋                                    | 49/540 [09:30<1:33:12, 11.39s/it]\u001b[A\n",
      "  9%|███▋                                    | 50/540 [09:42<1:33:40, 11.47s/it]\u001b[A\n",
      "  9%|███▊                                    | 51/540 [09:53<1:33:54, 11.52s/it]\u001b[A\n",
      " 10%|███▊                                    | 52/540 [10:05<1:33:25, 11.49s/it]\u001b[A\n",
      " 10%|███▉                                    | 53/540 [10:16<1:32:56, 11.45s/it]\u001b[A\n",
      " 10%|████                                    | 54/540 [10:27<1:32:07, 11.37s/it]\u001b[A\n",
      " 10%|████                                    | 55/540 [10:38<1:30:58, 11.25s/it]\u001b[A\n",
      " 10%|████▏                                   | 56/540 [10:50<1:31:36, 11.36s/it]\u001b[A\n",
      " 11%|████▏                                   | 57/540 [11:01<1:31:29, 11.37s/it]\u001b[A\n",
      " 11%|████▎                                   | 58/540 [11:13<1:31:04, 11.34s/it]\u001b[A\n",
      " 11%|████▎                                   | 59/540 [11:24<1:30:52, 11.34s/it]\u001b[A\n",
      " 11%|████▍                                   | 60/540 [11:36<1:32:21, 11.54s/it]\u001b[A\n",
      " 11%|████▌                                   | 61/540 [11:48<1:32:18, 11.56s/it]\u001b[A\n",
      " 11%|████▌                                   | 62/540 [11:59<1:32:00, 11.55s/it]\u001b[A\n",
      " 12%|████▋                                   | 63/540 [12:11<1:31:29, 11.51s/it]\u001b[A\n",
      " 12%|████▋                                   | 64/540 [12:22<1:31:42, 11.56s/it]\u001b[A\n",
      " 12%|████▊                                   | 65/540 [12:34<1:31:12, 11.52s/it]\u001b[A\n",
      " 12%|████▉                                   | 66/540 [12:45<1:30:36, 11.47s/it]\u001b[A\n",
      " 12%|████▉                                   | 67/540 [12:56<1:29:50, 11.40s/it]\u001b[A\n",
      " 13%|█████                                   | 68/540 [13:08<1:29:29, 11.38s/it]\u001b[A\n",
      " 13%|█████                                   | 69/540 [13:19<1:30:10, 11.49s/it]\u001b[A\n",
      " 13%|█████▏                                  | 70/540 [13:31<1:30:17, 11.53s/it]\u001b[A\n",
      " 13%|█████▎                                  | 71/540 [13:43<1:31:04, 11.65s/it]\u001b[A\n",
      " 13%|█████▎                                  | 72/540 [13:55<1:30:55, 11.66s/it]\u001b[A\n",
      " 14%|█████▍                                  | 73/540 [14:06<1:30:46, 11.66s/it]\u001b[A\n",
      " 14%|█████▍                                  | 74/540 [14:18<1:30:05, 11.60s/it]\u001b[A\n",
      " 14%|█████▌                                  | 75/540 [14:29<1:29:40, 11.57s/it]\u001b[A\n",
      " 14%|█████▋                                  | 76/540 [14:41<1:29:21, 11.56s/it]\u001b[A\n",
      " 14%|█████▋                                  | 77/540 [14:52<1:28:50, 11.51s/it]\u001b[A\n",
      " 14%|█████▊                                  | 78/540 [15:04<1:28:29, 11.49s/it]\u001b[A\n",
      " 15%|█████▊                                  | 79/540 [15:15<1:28:07, 11.47s/it]\u001b[A\n",
      " 15%|█████▉                                  | 80/540 [15:27<1:28:26, 11.53s/it]\u001b[A\n",
      " 15%|██████                                  | 81/540 [15:38<1:28:11, 11.53s/it]\u001b[A\n",
      " 15%|██████                                  | 82/540 [15:51<1:30:07, 11.81s/it]\u001b[A\n",
      " 15%|██████▏                                 | 83/540 [16:02<1:29:39, 11.77s/it]\u001b[A\n",
      " 16%|██████▏                                 | 84/540 [16:14<1:28:31, 11.65s/it]\u001b[A\n",
      " 16%|██████▎                                 | 85/540 [16:25<1:27:43, 11.57s/it]\u001b[A\n",
      " 16%|██████▎                                 | 86/540 [16:37<1:27:39, 11.59s/it]\u001b[A\n",
      " 16%|██████▍                                 | 87/540 [16:48<1:27:20, 11.57s/it]\u001b[A\n",
      " 16%|██████▌                                 | 88/540 [17:00<1:26:54, 11.54s/it]\u001b[A\n",
      " 16%|██████▌                                 | 89/540 [17:11<1:26:10, 11.46s/it]\u001b[A\n",
      " 17%|██████▋                                 | 90/540 [17:22<1:25:52, 11.45s/it]\u001b[A\n",
      " 17%|██████▋                                 | 91/540 [17:34<1:26:47, 11.60s/it]\u001b[A\n",
      " 17%|██████▊                                 | 92/540 [17:47<1:27:56, 11.78s/it]\u001b[A\n",
      " 17%|██████▉                                 | 93/540 [17:58<1:27:40, 11.77s/it]\u001b[A\n",
      " 17%|██████▉                                 | 94/540 [18:10<1:27:11, 11.73s/it]\u001b[A\n",
      " 18%|███████                                 | 95/540 [18:22<1:27:48, 11.84s/it]\u001b[A\n",
      " 18%|███████                                 | 96/540 [18:34<1:27:07, 11.77s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                | 97/540 [18:45<1:26:35, 11.73s/it]\u001b[A\n",
      " 18%|███████▎                                | 98/540 [18:57<1:26:24, 11.73s/it]\u001b[A\n",
      " 18%|███████▎                                | 99/540 [19:09<1:26:41, 11.79s/it]\u001b[A\n",
      " 19%|███████▏                               | 100/540 [19:21<1:26:04, 11.74s/it]\u001b[A\n",
      " 19%|███████▎                               | 101/540 [19:32<1:25:47, 11.73s/it]\u001b[A\n",
      " 19%|███████▎                               | 102/540 [19:44<1:25:11, 11.67s/it]\u001b[A\n",
      " 19%|███████▍                               | 103/540 [19:56<1:27:09, 11.97s/it]\u001b[A\n",
      " 19%|███████▌                               | 104/540 [20:08<1:25:56, 11.83s/it]\u001b[A\n",
      " 19%|███████▌                               | 105/540 [20:19<1:24:44, 11.69s/it]\u001b[A\n",
      " 20%|███████▋                               | 106/540 [20:31<1:24:21, 11.66s/it]\u001b[A\n",
      " 20%|███████▋                               | 107/540 [20:42<1:23:45, 11.61s/it]\u001b[A\n",
      " 20%|███████▊                               | 108/540 [20:54<1:24:28, 11.73s/it]\u001b[A\n",
      " 20%|███████▊                               | 109/540 [21:06<1:24:13, 11.73s/it]\u001b[A\n",
      " 20%|███████▉                               | 110/540 [21:18<1:24:24, 11.78s/it]\u001b[A\n",
      " 21%|████████                               | 111/540 [21:29<1:23:15, 11.64s/it]\u001b[A\n",
      " 21%|████████                               | 112/540 [21:41<1:23:12, 11.67s/it]\u001b[A\n",
      " 21%|████████▏                              | 113/540 [21:53<1:23:46, 11.77s/it]\u001b[A\n",
      " 21%|████████▏                              | 114/540 [22:05<1:23:18, 11.73s/it]\u001b[A\n",
      " 21%|████████▎                              | 115/540 [22:16<1:22:22, 11.63s/it]\u001b[A\n",
      " 21%|████████▍                              | 116/540 [22:28<1:22:49, 11.72s/it]\u001b[A\n",
      " 22%|████████▍                              | 117/540 [22:40<1:22:23, 11.69s/it]\u001b[A\n",
      " 22%|████████▌                              | 118/540 [22:51<1:21:29, 11.59s/it]\u001b[A\n",
      " 22%|████████▌                              | 119/540 [23:03<1:21:08, 11.56s/it]\u001b[A\n",
      " 22%|████████▋                              | 120/540 [23:14<1:20:55, 11.56s/it]\u001b[A\n",
      " 22%|████████▋                              | 121/540 [23:26<1:21:40, 11.69s/it]\u001b[A\n",
      " 23%|████████▊                              | 122/540 [23:38<1:21:33, 11.71s/it]\u001b[A\n",
      " 23%|████████▉                              | 123/540 [23:50<1:21:29, 11.73s/it]\u001b[A\n",
      " 23%|████████▉                              | 124/540 [24:01<1:21:16, 11.72s/it]\u001b[A\n",
      " 23%|█████████                              | 125/540 [24:13<1:21:16, 11.75s/it]\u001b[A\n",
      " 23%|█████████                              | 126/540 [24:25<1:20:43, 11.70s/it]\u001b[A\n",
      " 24%|█████████▏                             | 127/540 [24:36<1:20:30, 11.70s/it]\u001b[A\n",
      " 24%|█████████▏                             | 128/540 [24:48<1:20:26, 11.71s/it]\u001b[A\n",
      " 24%|█████████▎                             | 129/540 [25:00<1:20:17, 11.72s/it]\u001b[A\n",
      " 24%|█████████▍                             | 130/540 [25:12<1:20:00, 11.71s/it]\u001b[A\n",
      " 24%|█████████▍                             | 131/540 [25:23<1:19:55, 11.72s/it]\u001b[A\n",
      " 24%|█████████▌                             | 132/540 [25:35<1:20:14, 11.80s/it]\u001b[A\n",
      " 25%|█████████▌                             | 133/540 [25:47<1:19:46, 11.76s/it]\u001b[A\n",
      " 25%|█████████▋                             | 134/540 [25:59<1:20:10, 11.85s/it]\u001b[A\n",
      " 25%|█████████▊                             | 135/540 [26:11<1:19:57, 11.85s/it]\u001b[A\n",
      " 25%|█████████▊                             | 136/540 [26:23<1:20:04, 11.89s/it]\u001b[A\n",
      " 25%|█████████▉                             | 137/540 [26:35<1:19:48, 11.88s/it]\u001b[A\n",
      " 26%|█████████▉                             | 138/540 [26:47<1:19:45, 11.91s/it]\u001b[A\n",
      " 26%|██████████                             | 139/540 [26:58<1:18:51, 11.80s/it]\u001b[A\n",
      " 26%|██████████                             | 140/540 [27:10<1:18:30, 11.78s/it]\u001b[A\n",
      " 26%|██████████▏                            | 141/540 [27:22<1:18:03, 11.74s/it]\u001b[A\n",
      " 26%|██████████▎                            | 142/540 [27:34<1:18:21, 11.81s/it]\u001b[A\n",
      " 26%|██████████▎                            | 143/540 [27:46<1:18:43, 11.90s/it]\u001b[A\n",
      " 27%|██████████▍                            | 144/540 [27:58<1:18:47, 11.94s/it]\u001b[A\n",
      " 27%|██████████▍                            | 145/540 [28:10<1:18:22, 11.90s/it]\u001b[A\n",
      " 27%|██████████▌                            | 146/540 [28:21<1:17:46, 11.84s/it]\u001b[A\n",
      " 27%|██████████▌                            | 147/540 [28:33<1:17:29, 11.83s/it]\u001b[A\n",
      " 27%|██████████▋                            | 148/540 [28:45<1:17:16, 11.83s/it]\u001b[A\n",
      " 28%|██████████▊                            | 149/540 [28:56<1:16:42, 11.77s/it]\u001b[A\n",
      " 28%|██████████▊                            | 150/540 [29:08<1:16:13, 11.73s/it]\u001b[A\n",
      " 28%|██████████▉                            | 151/540 [29:20<1:16:44, 11.84s/it]\u001b[A\n",
      " 28%|██████████▉                            | 152/540 [29:32<1:16:34, 11.84s/it]\u001b[A\n",
      " 28%|███████████                            | 153/540 [29:44<1:16:09, 11.81s/it]\u001b[A\n",
      " 29%|███████████                            | 154/540 [29:55<1:15:45, 11.77s/it]\u001b[A\n",
      " 29%|███████████▏                           | 155/540 [30:08<1:16:51, 11.98s/it]\u001b[A\n",
      " 29%|███████████▎                           | 156/540 [30:20<1:16:31, 11.96s/it]\u001b[A\n",
      " 29%|███████████▎                           | 157/540 [30:32<1:15:59, 11.90s/it]\u001b[A\n",
      " 29%|███████████▍                           | 158/540 [30:43<1:15:34, 11.87s/it]\u001b[A\n",
      " 29%|███████████▍                           | 159/540 [30:56<1:15:57, 11.96s/it]\u001b[A\n",
      " 30%|███████████▌                           | 160/540 [31:08<1:16:01, 12.00s/it]\u001b[A\n",
      " 30%|███████████▋                           | 161/540 [31:20<1:15:36, 11.97s/it]\u001b[A\n",
      " 30%|███████████▋                           | 162/540 [31:31<1:15:12, 11.94s/it]\u001b[A\n",
      " 30%|███████████▊                           | 163/540 [31:43<1:15:07, 11.96s/it]\u001b[A\n",
      " 30%|███████████▊                           | 164/540 [31:55<1:14:28, 11.89s/it]\u001b[A\n",
      " 31%|███████████▉                           | 165/540 [32:07<1:14:09, 11.86s/it]\u001b[A\n",
      " 31%|███████████▉                           | 166/540 [32:19<1:14:04, 11.88s/it]\u001b[A\n",
      " 31%|████████████                           | 167/540 [32:31<1:13:46, 11.87s/it]\u001b[A\n",
      " 31%|████████████▏                          | 168/540 [32:43<1:14:13, 11.97s/it]\u001b[A\n",
      " 31%|████████████▏                          | 169/540 [32:55<1:13:55, 11.95s/it]\u001b[A\n",
      " 31%|████████████▎                          | 170/540 [33:07<1:13:24, 11.90s/it]\u001b[A\n",
      " 32%|████████████▎                          | 171/540 [33:19<1:13:13, 11.91s/it]\u001b[A\n",
      " 32%|████████████▍                          | 172/540 [33:31<1:13:05, 11.92s/it]\u001b[A\n",
      " 32%|████████████▍                          | 173/540 [33:42<1:12:20, 11.83s/it]\u001b[A\n",
      " 32%|████████████▌                          | 174/540 [33:54<1:11:59, 11.80s/it]\u001b[A\n",
      " 32%|████████████▋                          | 175/540 [34:06<1:12:48, 11.97s/it]\u001b[A\n",
      " 33%|████████████▋                          | 176/540 [34:19<1:13:17, 12.08s/it]\u001b[A\n",
      " 33%|████████████▊                          | 177/540 [34:31<1:12:51, 12.04s/it]\u001b[A\n",
      " 33%|████████████▊                          | 178/540 [34:42<1:12:26, 12.01s/it]\u001b[A\n",
      " 33%|████████████▉                          | 179/540 [34:54<1:12:00, 11.97s/it]\u001b[A\n",
      " 33%|█████████████                          | 180/540 [35:06<1:11:03, 11.84s/it]\u001b[A\n",
      " 34%|█████████████                          | 181/540 [35:18<1:10:56, 11.86s/it]\u001b[A\n",
      " 34%|█████████████▏                         | 182/540 [35:30<1:11:04, 11.91s/it]\u001b[A\n",
      " 34%|█████████████▏                         | 183/540 [35:42<1:11:10, 11.96s/it]\u001b[A\n",
      " 34%|█████████████▎                         | 184/540 [35:54<1:10:59, 11.96s/it]\u001b[A\n",
      " 34%|█████████████▎                         | 185/540 [36:06<1:11:19, 12.06s/it]\u001b[A\n",
      " 34%|█████████████▍                         | 186/540 [36:18<1:11:26, 12.11s/it]\u001b[A\n",
      " 35%|█████████████▌                         | 187/540 [36:30<1:10:48, 12.03s/it]\u001b[A\n",
      " 35%|█████████████▌                         | 188/540 [36:43<1:11:12, 12.14s/it]\u001b[A\n",
      " 35%|█████████████▋                         | 189/540 [36:55<1:11:47, 12.27s/it]\u001b[A\n",
      " 35%|█████████████▋                         | 190/540 [37:07<1:11:02, 12.18s/it]\u001b[A\n",
      " 35%|█████████████▊                         | 191/540 [37:19<1:10:39, 12.15s/it]\u001b[A\n",
      " 36%|█████████████▊                         | 192/540 [37:31<1:10:06, 12.09s/it]\u001b[A\n",
      " 36%|█████████████▉                         | 193/540 [37:44<1:11:35, 12.38s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████                         | 194/540 [37:57<1:12:37, 12.59s/it]\u001b[A\n",
      " 36%|██████████████                         | 195/540 [38:11<1:14:38, 12.98s/it]\u001b[A\n",
      " 36%|██████████████▏                        | 196/540 [38:25<1:15:48, 13.22s/it]\u001b[A\n",
      " 36%|██████████████▏                        | 197/540 [38:38<1:15:26, 13.20s/it]\u001b[A\n",
      " 37%|██████████████▎                        | 198/540 [38:51<1:14:47, 13.12s/it]\u001b[A\n",
      " 37%|██████████████▎                        | 199/540 [39:04<1:14:08, 13.05s/it]\u001b[A\n",
      " 37%|██████████████▍                        | 200/540 [39:17<1:13:25, 12.96s/it]\u001b[A\n",
      " 37%|██████████████▌                        | 201/540 [39:30<1:13:11, 12.96s/it]\u001b[A\n",
      " 37%|██████████████▌                        | 202/540 [39:42<1:12:25, 12.86s/it]\u001b[A\n",
      " 38%|██████████████▋                        | 203/540 [39:55<1:11:43, 12.77s/it]\u001b[A\n",
      " 38%|██████████████▋                        | 204/540 [40:08<1:11:25, 12.76s/it]\u001b[A\n",
      " 38%|██████████████▊                        | 205/540 [40:21<1:11:33, 12.82s/it]\u001b[A\n",
      " 38%|██████████████▉                        | 206/540 [40:33<1:10:38, 12.69s/it]\u001b[A\n",
      " 38%|██████████████▉                        | 207/540 [40:45<1:09:27, 12.51s/it]\u001b[A\n",
      " 39%|███████████████                        | 208/540 [40:57<1:08:15, 12.34s/it]\u001b[A\n",
      " 39%|███████████████                        | 209/540 [41:09<1:07:51, 12.30s/it]\u001b[A\n",
      " 39%|███████████████▏                       | 210/540 [41:21<1:07:22, 12.25s/it]\u001b[A\n",
      " 39%|███████████████▏                       | 211/540 [41:33<1:06:36, 12.15s/it]\u001b[A\n",
      " 39%|███████████████▎                       | 212/540 [41:45<1:05:50, 12.04s/it]\u001b[A\n",
      " 39%|███████████████▍                       | 213/540 [41:57<1:05:39, 12.05s/it]\u001b[A\n",
      " 40%|███████████████▍                       | 214/540 [42:09<1:05:21, 12.03s/it]\u001b[A\n",
      " 40%|███████████████▌                       | 215/540 [42:21<1:05:13, 12.04s/it]\u001b[A\n",
      " 40%|███████████████▌                       | 216/540 [42:33<1:05:30, 12.13s/it]\u001b[A\n",
      " 40%|███████████████▋                       | 217/540 [42:46<1:05:14, 12.12s/it]\u001b[A\n",
      " 40%|███████████████▋                       | 218/540 [42:58<1:05:53, 12.28s/it]\u001b[A\n",
      " 41%|███████████████▊                       | 219/540 [43:11<1:05:58, 12.33s/it]\u001b[A\n",
      " 41%|███████████████▉                       | 220/540 [43:23<1:05:23, 12.26s/it]\u001b[A\n",
      " 41%|███████████████▉                       | 221/540 [43:35<1:05:00, 12.23s/it]\u001b[A\n",
      " 41%|████████████████                       | 222/540 [43:48<1:06:11, 12.49s/it]\u001b[A\n",
      " 41%|████████████████                       | 223/540 [44:01<1:06:54, 12.66s/it]\u001b[A\n",
      " 41%|████████████████▏                      | 224/540 [44:14<1:07:39, 12.85s/it]\u001b[A\n",
      " 42%|████████████████▎                      | 225/540 [44:28<1:09:30, 13.24s/it]\u001b[A\n",
      " 42%|████████████████▎                      | 226/540 [44:42<1:09:39, 13.31s/it]\u001b[A\n",
      " 42%|████████████████▍                      | 227/540 [44:55<1:09:18, 13.29s/it]\u001b[A\n",
      " 42%|████████████████▍                      | 228/540 [45:09<1:09:27, 13.36s/it]\u001b[A\n",
      " 42%|████████████████▌                      | 229/540 [45:22<1:09:10, 13.35s/it]\u001b[A\n",
      " 43%|████████████████▌                      | 230/540 [45:35<1:09:06, 13.38s/it]\u001b[A\n",
      " 43%|████████████████▋                      | 231/540 [45:49<1:08:24, 13.28s/it]\u001b[A\n",
      " 43%|████████████████▊                      | 232/540 [46:01<1:07:06, 13.07s/it]\u001b[A\n",
      " 43%|████████████████▊                      | 233/540 [46:14<1:06:23, 12.98s/it]\u001b[A\n",
      " 43%|████████████████▉                      | 234/540 [46:27<1:06:58, 13.13s/it]\u001b[A\n",
      " 44%|████████████████▉                      | 235/540 [46:40<1:05:26, 12.88s/it]\u001b[A\n",
      " 44%|█████████████████                      | 236/540 [46:52<1:04:06, 12.65s/it]\u001b[A\n",
      " 44%|█████████████████                      | 237/540 [47:04<1:03:25, 12.56s/it]\u001b[A\n",
      " 44%|█████████████████▏                     | 238/540 [47:17<1:03:03, 12.53s/it]\u001b[A\n",
      " 44%|█████████████████▎                     | 239/540 [47:29<1:02:36, 12.48s/it]\u001b[A\n",
      " 44%|█████████████████▎                     | 240/540 [47:41<1:02:07, 12.42s/it]\u001b[A\n",
      " 45%|█████████████████▍                     | 241/540 [47:54<1:01:48, 12.40s/it]\u001b[A\n",
      " 45%|█████████████████▍                     | 242/540 [48:07<1:02:24, 12.56s/it]\u001b[A\n",
      " 45%|█████████████████▌                     | 243/540 [48:21<1:04:16, 12.98s/it]\u001b[A\n",
      " 45%|█████████████████▌                     | 244/540 [48:35<1:05:58, 13.37s/it]\u001b[A\n",
      " 45%|█████████████████▋                     | 245/540 [48:48<1:05:04, 13.24s/it]\u001b[A\n",
      " 46%|█████████████████▊                     | 246/540 [49:02<1:06:08, 13.50s/it]\u001b[A\n",
      " 46%|█████████████████▊                     | 247/540 [49:15<1:05:55, 13.50s/it]\u001b[A\n",
      " 46%|█████████████████▉                     | 248/540 [49:28<1:03:56, 13.14s/it]\u001b[A\n",
      " 46%|█████████████████▉                     | 249/540 [49:40<1:02:51, 12.96s/it]\u001b[A\n",
      " 46%|██████████████████                     | 250/540 [49:53<1:03:00, 13.04s/it]\u001b[A\n",
      " 46%|██████████████████▏                    | 251/540 [50:06<1:02:01, 12.88s/it]\u001b[A\n",
      " 47%|██████████████████▏                    | 252/540 [50:19<1:01:49, 12.88s/it]\u001b[A\n",
      " 47%|██████████████████▎                    | 253/540 [50:32<1:01:36, 12.88s/it]\u001b[A\n",
      " 47%|██████████████████▎                    | 254/540 [50:45<1:02:16, 13.06s/it]\u001b[A\n",
      " 47%|██████████████████▍                    | 255/540 [50:58<1:01:44, 13.00s/it]\u001b[A\n",
      " 47%|██████████████████▍                    | 256/540 [51:11<1:00:57, 12.88s/it]\u001b[A\n",
      " 48%|██████████████████▌                    | 257/540 [51:24<1:01:21, 13.01s/it]\u001b[A\n",
      " 48%|██████████████████▋                    | 258/540 [51:37<1:00:59, 12.98s/it]\u001b[A\n",
      " 48%|██████████████████▋                    | 259/540 [51:50<1:00:37, 12.95s/it]\u001b[A\n",
      " 48%|███████████████████▋                     | 260/540 [52:02<59:57, 12.85s/it]\u001b[A\n",
      " 48%|███████████████████▊                     | 261/540 [52:15<59:43, 12.84s/it]\u001b[A\n",
      " 49%|███████████████████▉                     | 262/540 [52:28<59:26, 12.83s/it]\u001b[A\n",
      " 49%|██████████████████▉                    | 263/540 [52:41<1:00:05, 13.02s/it]\u001b[A\n",
      " 49%|████████████████████                     | 264/540 [52:54<59:32, 12.94s/it]\u001b[A\n",
      " 49%|████████████████████                     | 265/540 [53:07<58:50, 12.84s/it]\u001b[A\n",
      " 49%|████████████████████▏                    | 266/540 [53:20<58:39, 12.85s/it]\u001b[A\n",
      " 49%|████████████████████▎                    | 267/540 [53:32<58:03, 12.76s/it]\u001b[A\n",
      " 50%|████████████████████▎                    | 268/540 [53:45<57:30, 12.69s/it]\u001b[A\n",
      " 50%|████████████████████▍                    | 269/540 [53:58<57:33, 12.74s/it]\u001b[A\n",
      " 50%|████████████████████▌                    | 270/540 [54:10<57:22, 12.75s/it]\u001b[A\n",
      " 50%|████████████████████▌                    | 271/540 [54:22<56:17, 12.56s/it]\u001b[A\n",
      " 50%|████████████████████▋                    | 272/540 [54:34<54:59, 12.31s/it]\u001b[A\n",
      " 51%|████████████████████▋                    | 273/540 [54:47<55:35, 12.49s/it]\u001b[A\n",
      " 51%|████████████████████▊                    | 274/540 [54:59<55:16, 12.47s/it]\u001b[A\n",
      " 51%|████████████████████▉                    | 275/540 [55:12<54:51, 12.42s/it]\u001b[A\n",
      " 51%|████████████████████▉                    | 276/540 [55:24<54:54, 12.48s/it]\u001b[A\n",
      " 51%|█████████████████████                    | 277/540 [55:37<54:24, 12.41s/it]\u001b[A\n",
      " 51%|█████████████████████                    | 278/540 [55:49<54:00, 12.37s/it]\u001b[A\n",
      " 52%|█████████████████████▏                   | 279/540 [56:01<53:54, 12.39s/it]\u001b[A\n",
      " 52%|█████████████████████▎                   | 280/540 [56:14<53:53, 12.44s/it]\u001b[A\n",
      " 52%|█████████████████████▎                   | 281/540 [56:26<53:22, 12.36s/it]\u001b[A\n",
      " 52%|█████████████████████▍                   | 282/540 [56:39<53:36, 12.47s/it]\u001b[A\n",
      " 52%|█████████████████████▍                   | 283/540 [56:52<53:53, 12.58s/it]\u001b[A\n",
      " 53%|█████████████████████▌                   | 284/540 [57:04<53:11, 12.47s/it]\u001b[A\n",
      " 53%|█████████████████████▋                   | 285/540 [57:16<52:14, 12.29s/it]\u001b[A\n",
      " 53%|█████████████████████▋                   | 286/540 [57:28<51:51, 12.25s/it]\u001b[A\n",
      " 53%|█████████████████████▊                   | 287/540 [57:40<51:49, 12.29s/it]\u001b[A\n",
      " 53%|█████████████████████▊                   | 288/540 [57:53<51:44, 12.32s/it]\u001b[A\n",
      " 54%|█████████████████████▉                   | 289/540 [58:05<51:41, 12.36s/it]\u001b[A\n",
      " 54%|██████████████████████                   | 290/540 [58:17<51:04, 12.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████                   | 291/540 [58:30<51:08, 12.32s/it]\u001b[A\n",
      " 54%|██████████████████████▏                  | 292/540 [58:43<51:53, 12.55s/it]\u001b[A\n",
      " 54%|██████████████████████▏                  | 293/540 [58:55<51:06, 12.41s/it]\u001b[A\n",
      " 54%|██████████████████████▎                  | 294/540 [59:07<50:39, 12.36s/it]\u001b[A\n",
      " 55%|██████████████████████▍                  | 295/540 [59:20<50:39, 12.40s/it]\u001b[A\n",
      " 55%|██████████████████████▍                  | 296/540 [59:33<51:12, 12.59s/it]\u001b[A\n",
      " 55%|██████████████████████▌                  | 297/540 [59:45<50:46, 12.54s/it]\u001b[A\n",
      " 55%|██████████████████████▋                  | 298/540 [59:57<50:02, 12.41s/it]\u001b[A\n",
      " 55%|█████████████████████▌                 | 299/540 [1:00:10<50:35, 12.59s/it]\u001b[A\n",
      " 56%|█████████████████████▋                 | 300/540 [1:00:22<49:47, 12.45s/it]\u001b[A\n",
      " 56%|█████████████████████▋                 | 301/540 [1:00:35<50:08, 12.59s/it]\u001b[A\n",
      " 56%|█████████████████████▊                 | 302/540 [1:00:49<51:24, 12.96s/it]\u001b[A\n",
      " 56%|█████████████████████▉                 | 303/540 [1:01:02<51:06, 12.94s/it]\u001b[A\n",
      " 56%|█████████████████████▉                 | 304/540 [1:01:15<51:31, 13.10s/it]\u001b[A\n",
      " 56%|██████████████████████                 | 305/540 [1:01:28<50:53, 12.99s/it]\u001b[A\n",
      " 57%|██████████████████████                 | 306/540 [1:01:41<50:10, 12.87s/it]\u001b[A\n",
      " 57%|██████████████████████▏                | 307/540 [1:01:53<49:47, 12.82s/it]\u001b[A\n",
      " 57%|██████████████████████▏                | 308/540 [1:02:06<49:11, 12.72s/it]\u001b[A\n",
      " 57%|██████████████████████▎                | 309/540 [1:02:18<48:29, 12.59s/it]\u001b[A\n",
      " 57%|██████████████████████▍                | 310/540 [1:02:31<48:13, 12.58s/it]\u001b[A\n",
      " 58%|██████████████████████▍                | 311/540 [1:02:44<48:17, 12.65s/it]\u001b[A\n",
      " 58%|██████████████████████▌                | 312/540 [1:02:57<48:55, 12.88s/it]\u001b[A\n",
      " 58%|██████████████████████▌                | 313/540 [1:03:09<47:57, 12.68s/it]\u001b[A\n",
      " 58%|██████████████████████▋                | 314/540 [1:03:22<47:34, 12.63s/it]\u001b[A\n",
      " 58%|██████████████████████▊                | 315/540 [1:03:35<48:03, 12.81s/it]\u001b[A\n",
      " 59%|██████████████████████▊                | 316/540 [1:03:48<48:03, 12.87s/it]\u001b[A\n",
      " 59%|██████████████████████▉                | 317/540 [1:04:01<47:50, 12.87s/it]\u001b[A\n",
      " 59%|██████████████████████▉                | 318/540 [1:04:14<47:39, 12.88s/it]\u001b[A\n",
      " 59%|███████████████████████                | 319/540 [1:04:27<47:27, 12.89s/it]\u001b[A\n",
      " 59%|███████████████████████                | 320/540 [1:04:39<46:21, 12.64s/it]\u001b[A\n",
      " 59%|███████████████████████▏               | 321/540 [1:04:51<46:07, 12.64s/it]\u001b[A\n",
      " 60%|███████████████████████▎               | 322/540 [1:05:04<46:01, 12.67s/it]\u001b[A\n",
      " 60%|███████████████████████▎               | 323/540 [1:05:16<45:16, 12.52s/it]\u001b[A\n",
      " 60%|███████████████████████▍               | 324/540 [1:05:28<44:36, 12.39s/it]\u001b[A\n",
      " 60%|███████████████████████▍               | 325/540 [1:05:40<44:04, 12.30s/it]\u001b[A\n",
      " 60%|███████████████████████▌               | 326/540 [1:05:52<43:36, 12.22s/it]\u001b[A\n",
      " 61%|███████████████████████▌               | 327/540 [1:06:05<44:01, 12.40s/it]\u001b[A\n",
      " 61%|███████████████████████▋               | 328/540 [1:06:18<43:56, 12.44s/it]\u001b[A\n",
      " 61%|███████████████████████▊               | 329/540 [1:06:30<44:01, 12.52s/it]\u001b[A\n",
      " 61%|███████████████████████▊               | 330/540 [1:06:43<43:53, 12.54s/it]\u001b[A\n",
      " 61%|███████████████████████▉               | 331/540 [1:06:56<43:43, 12.55s/it]\u001b[A\n",
      " 61%|███████████████████████▉               | 332/540 [1:07:08<43:42, 12.61s/it]\u001b[A\n",
      " 62%|████████████████████████               | 333/540 [1:07:21<43:02, 12.47s/it]\u001b[A\n",
      " 62%|████████████████████████               | 334/540 [1:07:33<42:33, 12.40s/it]\u001b[A\n",
      " 62%|████████████████████████▏              | 335/540 [1:07:45<42:13, 12.36s/it]\u001b[A\n",
      " 62%|████████████████████████▎              | 336/540 [1:07:57<41:55, 12.33s/it]\u001b[A\n",
      " 62%|████████████████████████▎              | 337/540 [1:08:09<41:23, 12.24s/it]\u001b[A\n",
      " 63%|████████████████████████▍              | 338/540 [1:08:21<40:57, 12.16s/it]\u001b[A\n",
      " 63%|████████████████████████▍              | 339/540 [1:08:33<40:35, 12.12s/it]\u001b[A\n",
      " 63%|████████████████████████▌              | 340/540 [1:08:46<40:57, 12.29s/it]\u001b[A\n",
      " 63%|████████████████████████▋              | 341/540 [1:08:59<41:53, 12.63s/it]\u001b[A\n",
      " 63%|████████████████████████▋              | 342/540 [1:09:12<41:50, 12.68s/it]\u001b[A\n",
      " 64%|████████████████████████▊              | 343/540 [1:09:24<41:12, 12.55s/it]\u001b[A\n",
      " 64%|████████████████████████▊              | 344/540 [1:09:37<40:57, 12.54s/it]\u001b[A\n",
      " 64%|████████████████████████▉              | 345/540 [1:09:50<41:27, 12.76s/it]\u001b[A\n",
      " 64%|████████████████████████▉              | 346/540 [1:10:03<41:34, 12.86s/it]\u001b[A\n",
      " 64%|█████████████████████████              | 347/540 [1:10:16<41:12, 12.81s/it]\u001b[A\n",
      " 64%|█████████████████████████▏             | 348/540 [1:10:29<41:17, 12.91s/it]\u001b[A\n",
      " 65%|█████████████████████████▏             | 349/540 [1:10:42<40:37, 12.76s/it]\u001b[A\n",
      " 65%|█████████████████████████▎             | 350/540 [1:10:54<40:08, 12.68s/it]\u001b[A\n",
      " 65%|█████████████████████████▎             | 351/540 [1:11:07<40:14, 12.77s/it]\u001b[A\n",
      " 65%|█████████████████████████▍             | 352/540 [1:11:20<39:44, 12.68s/it]\u001b[A\n",
      " 65%|█████████████████████████▍             | 353/540 [1:11:32<39:07, 12.56s/it]\u001b[A\n",
      " 66%|█████████████████████████▌             | 354/540 [1:11:44<38:41, 12.48s/it]\u001b[A\n",
      " 66%|█████████████████████████▋             | 355/540 [1:11:56<38:12, 12.39s/it]\u001b[A\n",
      " 66%|█████████████████████████▋             | 356/540 [1:12:09<37:56, 12.37s/it]\u001b[A\n",
      " 66%|█████████████████████████▊             | 357/540 [1:12:21<37:27, 12.28s/it]\u001b[A\n",
      " 66%|█████████████████████████▊             | 358/540 [1:12:33<37:28, 12.35s/it]\u001b[A\n",
      " 66%|█████████████████████████▉             | 359/540 [1:12:45<37:03, 12.28s/it]\u001b[A\n",
      " 67%|██████████████████████████             | 360/540 [1:12:58<37:03, 12.35s/it]\u001b[A\n",
      " 67%|██████████████████████████             | 361/540 [1:13:11<37:08, 12.45s/it]\u001b[A\n",
      " 67%|██████████████████████████▏            | 362/540 [1:13:23<36:40, 12.36s/it]\u001b[A\n",
      " 67%|██████████████████████████▏            | 363/540 [1:13:35<36:13, 12.28s/it]\u001b[A\n",
      " 67%|██████████████████████████▎            | 364/540 [1:13:47<35:49, 12.21s/it]\u001b[A\n",
      " 68%|██████████████████████████▎            | 365/540 [1:13:59<35:53, 12.30s/it]\u001b[A\n",
      " 68%|██████████████████████████▍            | 366/540 [1:14:12<35:48, 12.35s/it]\u001b[A\n",
      " 68%|██████████████████████████▌            | 367/540 [1:14:24<35:33, 12.33s/it]\u001b[A\n",
      " 68%|██████████████████████████▌            | 368/540 [1:14:36<35:17, 12.31s/it]\u001b[A\n",
      " 68%|██████████████████████████▋            | 369/540 [1:14:49<35:19, 12.40s/it]\u001b[A\n",
      " 69%|██████████████████████████▋            | 370/540 [1:15:02<35:31, 12.54s/it]\u001b[A\n",
      " 69%|██████████████████████████▊            | 371/540 [1:15:14<35:22, 12.56s/it]\u001b[A\n",
      " 69%|██████████████████████████▊            | 372/540 [1:15:27<35:11, 12.57s/it]\u001b[A\n",
      " 69%|██████████████████████████▉            | 373/540 [1:15:40<35:20, 12.70s/it]\u001b[A\n",
      " 69%|███████████████████████████            | 374/540 [1:15:53<35:08, 12.70s/it]\u001b[A\n",
      " 69%|███████████████████████████            | 375/540 [1:16:05<34:33, 12.57s/it]\u001b[A\n",
      " 70%|███████████████████████████▏           | 376/540 [1:16:17<34:11, 12.51s/it]\u001b[A\n",
      " 70%|███████████████████████████▏           | 377/540 [1:16:30<34:13, 12.60s/it]\u001b[A\n",
      " 70%|███████████████████████████▎           | 378/540 [1:16:43<33:54, 12.56s/it]\u001b[A\n",
      " 70%|███████████████████████████▎           | 379/540 [1:16:55<33:45, 12.58s/it]\u001b[A\n",
      " 70%|███████████████████████████▍           | 380/540 [1:17:08<33:43, 12.65s/it]\u001b[A\n",
      " 71%|███████████████████████████▌           | 381/540 [1:17:21<33:34, 12.67s/it]\u001b[A\n",
      " 71%|███████████████████████████▌           | 382/540 [1:17:33<33:07, 12.58s/it]\u001b[A\n",
      " 71%|███████████████████████████▋           | 383/540 [1:17:46<32:48, 12.54s/it]\u001b[A\n",
      " 71%|███████████████████████████▋           | 384/540 [1:17:58<32:20, 12.44s/it]\u001b[A\n",
      " 71%|███████████████████████████▊           | 385/540 [1:18:11<32:31, 12.59s/it]\u001b[A\n",
      " 71%|███████████████████████████▉           | 386/540 [1:18:23<32:02, 12.48s/it]\u001b[A\n",
      " 72%|███████████████████████████▉           | 387/540 [1:18:35<31:33, 12.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████           | 388/540 [1:18:47<31:16, 12.34s/it]\u001b[A\n",
      " 72%|████████████████████████████           | 389/540 [1:19:00<31:26, 12.50s/it]\u001b[A\n",
      " 72%|████████████████████████████▏          | 390/540 [1:19:14<32:26, 12.98s/it]\u001b[A\n",
      " 72%|████████████████████████████▏          | 391/540 [1:19:27<32:01, 12.90s/it]\u001b[A\n",
      " 73%|████████████████████████████▎          | 392/540 [1:19:39<31:19, 12.70s/it]\u001b[A\n",
      " 73%|████████████████████████████▍          | 393/540 [1:19:52<31:26, 12.83s/it]\u001b[A\n",
      " 73%|████████████████████████████▍          | 394/540 [1:20:05<30:54, 12.71s/it]\u001b[A\n",
      " 73%|████████████████████████████▌          | 395/540 [1:20:17<30:21, 12.56s/it]\u001b[A\n",
      " 73%|████████████████████████████▌          | 396/540 [1:20:30<30:12, 12.59s/it]\u001b[A\n",
      " 74%|████████████████████████████▋          | 397/540 [1:20:43<30:11, 12.67s/it]\u001b[A\n",
      " 74%|████████████████████████████▋          | 398/540 [1:20:55<29:48, 12.60s/it]\u001b[A\n",
      " 74%|████████████████████████████▊          | 399/540 [1:21:07<29:32, 12.57s/it]\u001b[A\n",
      " 74%|████████████████████████████▉          | 400/540 [1:21:20<29:22, 12.59s/it]\u001b[A\n",
      " 74%|████████████████████████████▉          | 401/540 [1:21:33<29:14, 12.63s/it]\u001b[A\n",
      " 74%|█████████████████████████████          | 402/540 [1:21:46<29:17, 12.73s/it]\u001b[A\n",
      " 75%|█████████████████████████████          | 403/540 [1:21:59<29:31, 12.93s/it]\u001b[A\n",
      " 75%|█████████████████████████████▏         | 404/540 [1:22:12<29:16, 12.92s/it]\u001b[A\n",
      " 75%|█████████████████████████████▎         | 405/540 [1:22:25<29:23, 13.06s/it]\u001b[A\n",
      " 75%|█████████████████████████████▎         | 406/540 [1:22:38<28:54, 12.94s/it]\u001b[A\n",
      " 75%|█████████████████████████████▍         | 407/540 [1:22:50<28:17, 12.76s/it]\u001b[A\n",
      " 76%|█████████████████████████████▍         | 408/540 [1:23:03<27:58, 12.72s/it]\u001b[A\n",
      " 76%|█████████████████████████████▌         | 409/540 [1:23:18<29:12, 13.38s/it]\u001b[A\n",
      " 76%|█████████████████████████████▌         | 410/540 [1:23:31<28:45, 13.27s/it]\u001b[A\n",
      " 76%|█████████████████████████████▋         | 411/540 [1:23:45<28:47, 13.39s/it]\u001b[A\n",
      " 76%|█████████████████████████████▊         | 412/540 [1:23:58<28:28, 13.35s/it]\u001b[A\n",
      " 76%|█████████████████████████████▊         | 413/540 [1:24:12<28:37, 13.53s/it]\u001b[A\n",
      " 77%|█████████████████████████████▉         | 414/540 [1:24:25<27:58, 13.32s/it]\u001b[A\n",
      " 77%|█████████████████████████████▉         | 415/540 [1:24:37<27:17, 13.10s/it]\u001b[A\n",
      " 77%|██████████████████████████████         | 416/540 [1:24:51<27:17, 13.21s/it]\u001b[A\n",
      " 77%|██████████████████████████████         | 417/540 [1:25:04<27:17, 13.31s/it]\u001b[A\n",
      " 77%|██████████████████████████████▏        | 418/540 [1:25:18<26:59, 13.27s/it]\u001b[A\n",
      " 78%|██████████████████████████████▎        | 419/540 [1:25:31<26:36, 13.19s/it]\u001b[A\n",
      " 78%|██████████████████████████████▎        | 420/540 [1:25:44<26:35, 13.29s/it]\u001b[A\n",
      " 78%|██████████████████████████████▍        | 421/540 [1:25:57<26:19, 13.27s/it]\u001b[A\n",
      " 78%|██████████████████████████████▍        | 422/540 [1:26:10<25:40, 13.05s/it]\u001b[A\n",
      " 78%|██████████████████████████████▌        | 423/540 [1:26:22<25:06, 12.88s/it]\u001b[A\n",
      " 79%|██████████████████████████████▌        | 424/540 [1:26:35<24:37, 12.74s/it]\u001b[A\n",
      " 79%|██████████████████████████████▋        | 425/540 [1:26:47<24:16, 12.67s/it]\u001b[A\n",
      " 79%|██████████████████████████████▊        | 426/540 [1:27:00<24:16, 12.77s/it]\u001b[A\n",
      " 79%|██████████████████████████████▊        | 427/540 [1:27:14<24:26, 12.98s/it]\u001b[A\n",
      " 79%|██████████████████████████████▉        | 428/540 [1:27:28<25:09, 13.48s/it]\u001b[A\n",
      " 79%|██████████████████████████████▉        | 429/540 [1:27:42<24:53, 13.46s/it]\u001b[A\n",
      " 80%|███████████████████████████████        | 430/540 [1:27:55<24:28, 13.35s/it]\u001b[A\n",
      " 80%|███████████████████████████████▏       | 431/540 [1:28:08<24:08, 13.29s/it]\u001b[A\n",
      " 80%|███████████████████████████████▏       | 432/540 [1:28:21<23:55, 13.29s/it]\u001b[A\n",
      " 80%|███████████████████████████████▎       | 433/540 [1:28:35<24:00, 13.46s/it]\u001b[A\n",
      " 80%|███████████████████████████████▎       | 434/540 [1:28:49<23:49, 13.48s/it]\u001b[A\n",
      " 81%|███████████████████████████████▍       | 435/540 [1:29:02<23:24, 13.37s/it]\u001b[A\n",
      " 81%|███████████████████████████████▍       | 436/540 [1:29:15<23:13, 13.40s/it]\u001b[A\n",
      " 81%|███████████████████████████████▌       | 437/540 [1:29:29<23:08, 13.48s/it]\u001b[A\n",
      " 81%|███████████████████████████████▋       | 438/540 [1:29:42<22:42, 13.35s/it]\u001b[A\n",
      " 81%|███████████████████████████████▋       | 439/540 [1:29:55<22:12, 13.19s/it]\u001b[A\n",
      " 81%|███████████████████████████████▊       | 440/540 [1:30:07<21:41, 13.02s/it]\u001b[A\n",
      " 82%|███████████████████████████████▊       | 441/540 [1:30:20<21:27, 13.01s/it]\u001b[A\n",
      " 82%|███████████████████████████████▉       | 442/540 [1:30:33<20:56, 12.82s/it]\u001b[A\n",
      " 82%|███████████████████████████████▉       | 443/540 [1:30:45<20:37, 12.76s/it]\u001b[A\n",
      " 82%|████████████████████████████████       | 444/540 [1:30:58<20:23, 12.75s/it]\u001b[A\n",
      " 82%|████████████████████████████████▏      | 445/540 [1:31:12<20:32, 12.97s/it]\u001b[A\n",
      " 83%|████████████████████████████████▏      | 446/540 [1:31:24<20:16, 12.94s/it]\u001b[A\n",
      " 83%|████████████████████████████████▎      | 447/540 [1:31:37<20:00, 12.91s/it]\u001b[A\n",
      " 83%|████████████████████████████████▎      | 448/540 [1:31:50<19:43, 12.86s/it]\u001b[A\n",
      " 83%|████████████████████████████████▍      | 449/540 [1:32:03<19:32, 12.88s/it]\u001b[A\n",
      " 83%|████████████████████████████████▌      | 450/540 [1:32:16<19:18, 12.87s/it]\u001b[A\n",
      " 84%|████████████████████████████████▌      | 451/540 [1:32:29<19:10, 12.92s/it]\u001b[A\n",
      " 84%|████████████████████████████████▋      | 452/540 [1:32:42<18:54, 12.89s/it]\u001b[A\n",
      " 84%|████████████████████████████████▋      | 453/540 [1:32:55<18:46, 12.95s/it]\u001b[A\n",
      " 84%|████████████████████████████████▊      | 454/540 [1:33:08<18:46, 13.09s/it]\u001b[A\n",
      " 84%|████████████████████████████████▊      | 455/540 [1:33:21<18:35, 13.12s/it]\u001b[A\n",
      " 84%|████████████████████████████████▉      | 456/540 [1:33:36<19:06, 13.65s/it]\u001b[A\n",
      " 85%|█████████████████████████████████      | 457/540 [1:33:50<19:03, 13.78s/it]\u001b[A\n",
      " 85%|█████████████████████████████████      | 458/540 [1:34:04<18:37, 13.63s/it]\u001b[A\n",
      " 85%|█████████████████████████████████▏     | 459/540 [1:34:18<18:41, 13.84s/it]\u001b[A\n",
      " 85%|█████████████████████████████████▏     | 460/540 [1:34:32<18:36, 13.96s/it]\u001b[A\n",
      " 85%|█████████████████████████████████▎     | 461/540 [1:34:46<18:22, 13.96s/it]\u001b[A\n",
      " 86%|█████████████████████████████████▎     | 462/540 [1:35:00<17:56, 13.80s/it]\u001b[A\n",
      " 86%|█████████████████████████████████▍     | 463/540 [1:35:13<17:22, 13.54s/it]\u001b[A\n",
      " 86%|█████████████████████████████████▌     | 464/540 [1:35:26<17:07, 13.51s/it]\u001b[A\n",
      " 86%|█████████████████████████████████▌     | 465/540 [1:35:39<16:45, 13.40s/it]\u001b[A\n",
      " 86%|█████████████████████████████████▋     | 466/540 [1:35:52<16:21, 13.27s/it]\u001b[A\n",
      " 86%|█████████████████████████████████▋     | 467/540 [1:36:05<16:00, 13.16s/it]\u001b[A\n",
      " 87%|█████████████████████████████████▊     | 468/540 [1:36:18<15:54, 13.25s/it]\u001b[A\n",
      " 87%|█████████████████████████████████▊     | 469/540 [1:36:31<15:33, 13.15s/it]\u001b[A\n",
      " 87%|█████████████████████████████████▉     | 470/540 [1:36:44<15:07, 12.97s/it]\u001b[A\n",
      " 87%|██████████████████████████████████     | 471/540 [1:36:57<14:47, 12.87s/it]\u001b[A\n",
      " 87%|██████████████████████████████████     | 472/540 [1:37:09<14:36, 12.90s/it]\u001b[A\n",
      " 88%|██████████████████████████████████▏    | 473/540 [1:37:22<14:20, 12.85s/it]\u001b[A\n",
      " 88%|██████████████████████████████████▏    | 474/540 [1:37:36<14:19, 13.03s/it]\u001b[A\n",
      " 88%|██████████████████████████████████▎    | 475/540 [1:37:48<14:01, 12.95s/it]\u001b[A\n",
      " 88%|██████████████████████████████████▍    | 476/540 [1:38:01<13:47, 12.93s/it]\u001b[A\n",
      " 88%|██████████████████████████████████▍    | 477/540 [1:38:14<13:28, 12.84s/it]\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 478/540 [1:38:27<13:15, 12.83s/it]\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 479/540 [1:38:40<13:01, 12.81s/it]\u001b[A\n",
      " 89%|██████████████████████████████████▋    | 480/540 [1:38:53<12:53, 12.89s/it]\u001b[A\n",
      " 89%|██████████████████████████████████▋    | 481/540 [1:39:05<12:34, 12.79s/it]\u001b[A\n",
      " 89%|██████████████████████████████████▊    | 482/540 [1:39:18<12:19, 12.76s/it]\u001b[A\n",
      " 89%|██████████████████████████████████▉    | 483/540 [1:39:31<12:09, 12.80s/it]\u001b[A\n",
      " 90%|██████████████████████████████████▉    | 484/540 [1:39:44<12:10, 13.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████    | 485/540 [1:39:57<11:58, 13.06s/it]\u001b[A\n",
      " 90%|███████████████████████████████████    | 486/540 [1:40:10<11:40, 12.98s/it]\u001b[A\n",
      " 90%|███████████████████████████████████▏   | 487/540 [1:40:23<11:26, 12.95s/it]\u001b[A\n",
      " 90%|███████████████████████████████████▏   | 488/540 [1:40:36<11:17, 13.02s/it]\u001b[A\n",
      " 91%|███████████████████████████████████▎   | 489/540 [1:40:49<11:01, 12.96s/it]\u001b[A\n",
      " 91%|███████████████████████████████████▍   | 490/540 [1:41:02<10:45, 12.90s/it]\u001b[A\n",
      " 91%|███████████████████████████████████▍   | 491/540 [1:41:15<10:30, 12.87s/it]\u001b[A\n",
      " 91%|███████████████████████████████████▌   | 492/540 [1:41:28<10:23, 12.99s/it]\u001b[A\n",
      " 91%|███████████████████████████████████▌   | 493/540 [1:41:41<10:16, 13.12s/it]\u001b[A\n",
      " 91%|███████████████████████████████████▋   | 494/540 [1:41:54<10:02, 13.11s/it]\u001b[A\n",
      " 92%|███████████████████████████████████▊   | 495/540 [1:42:07<09:45, 13.01s/it]\u001b[A\n",
      " 92%|███████████████████████████████████▊   | 496/540 [1:42:20<09:33, 13.04s/it]\u001b[A\n",
      " 92%|███████████████████████████████████▉   | 497/540 [1:42:34<09:22, 13.08s/it]\u001b[A\n",
      " 92%|███████████████████████████████████▉   | 498/540 [1:42:47<09:11, 13.13s/it]\u001b[A\n",
      " 92%|████████████████████████████████████   | 499/540 [1:43:00<08:54, 13.05s/it]\u001b[A\n",
      " 93%|████████████████████████████████████   | 500/540 [1:43:13<08:41, 13.04s/it]\u001b[A\n",
      " 93%|████████████████████████████████████▏  | 501/540 [1:43:26<08:26, 12.99s/it]\u001b[A\n",
      " 93%|████████████████████████████████████▎  | 502/540 [1:43:38<08:08, 12.85s/it]\u001b[A\n",
      " 93%|████████████████████████████████████▎  | 503/540 [1:43:52<08:02, 13.05s/it]\u001b[A\n",
      " 93%|████████████████████████████████████▍  | 504/540 [1:44:05<07:51, 13.10s/it]\u001b[A\n",
      " 94%|████████████████████████████████████▍  | 505/540 [1:44:17<07:32, 12.93s/it]\u001b[A\n",
      " 94%|████████████████████████████████████▌  | 506/540 [1:44:30<07:16, 12.85s/it]\u001b[A\n",
      " 94%|████████████████████████████████████▌  | 507/540 [1:44:43<07:01, 12.77s/it]\u001b[A\n",
      " 94%|████████████████████████████████████▋  | 508/540 [1:44:55<06:49, 12.79s/it]\u001b[A\n",
      " 94%|████████████████████████████████████▊  | 509/540 [1:45:08<06:36, 12.79s/it]\u001b[A\n",
      " 94%|████████████████████████████████████▊  | 510/540 [1:45:21<06:22, 12.75s/it]\u001b[A\n",
      " 95%|████████████████████████████████████▉  | 511/540 [1:45:34<06:10, 12.79s/it]\u001b[A\n",
      " 95%|████████████████████████████████████▉  | 512/540 [1:45:47<06:04, 13.03s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████  | 513/540 [1:46:00<05:49, 12.95s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████  | 514/540 [1:46:13<05:35, 12.92s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████▏ | 515/540 [1:46:26<05:23, 12.92s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████▎ | 516/540 [1:46:39<05:13, 13.04s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████▎ | 517/540 [1:46:52<04:59, 13.03s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████▍ | 518/540 [1:47:05<04:45, 12.98s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████▍ | 519/540 [1:47:18<04:31, 12.94s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████▌ | 520/540 [1:47:31<04:20, 13.01s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████▋ | 521/540 [1:47:44<04:07, 13.04s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████▋ | 522/540 [1:47:58<03:59, 13.31s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████▊ | 523/540 [1:48:11<03:45, 13.24s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████▊ | 524/540 [1:48:25<03:32, 13.26s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████▉ | 525/540 [1:48:38<03:17, 13.20s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████▉ | 526/540 [1:48:51<03:04, 13.16s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████ | 527/540 [1:49:04<02:53, 13.32s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████▏| 528/540 [1:49:18<02:41, 13.47s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████▏| 529/540 [1:49:31<02:27, 13.43s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████▎| 530/540 [1:49:44<02:12, 13.29s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████▎| 531/540 [1:49:58<02:01, 13.47s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████▍| 532/540 [1:50:12<01:48, 13.53s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████▍| 533/540 [1:50:25<01:34, 13.47s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████▌| 534/540 [1:50:38<01:19, 13.32s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████▋| 535/540 [1:50:52<01:06, 13.36s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████▋| 536/540 [1:51:06<00:54, 13.67s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████▊| 537/540 [1:51:20<00:41, 13.67s/it]\u001b[A\n",
      "100%|██████████████████████████████████████▊| 538/540 [1:51:34<00:27, 13.80s/it]\u001b[A\n",
      "100%|██████████████████████████████████████▉| 539/540 [1:51:49<00:14, 14.04s/it]\u001b[A\n",
      "100%|███████████████████████████████████████| 540/540 [1:52:03<00:00, 14.06s/it]\u001b[A"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m                 model_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoherence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cv)\n\u001b[1;32m     58\u001b[0m                 pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_results\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results/lda_tuning_results.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/io/formats/csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/io/common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 737\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pandas/io/common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('./results/lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f49f1",
   "metadata": {},
   "source": [
    "Step 7: Final Model\n",
    "Based on external evaluation (Code to be added from Excel based analysis), let's train the final model with parameters yielding highest coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d91a4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 8\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9707bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.011*\"model\" + 0.006*\"object\" + 0.006*\"input\" + 0.005*\"cell\" + 0.005*\"use\" '\n",
      "  '+ 0.004*\"neuron\" + 0.004*\"word\" + 0.004*\"performance\" + 0.003*\"show\" + '\n",
      "  '0.003*\"learn\"'),\n",
      " (1,\n",
      "  '0.006*\"player\" + 0.006*\"task\" + 0.004*\"regret\" + 0.004*\"game\" + '\n",
      "  '0.003*\"regression\" + 0.003*\"different\" + 0.003*\"classification\" + '\n",
      "  '0.003*\"result\" + 0.003*\"utility\" + 0.003*\"parameter\"'),\n",
      " (2,\n",
      "  '0.006*\"set\" + 0.006*\"method\" + 0.006*\"feature\" + 0.006*\"training\" + '\n",
      "  '0.005*\"neural\" + 0.005*\"use\" + 0.005*\"network\" + 0.005*\"figure\" + '\n",
      "  '0.004*\"system\" + 0.004*\"learn\"'),\n",
      " (3,\n",
      "  '0.013*\"network\" + 0.007*\"learn\" + 0.006*\"value\" + 0.006*\"layer\" + '\n",
      "  '0.005*\"use\" + 0.005*\"set\" + 0.004*\"language\" + 0.004*\"neural\" + '\n",
      "  '0.004*\"method\" + 0.004*\"game\"'),\n",
      " (4,\n",
      "  '0.011*\"model\" + 0.008*\"learn\" + 0.007*\"use\" + 0.007*\"cluster\" + '\n",
      "  '0.007*\"point\" + 0.006*\"graph\" + 0.006*\"result\" + 0.006*\"set\" + 0.006*\"show\" '\n",
      "  '+ 0.006*\"function\"'),\n",
      " (5,\n",
      "  '0.009*\"function\" + 0.009*\"set\" + 0.008*\"use\" + 0.008*\"learn\" + '\n",
      "  '0.008*\"problem\" + 0.007*\"example\" + 0.006*\"follow\" + 0.005*\"optimal\" + '\n",
      "  '0.005*\"task\" + 0.005*\"method\"'),\n",
      " (6,\n",
      "  '0.012*\"influence\" + 0.005*\"time\" + 0.004*\"function\" + 0.004*\"spike\" + '\n",
      "  '0.004*\"rule\" + 0.003*\"cascade\" + 0.003*\"model\" + 0.002*\"spike_train\" + '\n",
      "  '0.002*\"neuron\" + 0.002*\"input\"'),\n",
      " (7,\n",
      "  '0.016*\"model\" + 0.010*\"use\" + 0.008*\"set\" + 0.008*\"sample\" + '\n",
      "  '0.007*\"network\" + 0.007*\"distribution\" + 0.007*\"time\" + 0.006*\"method\" + '\n",
      "  '0.006*\"datum\" + 0.006*\"learn\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723dc4d",
   "metadata": {},
   "source": [
    "Step 8: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e826b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el126151406710323399043450198615\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el126151406710323399043450198615_data = {\"mdsDat\": {\"x\": [-0.08624100579555657, -0.07984060690411966, -0.08507200251767313, 0.002538760465989908, 0.025471662289779387, 0.0411884194961175, 0.09615468125724777, 0.08580009170821475], \"y\": [0.003575088995559735, -0.007161006832514683, -0.03349129684160273, 0.04118429380843772, 0.058728231050389185, -0.016107992591096854, -0.003900046875298187, -0.042827270713874134], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [28.01306801610648, 24.38392488859438, 24.240630236676804, 8.995666589927835, 7.429888160837939, 4.258607322404835, 1.416490681890118, 1.2617241035616134]}, \"tinfo\": {\"Term\": [\"network\", \"model\", \"task\", \"time\", \"input\", \"graph\", \"influence\", \"cluster\", \"regression\", \"learn\", \"feature\", \"value\", \"neural\", \"function\", \"object\", \"rule\", \"layer\", \"neuron\", \"classification\", \"different\", \"method\", \"game\", \"training\", \"output\", \"rate\", \"set\", \"parameter\", \"cell\", \"signal\", \"convergence\", \"tempered_transition\", \"timino\", \"sampler\", \"mmsb\", \"vertex_cover\", \"stochastic_gradient\", \"treewidth\", \"weak_learner\", \"coverage_risk\", \"causal\", \"causality\", \"retention_interval\", \"participant\", \"dag\", \"ado\", \"posterior\", \"gp\", \"variational_inference\", \"srnn\", \"density_ridge\", \"coverage\", \"tree_width\", \"instantaneous_effect\", \"variational_approximation\", \"expert\", \"link\", \"retention\", \"stochastic\", \"conditional_evidence\", \"stratify\", \"community\", \"bayesian\", \"likelihood\", \"inference\", \"full\", \"sample\", \"process\", \"noise\", \"model\", \"network\", \"distribution\", \"time\", \"probability\", \"experiment\", \"step\", \"parameter\", \"datum\", \"use\", \"mean\", \"set\", \"prior\", \"method\", \"estimate\", \"give\", \"test\", \"log\", \"show\", \"matrix\", \"number\", \"learn\", \"function\", \"value\", \"result\", \"figure\", \"error\", \"teacher\", \"cggm\", \"gene_expression\", \"tensor\", \"trmf\", \"tissue\", \"base_classifier\", \"mmse\", \"manifold_sculpte\", \"hypercube\", \"spectral_clustere\", \"gene\", \"semi_supervise\", \"mvp\", \"cluster\", \"alternating_minimization\", \"matrix_factorization\", \"volterra_functional\", \"multi_view\", \"volterra_serie\", \"amp\", \"spectral\", \"temporal_difference\", \"egood\", \"phase_transition\", \"wiener_functional\", \"clustering\", \"request\", \"random_walk\", \"monomial\", \"rkh\", \"identity\", \"merge\", \"supervise\", \"neighbor\", \"graph\", \"evolution\", \"specie\", \"chain\", \"regression\", \"expression\", \"point\", \"functional\", \"order\", \"component\", \"kernel\", \"view\", \"model\", \"error\", \"result\", \"learn\", \"also\", \"weight\", \"show\", \"number\", \"datum\", \"solution\", \"figure\", \"different\", \"use\", \"information\", \"variable\", \"problem\", \"give\", \"matrix\", \"base\", \"function\", \"set\", \"value\", \"estimate\", \"input\", \"method\", \"structure\", \"parameter\", \"borrow\", \"adversary\", \"ard\", \"borrowing\", \"vortex\", \"pascal\", \"rejection\", \"compressible_prior\", \"compressible\", \"asymptotic_variance\", \"dual\", \"convex_max\", \"non_factorial\", \"hmax\", \"scc\", \"subdifferential\", \"dual_objective\", \"ggd\", \"semi_metric\", \"ref\", \"primal\", \"factorial\", \"newton_direction\", \"subgradient\", \"lifelong\", \"mistake\", \"reversible_chain\", \"learner\", \"gsbl\", \"wavelet_coefficient\", \"descent\", \"loss\", \"norm\", \"signal\", \"convex\", \"expand\", \"optimal\", \"class\", \"task\", \"sparse\", \"example\", \"region\", \"program\", \"minimal\", \"problem\", \"function\", \"bind\", \"follow\", \"strategy\", \"guarantee\", \"theorem\", \"set\", \"solution\", \"learn\", \"use\", \"weight\", \"optimization\", \"define\", \"distribution\", \"let\", \"feature\", \"result\", \"method\", \"case\", \"show\", \"consider\", \"give\", \"rate\", \"value\", \"approach\", \"training\", \"also\", \"model\", \"number\", \"writer\", \"pedestrian\", \"pulse\", \"oam\", \"periodic\", \"viola_jone\", \"subject\", \"voltage\", \"axon\", \"pitch\", \"session\", \"face_detection\", \"hand_printe\", \"detect_rate\", \"inverter\", \"axon_circuit\", \"bci\", \"character\", \"configuration\", \"quadratic_programme\", \"cascade_architecture\", \"band\", \"window\", \"csp\", \"auditory\", \"rare_event\", \"cascade\", \"transistor\", \"periodicity\", \"backpropagation\", \"ensemble\", \"music\", \"circuit\", \"net\", \"adaptation\", \"capacity\", \"detection\", \"user\", \"false_positive\", \"segment\", \"adaboost\", \"detector\", \"neural\", \"channel\", \"feature\", \"pattern\", \"classifier\", \"output\", \"rate\", \"training\", \"system\", \"filter\", \"figure\", \"method\", \"network\", \"set\", \"input\", \"weight\", \"use\", \"learn\", \"function\", \"error\", \"time\", \"number\", \"performance\", \"estimate\", \"image\", \"example\", \"result\", \"show\", \"give\", \"datum\", \"navigation\", \"observer\", \"robot\", \"seemore\", \"rigid\", \"direct_connection\", \"surround\", \"dendritic\", \"complex_cell\", \"rat\", \"gram\", \"dts\", \"fire\", \"food\", \"grbf\", \"goal_cell\", \"deep_architecture\", \"firing_rate\", \"lgn\", \"binocular\", \"obstacle\", \"matching\", \"affine_ideal\", \"eep_atch\", \"win\", \"prefix\", \"curvature\", \"novel_views\", \"binocular_disparity\", \"monocular\", \"synaptic\", \"object\", \"cell\", \"patch\", \"stimulus\", \"neuron\", \"shape\", \"word\", \"environment\", \"language\", \"human\", \"text\", \"spike\", \"input\", \"architecture\", \"correlation\", \"model\", \"response\", \"view\", \"fig\", \"performance\", \"position\", \"match\", \"decision\", \"layer\", \"use\", \"level\", \"show\", \"image\", \"learn\", \"task\", \"space\", \"figure\", \"set\", \"base\", \"time\", \"result\", \"information\", \"network\", \"unlabeled_parallel\", \"cross_language\", \"highway_network\", \"cross_lingual\", \"trepan\", \"highway\", \"markov_game\", \"stationary_equilibrium\", \"multilingual\", \"sentiment_classification\", \"fitnet\", \"noop\", \"selective_sample\", \"document_term\", \"text_classification\", \"transform_gate\", \"comprehensible\", \"mij_mij\", \"cl_opca\", \"arxiv_c\", \"nosde_game\", \"cyclic_equilibrium\", \"cifar\", \"cl_kcca\", \"monolingual\", \"coherent\", \"correlated_equilibrium\", \"plain\", \"latent_semantic\", \"decision_tree\", \"player\", \"game\", \"language\", \"deep\", \"layer\", \"document\", \"concept\", \"network\", \"equilibrium\", \"extract\", \"domain\", \"policy\", \"value\", \"train\", \"neural\", \"accuracy\", \"learn\", \"feature\", \"representation\", \"tree\", \"split\", \"use\", \"set\", \"method\", \"training\", \"action\", \"rule\", \"datum\", \"iteration\", \"classification\", \"result\", \"function\", \"propose\", \"first\", \"matrix\", \"postsynaptic\", \"tpost\", \"presynaptic\", \"tmin\", \"spike_train\", \"influence\", \"partial_observation\", \"spiketrain\", \"fm_km\", \"stdp\", \"learnability\", \"ic_influence\", \"voter\", \"tpre\", \"bayesian_binne\", \"psth\", \"eqn\", \"opinion\", \"bin_boundarie\", \"pac_learnability\", \"seed\", \"spike_time\", \"membrane_potential\", \"tmax\", \"fg\", \"epsp\", \"refractoriness\", \"spike\", \"dependent_plasticity\", \"pac_learnable\", \"bin\", \"cascade\", \"mutual_information\", \"rule\", \"time\", \"neuron\", \"interval\", \"function\", \"synaptic\", \"input\", \"model\", \"temporal\", \"learn\", \"give\", \"signal\", \"depend\", \"information\", \"small\", \"neural\", \"output\", \"see\", \"knn_graph\", \"ncut\", \"welfare\", \"rvu_property\", \"regret\", \"hedge\", \"player\", \"bid\", \"trait\", \"recency_bia\", \"oftrl\", \"stacked_density\", \"asthma\", \"dummy_variable\", \"mirror_descent\", \"cheat\", \"kmj\", \"clinical\", \"omd\", \"mti\", \"opponent\", \"union_support\", \"mai\", \"neighborhood_graph\", \"ftrl\", \"adversarial\", \"sim\", \"kj\", \"sencitivity_sencitivity\", \"unweighte\", \"utility\", \"kth\", \"stepsize\", \"hyperplane\", \"game\", \"cut\", \"vol\", \"proposition\", \"task\", \"stack\", \"classification\", \"play\", \"regression\", \"convergence\", \"fast\", \"different\", \"density\", \"dynamic\", \"sum\", \"graph\", \"parameter\", \"result\", \"input\", \"rate\", \"strategy\", \"learn\", \"algorithm\", \"set\", \"use\", \"model\", \"output\", \"show\"], \"Freq\": [676.0, 1631.0, 382.0, 649.0, 423.0, 461.0, 73.0, 378.0, 257.0, 1122.0, 380.0, 558.0, 311.0, 1006.0, 151.0, 150.0, 160.0, 128.0, 163.0, 412.0, 833.0, 82.0, 483.0, 297.0, 318.0, 1213.0, 548.0, 126.0, 237.0, 171.0, 37.60064085252142, 34.25495913884562, 32.518274499737714, 29.85617363383885, 35.06067329710751, 43.4531483038749, 29.182828687850193, 25.994704082743787, 24.532838767531878, 22.819306900107716, 24.250940998933167, 22.699072369497394, 22.692181937012045, 25.394953720588447, 20.06428207218085, 165.8518401864562, 40.22237506478918, 22.83372212691106, 18.362293580819937, 18.378304758659255, 19.464857502188426, 16.58887766935262, 15.777736990526867, 15.73273605101882, 44.962785944791314, 77.98608996453314, 15.691874250708388, 112.38528748387816, 14.747632403648662, 13.99929641667021, 71.78629667875455, 89.56664939058948, 171.50388355786308, 156.73475748270835, 86.84574232167984, 398.35810464219725, 203.82072090678872, 155.04988097354342, 809.8790623093215, 359.07695031212, 347.4936754729701, 325.08268805275134, 237.6064761818892, 181.77468959901208, 200.623422453641, 261.7730786316516, 295.9471207566409, 473.2873398447483, 138.04247375625334, 403.4831052768826, 146.79660963843173, 303.603552330947, 194.97283725332457, 273.993861278869, 144.2123056447055, 167.81782222953294, 251.96842807295238, 192.12870324561214, 215.98937680793915, 277.9665623022573, 259.48866417108064, 175.63794786081658, 188.89615608972747, 164.92528153428339, 156.70313698520425, 59.79240382116063, 30.87492815944966, 30.895788537200517, 38.04887927891214, 26.772429677098163, 24.207362772352933, 23.402148193492962, 22.502286115581587, 20.869360031131652, 20.864486613141107, 31.081315724829228, 75.26248394725745, 21.53539049177516, 16.66394885274709, 310.2237047871321, 17.301685755161987, 17.66114936597023, 15.050577654686794, 19.181866906330796, 14.172647831643907, 14.124986778130136, 29.641624848772338, 16.497065830740237, 13.295022831464307, 16.641909160312032, 12.527573806527466, 67.0321067313635, 14.362049018039263, 15.522592110668588, 11.6868573582865, 20.755403752674493, 59.03928646789452, 17.459080540911938, 29.350449054985138, 41.543068757896485, 278.4546462190201, 31.883467083767947, 31.038762952823618, 70.67024256116619, 149.99109813349187, 64.20492964241015, 289.0290412942651, 42.591799326303914, 180.75256222845215, 113.39360543410433, 71.08131368214859, 99.79224936704834, 451.79117800359666, 202.93970897580547, 255.1193866556347, 331.64009942901356, 185.94914242504362, 165.51651610201606, 238.16180093926158, 211.91521318827043, 219.5751618879311, 138.35452030708578, 182.48163743933742, 148.89696394974266, 311.91602135896227, 115.89096418497839, 139.99872483747743, 210.05197594076884, 207.65730751515053, 167.7280309606624, 161.0000206989042, 236.50644289033121, 254.464387284675, 164.52737090773755, 142.0185710773642, 136.90543239177617, 171.2493446773834, 125.75999915457132, 135.41331947887764, 78.88954713196142, 35.57275577000357, 31.85732828052562, 28.703425686753246, 26.964799611540638, 24.449071506105195, 29.589676200368277, 23.43504352096695, 23.415505438215135, 21.90662943168987, 80.7690779056669, 20.229303904821197, 20.913331784543825, 20.88102166752938, 19.412566839450804, 17.69481765027036, 17.696080695665643, 18.383137648858373, 17.55248100355648, 21.913216641892998, 15.99910531211637, 17.562519544294016, 15.858975579529744, 23.57195664826962, 15.062044854340252, 36.51572534281485, 14.292345984000686, 70.35697876266711, 14.20062429803879, 14.190663999051404, 49.11420946814923, 149.24488157594283, 80.6999519403754, 158.70073737112173, 55.92952790514501, 47.105448161846304, 226.14604006302142, 184.75302456351278, 223.1458092342744, 105.00793990970166, 310.343641653893, 102.74123418214137, 49.751877248008995, 40.27378340873182, 323.8545164889878, 391.9307805250201, 73.75701748308687, 248.79344499807863, 79.28337884424171, 65.98428828168065, 116.17551655350181, 379.46364566919993, 157.02350250532865, 339.7721174941659, 354.23373639978536, 171.44467415191804, 96.0121555408668, 145.38736955205704, 209.20586160908553, 135.16597660248706, 141.29688091873962, 210.11797660982165, 217.8354646517567, 138.9265781462502, 189.74926950295094, 130.1673372171078, 171.73590236530285, 118.27057726828795, 143.52318906457154, 126.2648572997388, 132.42159381286638, 133.54770869379135, 169.1084897502243, 138.6909189625277, 23.561518257656406, 26.174089646010042, 20.367438532725448, 19.71409382038835, 19.09221612110957, 18.491039288292324, 20.370804797055197, 26.14695674436423, 11.429893360868052, 15.295753902423984, 10.148591947813319, 12.09304927734695, 9.49105876200569, 8.25668594959614, 8.247770695325237, 8.239263780347347, 8.231777252722422, 13.97862094684725, 39.88179636800607, 7.619650843242225, 7.614756763160406, 12.085737883956048, 32.58787215606867, 8.86646187330392, 11.409695774889554, 6.97661462409564, 31.331451787113863, 6.9612401427462265, 10.154053370637461, 12.712735033423058, 51.113387079208, 16.25833221001656, 30.337799135850826, 47.31897669633787, 21.704011388278744, 17.841717132783, 40.464657846981005, 21.560777394103383, 18.62615074104552, 19.149757856336553, 17.124570097232155, 31.14494673250702, 81.43907061310094, 26.152089099180234, 89.03351779654899, 44.286311742592126, 37.63605930271899, 69.02127176912319, 69.52487671137052, 87.6463588001368, 70.98739873396023, 29.15570020526067, 77.27867761259708, 92.2677124786625, 77.78686185418455, 98.11214465502151, 59.409230278254334, 56.46662856523454, 80.32098416680536, 69.70894094781056, 66.73787531296638, 54.36460480886857, 54.887854281618544, 53.97702353138416, 41.211821046725156, 43.892657915982745, 39.87567220037002, 41.975233016350145, 42.38887058082069, 42.421345998363336, 41.88593299218089, 40.03493374223588, 26.614073997734643, 14.10476172926013, 34.00377833213336, 12.510604987254654, 12.486940163602185, 11.266281700291836, 16.61448616664099, 9.918305663507246, 9.90574238593959, 26.094565492909915, 14.782214888717096, 8.276956311523348, 21.486289503176682, 12.400375968397041, 7.574174847533698, 10.152026630473843, 7.109029811456618, 12.876142919916123, 6.996191754165824, 6.9949264428509865, 9.423972438200595, 21.415800547690424, 6.406785076995824, 5.913685187627823, 13.404010701658368, 5.8894764019209305, 7.094752805989022, 5.8388909761335, 5.821426330187431, 5.813082279639526, 18.389672262248922, 81.4674542329525, 65.37588575529259, 32.22445523190158, 32.95222088447066, 56.645962458108606, 31.59372723287592, 51.77240352115654, 27.08257416435594, 33.779987242109854, 26.982701360790585, 19.026300479499607, 17.464729691102836, 76.27911142116986, 23.054115284210457, 30.61902640847163, 144.77721908053135, 28.46614869197716, 39.29107427475673, 29.343111449835835, 45.87558991237836, 25.8619979234415, 24.85716259093619, 23.054920759162986, 30.208983320068423, 60.11295200404995, 29.16521872837365, 45.41066489734219, 35.99671521693933, 43.827694969091354, 34.22139360664184, 32.57709186158999, 31.37434569949233, 32.56299528860231, 29.588804149910626, 29.884807820460573, 30.052118215041745, 28.506943181444214, 29.105111111689514, 16.039555092964374, 19.180893295691547, 13.792427573546, 13.814432678097052, 11.992506196510812, 8.425367387980275, 7.518723742054111, 7.071416362575347, 6.659003053561895, 6.21484406048227, 6.198277831617827, 6.185723559032483, 8.369151126992277, 5.7656175398554215, 7.558872977786901, 5.3089313289315125, 5.303221469467514, 4.87330330662156, 4.870920307574338, 4.862034134236558, 4.843513418513938, 4.842247954819205, 9.71419066978553, 4.4240401311842446, 4.423636491902303, 4.390372687769241, 4.847128717379756, 9.722833350453772, 4.871786059288254, 7.535810120133768, 16.016902420095054, 30.28951062897468, 32.010687873054856, 20.36785285920579, 41.70287256555575, 19.590283891941752, 16.467217239499373, 93.76450627931169, 9.679959440476182, 15.239258397742914, 18.627992134589842, 15.383634714308329, 44.908950145438354, 26.349092321640153, 31.00516263948934, 18.84636054975315, 49.82447892098565, 29.002858708322872, 21.58066279143591, 19.74050403257609, 15.367450742753055, 40.73445945485566, 38.281456701508546, 30.83689611383451, 25.97833938655772, 13.723897041707865, 17.550309288417008, 25.95727334334152, 18.42155747843467, 17.57758046740532, 20.21202104163549, 20.265999613717767, 17.418680118558687, 18.043258888797293, 16.466627271597552, 4.997219574122693, 3.969098830267711, 3.305390642184046, 3.122070532499422, 6.229747466896188, 30.406011532418304, 3.2225438503942443, 2.7000592001967845, 2.4898503722753746, 2.4779602105642424, 4.389506035773089, 2.600518284631458, 2.395658868331453, 2.0756733096079922, 2.0697581283289943, 2.0684794134281757, 2.699804037790923, 2.99082764744408, 1.858018906546718, 1.9910157065693124, 4.527460069475884, 1.8122014340448493, 1.6562877697310883, 1.648272506057091, 1.9641930286594134, 1.63010604585093, 1.84422010681677, 9.031311665522985, 1.3735232649588953, 1.3700299493819479, 3.44281983671756, 8.38396841558544, 4.1470076971677345, 9.025026948700573, 12.16582767905369, 6.14545098107354, 4.650225408569021, 9.76053272873979, 3.054316350272247, 5.897581169023293, 7.289403555416426, 3.5582960654453037, 5.130392288158885, 4.696268143900183, 3.902037273183181, 3.4672263095248566, 3.733448655845152, 3.6557591055826935, 3.3388534935329415, 3.2567300973238074, 3.1564425632057214, 5.474120139044315, 4.177368807210272, 3.85242207068027, 3.113984072878123, 8.706397239526646, 2.7436660212919977, 12.880245871874127, 2.0047790163171433, 2.4873050334292115, 1.82011282534768, 1.635190779153688, 1.6556264879841893, 1.4219624054536757, 1.421487670544899, 1.265973331673885, 1.4749235319353546, 1.2373568491988682, 1.237212179165393, 1.0819935799740703, 1.0818496210086772, 1.0816860753497441, 1.0529732108282968, 1.0380444010825836, 2.0039316817332318, 0.8971305524309107, 1.061729755691831, 0.8695182273732327, 0.8693432399824296, 0.8693582370547112, 0.86908318299196, 5.660106589514984, 1.5992639996520188, 1.0798551396803282, 2.865795713698182, 8.037487478813553, 4.024091488526231, 1.3973383763332157, 3.018134681083776, 12.230546843613359, 3.271053840857931, 6.331937676480453, 2.4753086684549777, 7.045161200083603, 5.322561795128001, 4.40626860430415, 6.81644188499753, 4.055843651959164, 4.061546159409143, 3.7193695968190457, 5.358164327584133, 5.6258041480835415, 5.78334477241895, 4.361339961450547, 4.05121033233478, 3.1888789347120885, 4.423710716508093, 3.7005278440588896, 4.350755131262267, 4.145845219844528, 3.5908987285398553, 3.2565852860891367, 3.2086794658174207], \"Total\": [676.0, 1631.0, 382.0, 649.0, 423.0, 461.0, 73.0, 378.0, 257.0, 1122.0, 380.0, 558.0, 311.0, 1006.0, 151.0, 150.0, 160.0, 128.0, 163.0, 412.0, 833.0, 82.0, 483.0, 297.0, 318.0, 1213.0, 548.0, 126.0, 237.0, 171.0, 41.43734882852699, 37.93546412754704, 36.13272312386765, 33.44949763595444, 39.52966244030848, 49.55281352498348, 33.41908531437624, 29.803672361646992, 28.156772251216633, 26.398612967015136, 28.15794862440785, 26.371628290601645, 26.372711937744054, 29.635412857134497, 23.712456722972764, 196.22316702293816, 47.80283788327749, 27.21205984963646, 21.910958011450564, 21.95145730699961, 23.28168830363166, 20.122785462828144, 19.300302794244097, 19.261500364799215, 55.196210310023275, 95.76071055069514, 19.28262530406876, 139.25808909769813, 18.367293030129456, 17.499118207326088, 92.98554124552038, 117.01701924640966, 231.7804695959607, 226.3161525620925, 121.17072050580329, 642.5477672038511, 307.75531105048225, 239.37131159317212, 1631.2493389787865, 676.217014009224, 688.0564544884297, 649.5967579227781, 445.8799646456467, 334.0266572365691, 383.7384934995609, 548.5017292351138, 709.1930893680344, 1326.9008116062398, 266.9823143668243, 1213.5499758441708, 299.50095811159844, 833.9027680491034, 448.780232260395, 740.5002334432104, 307.4357859845084, 399.8058232473141, 786.7690366036445, 521.2519083832541, 664.5596125633482, 1122.2939970679915, 1006.1913430608881, 558.4347383044413, 755.1434396683221, 558.5879895949648, 546.2498251008603, 66.54213512935814, 34.483543857292304, 34.51579411246004, 43.09266286574572, 30.389286500996224, 27.790187123424204, 27.00937330407181, 26.148433176294432, 24.453745749952606, 24.46802763486673, 37.246429053490616, 90.25480588358704, 26.045147238197707, 20.243597595021964, 378.4406202042301, 21.10677947602065, 21.73994729258062, 18.569636588941037, 23.87476649083886, 17.705782379225585, 17.715324403160434, 37.30022633109598, 20.82139482481308, 16.867805288189757, 21.128831102343955, 16.038692017468634, 86.53736782438976, 18.567861501085805, 20.151407368861943, 15.192080895196048, 27.01102843038684, 80.92784295039776, 22.77460667535813, 39.623850273293186, 57.651743746355336, 461.4751096553835, 43.727223579462056, 42.44416260902812, 107.88636918388724, 257.6988610756718, 97.71625588753598, 561.1422420273174, 62.03521162072084, 396.71335393524276, 222.84055605675445, 130.54727349387807, 203.92750625944385, 1631.2493389787865, 546.2498251008603, 755.1434396683221, 1122.2939970679915, 530.3727685649653, 464.16743313147185, 786.7690366036445, 664.5596125633482, 709.1930893680344, 362.05678230763306, 558.5879895949648, 412.3443499500019, 1326.9008116062398, 283.27217426601936, 382.4767234858108, 745.2804751379136, 740.5002334432104, 521.2519083832541, 490.6328916096487, 1006.1913430608881, 1213.5499758441708, 558.4347383044413, 448.780232260395, 423.5465355285984, 833.9027680491034, 358.70623512280974, 548.5017292351138, 84.87765467780184, 39.38293762705756, 35.725199934573425, 32.30542660626541, 30.621338619267895, 28.0398890724014, 34.06349840404333, 27.230369385267934, 27.230178070247792, 25.51128716301627, 94.8056633299438, 23.796476118686734, 24.661010978523212, 24.676008233547314, 22.957977632958325, 21.241620466567092, 21.244645233868862, 22.117160256913337, 21.26416492390157, 26.695104438236456, 19.540480926228074, 21.495766991286512, 19.5396306153751, 29.134680783709914, 18.63127349128166, 45.18238850342053, 17.84514478396829, 88.1258097111381, 17.846869844359226, 17.85456581540306, 61.96997216796853, 196.90767184059155, 112.3604049873767, 237.282509569882, 78.54817184882481, 65.01433421107728, 384.6068901949867, 307.19006047974176, 382.35004901726825, 164.16819066714083, 571.6811562558336, 169.4487956520755, 72.37821575563454, 56.17281655866582, 745.2804751379136, 1006.1913430608881, 121.50315590917717, 566.9280585843594, 134.2549271948709, 105.89927332117341, 231.74968625776657, 1213.5499758441708, 362.05678230763306, 1122.2939970679915, 1326.9008116062398, 464.16743313147185, 194.04752696606135, 382.0800312765465, 688.0564544884297, 352.07795204714654, 380.85957140976853, 755.1434396683221, 833.9027680491034, 392.9726868561656, 786.7690366036445, 367.9313186979341, 740.5002334432104, 318.64603795002637, 558.4347383044413, 389.0657661346892, 483.3431287348999, 530.3727685649653, 1631.2493389787865, 664.5596125633482, 27.42993141725621, 30.852486950054285, 24.1736049936919, 23.564942382775552, 22.90061245839892, 22.263721708436776, 25.40889030294382, 32.99500921231562, 15.159199329456694, 20.7488370883133, 13.885973452356529, 16.658225812780938, 13.237744611229221, 11.945619521386982, 11.941983050257349, 11.940919384655135, 11.952600910892192, 20.36622732832354, 58.98030786269367, 11.303346997117904, 11.307215624548304, 18.139270744765874, 49.36689027761195, 13.439014648722585, 17.30044631000135, 10.66297284960213, 47.947390885745286, 10.65398899264445, 15.606119225478086, 19.857208784657846, 81.04296984167414, 26.10625615002593, 50.938442017865356, 83.2480875374743, 36.6444140267084, 29.81340116153989, 78.45010703768547, 37.53452125736823, 33.695537956283346, 35.024579038088305, 30.36339828632666, 74.86998988186208, 311.815980637236, 58.34636159517448, 380.85957140976853, 133.16502200345073, 104.87532118638495, 297.14509002657644, 318.64603795002637, 483.3431287348999, 347.86859592414714, 78.0145036986837, 558.5879895949648, 833.9027680491034, 676.217014009224, 1213.5499758441708, 423.5465355285984, 464.16743313147185, 1326.9008116062398, 1122.2939970679915, 1006.1913430608881, 546.2498251008603, 649.5967579227781, 664.5596125633482, 312.2072177633599, 448.780232260395, 365.91595000228796, 571.6811562558336, 755.1434396683221, 786.7690366036445, 740.5002334432104, 709.1930893680344, 31.54282662435281, 18.17188345930581, 44.037337096632, 16.28770550566995, 16.296274515272408, 15.049274887702182, 23.082776974916158, 13.950854627142967, 13.952881755209912, 36.812391296649594, 21.329805583096842, 12.064326317645163, 31.598312692855174, 18.798421182591234, 11.515198362350656, 15.492291411107548, 10.854179969373495, 19.94498629590329, 10.904930200834956, 10.905006603303287, 14.742337132435413, 33.800408068472564, 10.298261318948102, 9.647504670757153, 21.941852662826484, 9.653572250210807, 11.746846807939058, 9.682513107010235, 9.690568882484754, 9.69288497283508, 31.091348957253793, 151.75914986192754, 126.3491370018835, 64.7177934999524, 66.99086439802906, 128.98929291028563, 70.20965594186475, 136.2551944469822, 62.55428244268542, 90.9357470538201, 68.61360797220007, 42.5962145797764, 37.765861989316, 423.5465355285984, 60.142723389066454, 98.86742294188387, 1631.2493389787865, 89.65425891843212, 203.92750625944385, 114.38502773750943, 312.2072177633599, 90.90462052430888, 84.24411286330991, 71.28325006565343, 160.25248887857867, 1326.9008116062398, 156.3639433732431, 786.7690366036445, 365.91595000228796, 1122.2939970679915, 382.35004901726825, 363.42252991656744, 558.5879895949648, 1213.5499758441708, 490.6328916096487, 649.5967579227781, 755.1434396683221, 283.27217426601936, 676.217014009224, 20.128483962041706, 24.50480702241822, 17.814503442846057, 17.845426705467705, 16.006387118436557, 12.381715323138826, 11.517348363576398, 11.06302584357918, 10.582150361929827, 10.12567511398962, 10.115475602610053, 10.147714245343, 13.948238809471853, 9.671909352083459, 12.959125599053113, 9.20828094564682, 9.209440523443368, 8.763567854729741, 8.763968094340632, 8.755930882937232, 8.788404209219458, 8.789371662307628, 18.217048511216124, 8.310399517385768, 8.311529456569195, 8.32829568667813, 9.214105486991414, 18.628935274851177, 9.3704084864658, 14.783858910143021, 34.726298187280236, 82.09771058843245, 90.9357470538201, 59.28697568064847, 160.25248887857867, 63.02022040450541, 50.18948206540698, 676.217014009224, 26.248060235572527, 61.28092842400488, 87.65691581136024, 63.333863686181715, 558.4347383044413, 200.96451180333312, 311.815980637236, 122.22511746107126, 1122.2939970679915, 380.85957140976853, 189.37771610154644, 152.5016431078528, 81.14625194879459, 1326.9008116062398, 1213.5499758441708, 833.9027680491034, 483.3431287348999, 62.369003694484896, 150.29938968088052, 709.1930893680344, 200.82217688053524, 163.34216220938893, 755.1434396683221, 1006.1913430608881, 249.13443754198323, 393.4812432395, 521.2519083832541, 9.286597034366704, 8.136830742389789, 7.581774461655591, 7.294684809257797, 14.786109096655938, 73.76558806312084, 7.845110840741598, 6.86646858578427, 6.648497507371446, 6.6761589713952, 11.983958061294079, 7.167575073753136, 6.9336295170136655, 6.188225335210947, 6.214580357828026, 6.217391818600086, 8.551289843973562, 9.63345102819437, 6.001064652710172, 6.4525078860023335, 15.004606814004608, 6.131842295934939, 5.753530390568009, 5.782677443966573, 7.3753087174315715, 6.437466471348736, 7.323175228449394, 37.765861989316, 5.751231425399967, 5.772118996437725, 14.946662488894559, 47.947390885745286, 32.39975136678834, 150.29938968088052, 649.5967579227781, 128.98929291028563, 87.7304939547839, 1006.1913430608881, 31.091348957253793, 423.5465355285984, 1631.2493389787865, 87.88269002581494, 1122.2939970679915, 740.5002334432104, 237.282509569882, 127.8408622042705, 283.27217426601936, 251.94161617841934, 311.815980637236, 297.14509002657644, 334.77198018740467, 10.111862735981191, 8.74699171206355, 8.166375163768349, 7.379679587493031, 20.81989860063701, 6.992392835875346, 34.726298187280236, 6.211971498307729, 7.900416618073382, 6.017678561345638, 5.82198903552436, 6.644599933141343, 5.730427744619738, 5.731886332159473, 5.431261529043976, 6.430995167819364, 5.534074717163598, 5.535429673820964, 5.233386269987165, 5.233544402302969, 5.234263936412697, 5.337531995037304, 5.393525931831857, 10.449533077861439, 5.038159067738142, 6.155015717467748, 5.137412956417922, 5.137892251315563, 5.137997831885695, 5.1396117787211795, 34.27209993614647, 9.898811041182386, 6.580933069003645, 20.22357871342482, 82.09771058843245, 36.407724044517295, 9.511984251996594, 33.108464395595334, 382.35004901726825, 41.404538160923764, 163.34216220938893, 28.8920595782416, 257.6988610756718, 171.2204676611189, 124.23082368106988, 412.3443499500019, 139.6252668882226, 142.52522721697122, 115.40013188655024, 461.4751096553835, 548.5017292351138, 755.1434396683221, 423.5465355285984, 318.64603795002637, 134.2549271948709, 1122.2939970679915, 364.6652768036969, 1213.5499758441708, 1326.9008116062398, 1631.2493389787865, 297.14509002657644, 786.7690366036445], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.1789, -7.2721, -7.3241, -7.4096, -7.2489, -7.0343, -7.4324, -7.5481, -7.6059, -7.6783, -7.6175, -7.6836, -7.6839, -7.5714, -7.807, -5.6949, -7.1115, -7.6777, -7.8957, -7.8948, -7.8373, -7.9972, -8.0474, -8.0502, -7.0001, -6.4494, -8.0528, -6.084, -8.1149, -8.1669, -6.5323, -6.311, -5.6613, -5.7514, -6.3418, -4.8186, -5.4887, -5.7622, -4.1091, -4.9224, -4.9552, -5.0219, -5.3353, -5.6032, -5.5045, -5.2385, -5.1158, -4.6462, -5.8784, -4.8058, -5.8169, -5.0902, -5.5331, -5.1928, -5.8347, -5.6831, -5.2766, -5.5478, -5.4307, -5.1784, -5.2472, -5.6375, -5.5648, -5.7005, -5.7516, -6.5763, -7.2373, -7.2366, -7.0283, -7.3798, -7.4805, -7.5144, -7.5536, -7.6289, -7.6292, -7.2306, -6.3462, -7.5975, -7.854, -4.9299, -7.8164, -7.7958, -7.9558, -7.7132, -8.0159, -8.0193, -7.278, -7.864, -8.0798, -7.8553, -8.1393, -6.462, -8.0026, -7.9249, -8.2087, -7.6344, -6.589, -7.8073, -7.2879, -6.9405, -5.0379, -7.2051, -7.232, -6.4092, -5.6566, -6.5051, -5.0007, -6.9155, -5.4701, -5.9363, -6.4034, -6.0641, -4.554, -5.3543, -5.1255, -4.8632, -5.4417, -5.5581, -5.1943, -5.311, -5.2755, -5.7374, -5.4606, -5.6639, -4.9245, -5.9146, -5.7256, -5.3198, -5.3313, -5.5449, -5.5858, -5.2012, -5.128, -5.5641, -5.7112, -5.7479, -5.5241, -5.8328, -5.7589, -6.2933, -7.0897, -7.2, -7.3043, -7.3668, -7.4647, -7.2739, -7.5071, -7.5079, -7.5745, -6.2697, -7.6542, -7.6209, -7.6225, -7.6954, -7.788, -7.788, -7.7499, -7.7961, -7.5742, -7.8888, -7.7955, -7.8976, -7.5013, -7.9491, -7.0636, -8.0016, -6.4077, -8.008, -8.0087, -6.7672, -5.6557, -6.2706, -5.5943, -6.6372, -6.8089, -5.2401, -5.4423, -5.2535, -6.0073, -4.9236, -6.0291, -6.7543, -6.9656, -4.881, -4.6902, -6.3605, -5.1447, -6.2883, -6.4719, -5.9062, -4.7226, -5.6049, -4.833, -4.7914, -5.517, -6.0968, -5.6819, -5.318, -5.7548, -5.7104, -5.3136, -5.2776, -5.7274, -5.4156, -5.7925, -5.5154, -5.8883, -5.6948, -5.8229, -5.7753, -5.7669, -5.5308, -5.7291, -6.5104, -6.4053, -6.6561, -6.6887, -6.7207, -6.7527, -6.6559, -6.4063, -7.2338, -6.9424, -7.3527, -7.1774, -7.4197, -7.559, -7.5601, -7.5611, -7.562, -7.0325, -5.9841, -7.6393, -7.6399, -7.178, -6.1861, -7.4877, -7.2356, -7.7275, -6.2254, -7.7297, -7.3521, -7.1274, -5.736, -6.8814, -6.2576, -5.8131, -6.5925, -6.7885, -5.9696, -6.5991, -6.7455, -6.7177, -6.8295, -6.2314, -5.2702, -6.4061, -5.181, -5.8793, -6.0421, -5.4356, -5.4283, -5.1967, -5.4075, -6.2974, -5.3226, -5.1453, -5.316, -5.0839, -5.5856, -5.6364, -5.284, -5.4257, -5.4692, -5.6743, -5.6647, -5.6815, -5.9513, -5.8883, -5.9843, -5.9329, -5.9231, -5.9224, -5.9351, -5.9803, -6.1973, -6.8323, -5.9523, -6.9522, -6.9541, -7.057, -6.6685, -7.1844, -7.1857, -6.2171, -6.7854, -7.3653, -6.4114, -6.9611, -7.454, -7.1611, -7.5174, -6.9234, -7.5334, -7.5336, -7.2355, -6.4147, -7.6214, -7.7015, -6.8832, -7.7056, -7.5194, -7.7142, -7.7172, -7.7187, -6.567, -5.0786, -5.2986, -6.0061, -5.9837, -5.442, -6.0258, -5.5319, -6.1799, -5.9589, -6.1836, -6.533, -6.6186, -5.1444, -6.3409, -6.0572, -4.5036, -6.1301, -5.8078, -6.0997, -5.6529, -6.226, -6.2656, -6.3409, -6.0707, -5.3826, -6.1058, -5.663, -5.8954, -5.6985, -5.9459, -5.9952, -6.0328, -5.9956, -6.0914, -6.0814, -6.0759, -6.1286, -6.1079, -6.1472, -5.9683, -6.2981, -6.2965, -6.4379, -6.791, -6.9048, -6.9662, -7.0263, -7.0953, -7.0979, -7.1, -6.7977, -7.1703, -6.8995, -7.2528, -7.2539, -7.3384, -7.3389, -7.3408, -7.3446, -7.3448, -6.6486, -7.4352, -7.4353, -7.4428, -7.3438, -6.6477, -7.3388, -6.9026, -6.1486, -5.5114, -5.4562, -5.9083, -5.1917, -5.9472, -6.1208, -4.3814, -6.6522, -6.1983, -5.9976, -6.1889, -5.1176, -5.6508, -5.4881, -5.9859, -5.0137, -5.5548, -5.8504, -5.9395, -6.19, -5.2151, -5.2773, -5.4935, -5.665, -6.3031, -6.0571, -5.6658, -6.0087, -6.0556, -5.9159, -5.9133, -6.0647, -6.0294, -6.1209, -6.2126, -6.4429, -6.6259, -6.683, -5.9921, -4.4068, -6.6513, -6.8282, -6.9092, -6.914, -6.3422, -6.8658, -6.9478, -7.0912, -7.094, -7.0946, -6.8283, -6.7259, -7.202, -7.1328, -6.3113, -7.2269, -7.3169, -7.3217, -7.1464, -7.3328, -7.2094, -5.6208, -7.5041, -7.5066, -6.5852, -5.6951, -6.3991, -5.6215, -5.3228, -6.0057, -6.2845, -5.5431, -6.7049, -6.0469, -5.835, -6.5522, -6.1863, -6.2747, -6.46, -6.5781, -6.5041, -6.5252, -6.6158, -6.6407, -6.672, -6.0057, -6.2761, -6.3571, -6.5699, -5.5417, -6.6965, -5.1501, -7.0102, -6.7946, -7.1069, -7.214, -7.2016, -7.3537, -7.3541, -7.4699, -7.3172, -7.4928, -7.4929, -7.627, -7.6271, -7.6272, -7.6541, -7.6684, -7.0106, -7.8143, -7.6459, -7.8456, -7.8458, -7.8458, -7.8461, -5.9723, -7.2362, -7.6289, -6.6529, -5.6216, -6.3135, -7.3712, -6.6011, -5.2018, -6.5206, -5.8602, -6.7994, -5.7534, -6.0338, -6.2227, -5.7864, -6.3056, -6.3042, -6.3922, -6.0271, -5.9784, -5.9508, -6.233, -6.3067, -6.5461, -6.2188, -6.3973, -6.2354, -6.2837, -6.4274, -6.5251, -6.5399], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1753, 1.1704, 1.1671, 1.1589, 1.1525, 1.1411, 1.137, 1.1358, 1.1347, 1.1268, 1.1231, 1.1225, 1.1222, 1.1181, 1.1054, 1.1043, 1.0998, 1.0971, 1.0958, 1.0948, 1.0934, 1.0794, 1.071, 1.0701, 1.0674, 1.0672, 1.0664, 1.0581, 1.053, 1.0494, 1.0137, 1.0052, 0.9713, 0.9051, 0.9394, 0.7944, 0.8604, 0.8382, 0.5723, 0.6395, 0.5894, 0.5802, 0.6431, 0.664, 0.624, 0.5328, 0.3986, 0.2416, 0.6129, 0.1713, 0.5594, 0.2621, 0.4388, 0.2783, 0.5155, 0.4044, 0.1339, 0.2744, 0.1486, -0.1231, -0.0827, 0.1158, -0.1132, 0.0526, 0.0238, 1.3043, 1.3007, 1.3004, 1.2868, 1.2845, 1.2732, 1.2679, 1.2611, 1.2527, 1.2519, 1.2303, 1.2296, 1.2211, 1.2167, 1.2125, 1.2125, 1.2035, 1.2011, 1.1924, 1.1887, 1.1848, 1.1814, 1.1784, 1.1732, 1.1725, 1.1642, 1.1558, 1.1544, 1.1503, 1.1489, 1.1478, 1.0959, 1.1455, 1.1111, 1.0836, 0.9061, 1.0954, 1.0983, 0.9882, 0.87, 0.9913, 0.7478, 1.0352, 0.6252, 0.7357, 0.8033, 0.6966, 0.1274, 0.4211, 0.3261, 0.1922, 0.3631, 0.3801, 0.2163, 0.2683, 0.2388, 0.4493, 0.2925, 0.3926, -0.0366, 0.5175, 0.4062, 0.1448, 0.1398, 0.2774, 0.297, -0.0367, -0.1509, 0.1892, 0.2607, 0.2819, -0.1718, 0.3631, 0.0124, 1.344, 1.3154, 1.3026, 1.2989, 1.29, 1.2801, 1.2763, 1.267, 1.2662, 1.2648, 1.2569, 1.2547, 1.2523, 1.2501, 1.2494, 1.2344, 1.2344, 1.2322, 1.2253, 1.2197, 1.2172, 1.2151, 1.2084, 1.2053, 1.2045, 1.2042, 1.1951, 1.192, 1.1886, 1.1875, 1.1846, 1.14, 1.0862, 1.0149, 1.0775, 1.0949, 0.8861, 0.9087, 0.8786, 0.9703, 0.8062, 0.9168, 1.0423, 1.0844, 0.5837, 0.4743, 0.918, 0.5935, 0.8904, 0.9441, 0.7266, 0.2546, 0.5817, 0.2223, 0.0965, 0.4212, 0.7135, 0.4509, 0.2266, 0.4598, 0.4256, 0.1379, 0.0748, 0.3773, -0.0051, 0.3781, -0.0442, 0.426, 0.0585, 0.2918, 0.1224, 0.038, -0.8494, -0.1497, 2.2564, 2.244, 2.2371, 2.23, 2.2265, 2.2228, 2.1874, 2.1758, 2.1261, 2.1035, 2.0949, 2.0882, 2.0757, 2.0391, 2.0383, 2.0374, 2.0355, 2.0321, 2.0171, 2.0141, 2.0131, 2.0024, 1.9931, 1.9925, 1.9922, 1.9842, 1.9829, 1.9829, 1.9786, 1.9625, 1.9475, 1.9349, 1.8902, 1.8435, 1.8847, 1.895, 1.7464, 1.854, 1.8156, 1.8047, 1.8357, 1.5313, 1.0659, 1.606, 0.955, 1.3075, 1.3836, 0.9486, 0.886, 0.701, 0.8191, 1.4242, 0.4304, 0.207, 0.2459, -0.1068, 0.4442, 0.3018, -0.3961, -0.3704, -0.3047, 0.1011, -0.0626, -0.1021, 0.3835, 0.0836, 0.1918, -0.2031, -0.4716, -0.5119, -0.4639, -0.4659, 2.4298, 2.3463, 2.3411, 2.3358, 2.3334, 2.3101, 2.2708, 2.2585, 2.2571, 2.2556, 2.233, 2.2229, 2.214, 2.1836, 2.1807, 2.177, 2.1765, 2.1621, 2.1558, 2.1556, 2.1522, 2.1433, 2.125, 2.1102, 2.1068, 2.1055, 2.0954, 2.0939, 2.0901, 2.0884, 2.0745, 1.9776, 1.9408, 1.9023, 1.8902, 1.7768, 1.8011, 1.632, 1.7625, 1.6094, 1.6664, 1.7937, 1.8284, 0.8854, 1.6408, 1.4275, 0.1778, 1.4524, 0.9529, 1.2391, 0.6819, 1.3426, 1.3791, 1.4709, 0.931, -0.4947, 0.9204, -0.2525, 0.2807, -0.6432, 0.1862, 0.1877, -0.2798, -1.0185, -0.2086, -0.4793, -0.6243, 0.3034, -0.5459, 2.9291, 2.9113, 2.9003, 2.9002, 2.8675, 2.7713, 2.7298, 2.7087, 2.693, 2.6681, 2.6664, 2.6612, 2.6454, 2.6389, 2.6171, 2.6055, 2.6043, 2.5694, 2.5689, 2.568, 2.5604, 2.5601, 2.5275, 2.5258, 2.5255, 2.516, 2.5139, 2.506, 2.5021, 2.4824, 2.3824, 2.1591, 2.1121, 2.0878, 1.81, 1.9878, 2.0418, 1.1805, 2.1587, 1.7646, 1.6075, 1.7411, 0.6357, 1.1245, 0.848, 1.2867, 0.0416, 0.5812, 0.9843, 1.1117, 1.4922, -0.3273, -0.3001, -0.1412, 0.2328, 1.6423, 1.0087, -0.1514, 0.7673, 0.927, -0.4644, -0.7488, 0.4958, 0.074, -0.2987, 3.6373, 3.5391, 3.4268, 3.4083, 3.3926, 3.3707, 3.3673, 3.3236, 3.2748, 3.2659, 3.2526, 3.2431, 3.1943, 3.1646, 3.1575, 3.1565, 3.1041, 3.0873, 3.0846, 3.0812, 3.0588, 3.038, 3.0118, 3.0018, 2.9339, 2.8835, 2.878, 2.8263, 2.825, 2.8188, 2.7888, 2.5132, 2.2012, 1.4444, 0.2793, 1.213, 1.3196, -0.3786, 1.9366, -0.0171, -1.1537, 1.0503, -1.131, -0.8036, 0.1492, 0.6496, -0.0721, 0.0241, -0.2798, -0.2565, -0.407, 3.759, 3.6337, 3.6214, 3.5099, 3.5008, 3.4372, 3.3809, 3.2417, 3.217, 3.1769, 3.1028, 2.9831, 2.9789, 2.9784, 2.9164, 2.9002, 2.8747, 2.8744, 2.7964, 2.7963, 2.796, 2.7495, 2.7248, 2.7212, 2.6471, 2.6153, 2.5963, 2.596, 2.596, 2.5954, 2.5718, 2.5498, 2.5653, 2.4187, 2.0489, 2.1702, 2.4547, 1.9775, 0.9303, 1.8344, 1.1225, 1.9155, 0.7732, 0.9017, 1.0336, 0.2702, 0.8339, 0.8147, 0.9378, -0.0831, -0.2071, -0.4992, -0.2032, 0.0076, 0.6326, -1.1635, -0.2178, -1.2583, -1.3958, -1.746, -0.1409, -1.1294]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5], \"Freq\": [0.31090172617017947, 0.2699936043056822, 0.13090598996639136, 0.11454274122059244, 0.00818162437289946, 0.15545086308508974, 0.016033605489331026, 0.11223523842531717, 0.3367057152759515, 0.1282688439146482, 0.17636966038264126, 0.22447047685063434, 0.016033605489331026, 0.09880316991234045, 0.2634751197662412, 0.03293438997078015, 0.5598846295032626, 0.03293438997078015, 0.10915715549673102, 0.027289288874182756, 0.16373573324509655, 0.6003643552320207, 0.027289288874182756, 0.08186786662254827, 0.8434385451349664, 0.042171927256748315, 0.042171927256748315, 0.042171927256748315, 0.042171927256748315, 0.1624691220790924, 0.1624691220790924, 0.3249382441581848, 0.1624691220790924, 0.1624691220790924, 0.1624691220790924, 0.025391706669259797, 0.025391706669259797, 0.9141014400933527, 0.025391706669259797, 0.025391706669259797, 0.09710377014419588, 0.09710377014419588, 0.09710377014419588, 0.09710377014419588, 0.5826226208651752, 0.34552234066372906, 0.27696632069076693, 0.28519304308752236, 0.04387585278269575, 0.0027422407989184843, 0.032906889587021815, 0.0027422407989184843, 0.010968963195673937, 0.2884763492175014, 0.3506967382644135, 0.25265248885715813, 0.05279305737313752, 0.03205292769083349, 0.01885466334754911, 0.0018854663347549112, 0.0037709326695098224, 0.04737814222847673, 0.8054284178841045, 0.04737814222847673, 0.04737814222847673, 0.04737814222847673, 0.056448303019593526, 0.7902762422743094, 0.056448303019593526, 0.056448303019593526, 0.056448303019593526, 0.22361258062957354, 0.3007203670535644, 0.3238527029807617, 0.06939700778159179, 0.05140519094932725, 0.023132335927197264, 0.005140519094932725, 0.0025702595474663627, 0.08313557681208973, 0.16627115362417946, 0.016627115362417948, 0.19952538434901537, 0.3824236533356128, 0.1496440382617615, 0.02799144586542229, 0.02799144586542229, 0.8957262676935133, 0.02799144586542229, 0.02799144586542229, 0.11420830216336104, 0.11420830216336104, 0.11420830216336104, 0.11420830216336104, 0.11420830216336104, 0.5710415108168052, 0.17450704285363228, 0.17450704285363228, 0.17450704285363228, 0.17450704285363228, 0.17450704285363228, 0.17450704285363228, 0.03919833576448078, 0.03919833576448078, 0.862363386818577, 0.03919833576448078, 0.03919833576448078, 0.17340593105194668, 0.05780197701731556, 0.05780197701731556, 0.6358217471904712, 0.05780197701731556, 0.06596654468794032, 0.06596654468794032, 0.06596654468794032, 0.7256319915673436, 0.06596654468794032, 0.08374564535500219, 0.08374564535500219, 0.08374564535500219, 0.6699651628400175, 0.08374564535500219, 0.10071909006391914, 0.10071909006391914, 0.05035954503195957, 0.6546740854154744, 0.05035954503195957, 0.05035954503195957, 0.11025801577922334, 0.05512900788961167, 0.05512900788961167, 0.66154809467534, 0.05512900788961167, 0.26292570719582614, 0.32814758805060473, 0.240505685651996, 0.0733746159616259, 0.06114551330135492, 0.03057275665067746, 0.0020381837767118305, 0.0020381837767118305, 0.03702418374325051, 0.8515562260947619, 0.03702418374325051, 0.03702418374325051, 0.03702418374325051, 0.7691188903938979, 0.05127459269292653, 0.1367322471811374, 0.008545765448821088, 0.025637296346463265, 0.008545765448821088, 0.16091191076809835, 0.16091191076809835, 0.16091191076809835, 0.16091191076809835, 0.16091191076809835, 0.3218238215361967, 0.08366379898861324, 0.08366379898861324, 0.08366379898861324, 0.669310391908906, 0.08366379898861324, 0.16097948940564535, 0.16097948940564535, 0.16097948940564535, 0.16097948940564535, 0.16097948940564535, 0.3219589788112907, 0.26761827283997475, 0.13380913641998737, 0.26761827283997475, 0.06690456820999369, 0.06690456820999369, 0.20071370462998106, 0.1666370982269596, 0.1666370982269596, 0.1666370982269596, 0.1666370982269596, 0.1666370982269596, 0.3332741964539192, 0.13991406126691386, 0.2057559724513439, 0.6090376784559779, 0.01646047779610751, 0.024690716694161268, 0.09170099903443299, 0.09170099903443299, 0.09170099903443299, 0.09170099903443299, 0.6419069932410308, 0.10319311612421979, 0.10319311612421979, 0.10319311612421979, 0.10319311612421979, 0.6191586967453186, 0.023563327799195923, 0.023563327799195923, 0.930751448068239, 0.011781663899597962, 0.011781663899597962, 0.030954551759612335, 0.030954551759612335, 0.8976820010287577, 0.030954551759612335, 0.030954551759612335, 0.03354196304479435, 0.16770981522397177, 0.0670839260895887, 0.6037553348062984, 0.03354196304479435, 0.03354196304479435, 0.03354196304479435, 0.041712384408274406, 0.08342476881654881, 0.020856192204137203, 0.6465419583282533, 0.020856192204137203, 0.16684953763309762, 0.08843910235769892, 0.08843910235769892, 0.08843910235769892, 0.7075128188615913, 0.08843910235769892, 0.26464943615296527, 0.274828260620387, 0.3537141502429055, 0.0508941223371087, 0.035625885635976094, 0.015268236701132611, 0.002544706116855435, 0.00508941223371087, 0.8712578963424451, 0.03788077810184544, 0.03788077810184544, 0.03788077810184544, 0.03788077810184544, 0.8523348174304267, 0.03551395072626778, 0.03551395072626778, 0.03551395072626778, 0.03551395072626778, 0.23743731624817338, 0.05540204045790712, 0.11871865812408669, 0.05540204045790712, 0.514447518537709, 0.007914577208272447, 0.028999339631055002, 0.8989795285627051, 0.028999339631055002, 0.028999339631055002, 0.028999339631055002, 0.05561406918582349, 0.6580998186989113, 0.24099429980523512, 0.01853802306194116, 0.01853802306194116, 0.017139029284093436, 0.15425126355684093, 0.017139029284093436, 0.44561476138642936, 0.3427805856818687, 0.017139029284093436, 0.14730268653281045, 0.09820179102187364, 0.04910089551093682, 0.6874125371531155, 0.04910089551093682, 0.31099385830796145, 0.15549692915398072, 0.15549692915398072, 0.15549692915398072, 0.15549692915398072, 0.15549692915398072, 0.27446817177445243, 0.05489363435489049, 0.05489363435489049, 0.05489363435489049, 0.05489363435489049, 0.5489363435489049, 0.13742077147834497, 0.03926307756524142, 0.1766838490435864, 0.5889461634786213, 0.01963153878262071, 0.03926307756524142, 0.12033115831651058, 0.12033115831651058, 0.12033115831651058, 0.12033115831651058, 0.12033115831651058, 0.4813246332660423, 0.11410356464507831, 0.11410356464507831, 0.11410356464507831, 0.11410356464507831, 0.11410356464507831, 0.5705178232253916, 0.17578693762313685, 0.12044660540844562, 0.602233027042228, 0.0325531365968772, 0.026042509277501756, 0.03906376391625263, 0.0032553136596877195, 0.0032553136596877195, 0.13468659715547365, 0.11019812494538754, 0.45915885393911476, 0.11632024299790907, 0.03061059026260765, 0.11019812494538754, 0.03673270831512918, 0.15256210726224828, 0.11442158044668621, 0.30512421452449656, 0.36233500474783964, 0.009535131703890518, 0.04767565851945259, 0.180654449415076, 0.180654449415076, 0.180654449415076, 0.180654449415076, 0.180654449415076, 0.180654449415076, 0.1109817439188589, 0.819150967020149, 0.0528484494851709, 0.0026424224742585454, 0.007927267422775636, 0.0026424224742585454, 0.0026424224742585454, 0.10400131441787894, 0.7742320073330988, 0.05777850800993274, 0.011555701601986549, 0.023111403203973098, 0.023111403203973098, 0.12007258599134411, 0.12007258599134411, 0.12007258599134411, 0.12007258599134411, 0.12007258599134411, 0.48029034396537645, 0.7743139313443382, 0.1613154023634038, 0.03226308047268076, 0.010754360157560254, 0.021508720315120508, 0.07166978245383658, 0.07166978245383658, 0.07166978245383658, 0.07166978245383658, 0.7166978245383658, 0.14808794495915434, 0.5070890236480133, 0.20642562024609393, 0.05833767528693959, 0.06731270225416107, 0.004487513483610738, 0.004487513483610738, 0.004487513483610738, 0.10858422913470368, 0.10858422913470368, 0.10858422913470368, 0.10858422913470368, 0.10858422913470368, 0.5429211456735183, 0.036723961092734056, 0.036723961092734056, 0.8446511051328832, 0.036723961092734056, 0.036723961092734056, 0.03672370307767533, 0.03672370307767533, 0.8446451707865325, 0.03672370307767533, 0.03672370307767533, 0.19924493317081837, 0.2789429064391457, 0.13947145321957286, 0.019924493317081838, 0.019924493317081838, 0.3187918930733094, 0.8166690636118347, 0.05444460424078897, 0.05444460424078897, 0.05444460424078897, 0.05444460424078897, 0.05086443439705348, 0.06781924586273798, 0.15259330319116046, 0.6781924586273798, 0.03390962293136899, 0.016954811465684495, 0.016954811465684495, 0.29896884122090267, 0.26635405854225874, 0.3533268123519759, 0.04076847834830491, 0.021743188452429285, 0.010871594226214643, 0.0027178985565536606, 0.005435797113107321, 0.32122327868451156, 0.2686594694452279, 0.3270637019333209, 0.011680846497618603, 0.017521269746427905, 0.02920211624404651, 0.02920211624404651, 0.10184832837862784, 0.12731041047328479, 0.7129382986503948, 0.01273104104732848, 0.01273104104732848, 0.02546208209465696, 0.01273104104732848, 0.0420230287464591, 0.0420230287464591, 0.8404605749291819, 0.0420230287464591, 0.0420230287464591, 0.10852925456647008, 0.10852925456647008, 0.10852925456647008, 0.10852925456647008, 0.10852925456647008, 0.5426462728323505, 0.10852925456647008, 0.3034366539283072, 0.23263476801170221, 0.05057277565471787, 0.0809164410475486, 0.3135512090592508, 0.010114555130943574, 0.010114555130943574, 0.816092018422746, 0.042952211495934, 0.042952211495934, 0.042952211495934, 0.042952211495934, 0.887885861949953, 0.03551543447799812, 0.03551543447799812, 0.03551543447799812, 0.03551543447799812, 0.04080831973437498, 0.04080831973437498, 0.04080831973437498, 0.04080831973437498, 0.08161663946874996, 0.7753580749531246, 0.05603676597397402, 0.05603676597397402, 0.05603676597397402, 0.05603676597397402, 0.05603676597397402, 0.7845147236356362, 0.07441021727698263, 0.14882043455396526, 0.07441021727698263, 0.6696919554928437, 0.07441021727698263, 0.17025845596695008, 0.08512922798347504, 0.08512922798347504, 0.08512922798347504, 0.5959045958843252, 0.19226689346032172, 0.4669338841179242, 0.16480019439456148, 0.027466699065760245, 0.027466699065760245, 0.10986679626304098, 0.11377377569416064, 0.11377377569416064, 0.11377377569416064, 0.11377377569416064, 0.11377377569416064, 0.5688688784708033, 0.8435853456983793, 0.03374341382793517, 0.03374341382793517, 0.03374341382793517, 0.03374341382793517, 0.4173757534267108, 0.3102117086279607, 0.13395505599843757, 0.05640212884144741, 0.03948149018901318, 0.036661383746940814, 0.00282010644207237, 0.004230159663108556, 0.21042811580819717, 0.08417124632327887, 0.26654228002371644, 0.07014270526939906, 0.3226564442392357, 0.042085623161639434, 0.06764133817009796, 0.13528267634019592, 0.06764133817009796, 0.06764133817009796, 0.13528267634019592, 0.5411307053607837, 0.11806977704016755, 0.303607998103288, 0.11806977704016755, 0.01686711100573822, 0.10120266603442932, 0.3373422201147644, 0.09213040532049702, 0.09213040532049702, 0.09213040532049702, 0.09213040532049702, 0.6449128372434791, 0.30098406246403364, 0.24602175540538404, 0.37950164397639025, 0.01570351630247132, 0.0392587907561783, 0.013086263585392768, 0.0026172527170785537, 0.0026172527170785537, 0.07168019642713407, 0.07168019642713407, 0.07168019642713407, 0.07168019642713407, 0.7168019642713407, 0.4870178694407624, 0.2005367697697257, 0.2506709622121571, 0.007162027491775918, 0.014324054983551836, 0.007162027491775918, 0.007162027491775918, 0.028648109967103673, 0.819991117139197, 0.04555506206328872, 0.04555506206328872, 0.04555506206328872, 0.04555506206328872, 0.34417790400767645, 0.21902230255033955, 0.2503112029146738, 0.070400025819752, 0.070400025819752, 0.007822225091083556, 0.023466675273250664, 0.007822225091083556, 0.17387580607234138, 0.17387580607234138, 0.17387580607234138, 0.17387580607234138, 0.17387580607234138, 0.17387580607234138, 0.09682108592427804, 0.01613684765404634, 0.7907055350482707, 0.01613684765404634, 0.03227369530809268, 0.04841054296213902, 0.08371269470031571, 0.08371269470031571, 0.08371269470031571, 0.6697015576025257, 0.08371269470031571, 0.03824086560594334, 0.025493910403962226, 0.3824086560594334, 0.5098782080792446, 0.025493910403962226, 0.012746955201981113, 0.026712972756585317, 0.04006945913487797, 0.46747702324024304, 0.4140510777270724, 0.013356486378292658, 0.026712972756585317, 0.19886291641911127, 0.361348470078629, 0.25949185435176714, 0.06790441048457459, 0.06790441048457459, 0.02425157517306235, 0.00485031503461247, 0.016976102621143647, 0.06644838422196475, 0.06644838422196475, 0.06644838422196475, 0.06644838422196475, 0.7309322264416123, 0.5043190827386318, 0.15696386436821969, 0.30375414493479547, 0.018893798488767183, 0.007266845572602763, 0.004360107343561658, 0.0014533691145205527, 0.0014533691145205527, 0.2856226126228075, 0.206282998005361, 0.12694338338791447, 0.01586792292348931, 0.04760376877046792, 0.31735845846978616, 0.10339220143586092, 0.10339220143586092, 0.10339220143586092, 0.10339220143586092, 0.10339220143586092, 0.6203532086151655, 0.12548924289866942, 0.19393792084339817, 0.262386598788127, 0.022816225981576257, 0.18252980785261005, 0.21675414682497443, 0.0828890046299071, 0.0828890046299071, 0.0828890046299071, 0.0828890046299071, 0.6631120370392568, 0.10547893078072647, 0.010547893078072648, 0.8543793393238844, 0.010547893078072648, 0.010547893078072648, 0.010547893078072648, 0.04707068482394657, 0.04707068482394657, 0.8472723268310384, 0.04707068482394657, 0.04707068482394657, 0.17446263621617436, 0.17446263621617436, 0.17446263621617436, 0.17446263621617436, 0.17446263621617436, 0.17446263621617436, 0.5893693463271861, 0.1964564487757287, 0.05613041393592249, 0.042097810451941865, 0.07717931916189341, 0.007016301741990311, 0.028065206967961245, 0.10365374613718827, 0.10365374613718827, 0.10365374613718827, 0.10365374613718827, 0.6219224768231296, 0.059284535416125814, 0.7706989604096356, 0.059284535416125814, 0.059284535416125814, 0.059284535416125814, 0.20976526444195304, 0.07403479921480695, 0.049356532809871304, 0.6292957933258592, 0.024678266404935652, 0.031972231506811305, 0.07993057876702826, 0.36768066232833, 0.04795834726021696, 0.43162512534195263, 0.015986115753405652, 0.015986115753405652, 0.15534061489107634, 0.15534061489107634, 0.15534061489107634, 0.15534061489107634, 0.15534061489107634, 0.3106812297821527, 0.11694142266791954, 0.23388284533583908, 0.11694142266791954, 0.11694142266791954, 0.11694142266791954, 0.3508242680037586, 0.3809805338090302, 0.07619610676180603, 0.11429416014270906, 0.03809805338090302, 0.03809805338090302, 0.3809805338090302, 0.03809805338090302, 0.2874142796677533, 0.3716248329462033, 0.21784904000294678, 0.0988558668920935, 0.016475977815348916, 0.00366132840341087, 0.00366132840341087, 0.001830664201705435, 0.43451111698443856, 0.3164132236502065, 0.11809789333423203, 0.09804353408879639, 0.024510883522199097, 0.004456524276763472, 0.002228262138381736, 0.002228262138381736, 0.1372142914378424, 0.7318095543351594, 0.04573809714594746, 0.02286904857297373, 0.02286904857297373, 0.02286904857297373, 0.15743041206648417, 0.16617654607017773, 0.542260308229001, 0.07346752563102595, 0.03148608241329683, 0.024489175210341982, 0.001749226800738713, 0.001749226800738713, 0.09228734051971121, 0.07690611709975935, 0.7229175007377379, 0.04614367025985561, 0.03076244683990374, 0.03076244683990374, 0.5448666926936354, 0.20657033953769693, 0.09879451021368114, 0.06286923377234255, 0.038919049478116814, 0.04490659555167325, 0.0029937730367782167, 0.8152733629219521, 0.018117185842710045, 0.05435155752813014, 0.07246874337084018, 0.018117185842710045, 0.018117185842710045, 0.20467423581004257, 0.6549575545921362, 0.09210340611451916, 0.010233711790502129, 0.010233711790502129, 0.020467423581004257, 0.1142280343986755, 0.4079572657095553, 0.08159145314191107, 0.08159145314191107, 0.04895487188514664, 0.2447743594257332, 0.016318290628382214, 0.060030402471357734, 0.12006080494271547, 0.060030402471357734, 0.7203648296562928, 0.060030402471357734, 0.046520787111497736, 0.046520787111497736, 0.8373741680069592, 0.046520787111497736, 0.046520787111497736, 0.02967751995226792, 0.05935503990453584, 0.32645271947494714, 0.5638728790930905, 0.02967751995226792, 0.02967751995226792, 0.35417941132676123, 0.152941109436556, 0.305882218873112, 0.11269344905851494, 0.01609906415121642, 0.01609906415121642, 0.03219812830243284, 0.05513843310348634, 0.20742553405597242, 0.37021519369483685, 0.2336819307719183, 0.05513843310348634, 0.07614355047624304, 0.13558754464562223, 0.27117508929124445, 0.13558754464562223, 0.13558754464562223, 0.13558754464562223, 0.27117508929124445, 0.2273024758071026, 0.23604487872276042, 0.2273024758071026, 0.03496961166263117, 0.253529684554076, 0.017484805831315585, 0.2953876615206897, 0.3258215417985789, 0.1521694013894462, 0.13784757537632186, 0.05549707580085685, 0.02506319552296761, 0.0017902282516405435, 0.003580456503281087, 0.23072632839557122, 0.1025450348424761, 0.025636258710619024, 0.37172575130397584, 0.24354445775088074, 0.012818129355309512, 0.031647259450853976, 0.15823629725426988, 0.031647259450853976, 0.031647259450853976, 0.6645924484679334, 0.06329451890170795, 0.05013791361718812, 0.10027582723437624, 0.05013791361718812, 0.05013791361718812, 0.6517928770234455, 0.10027582723437624, 0.27955589215480436, 0.27447305775198977, 0.284638726557619, 0.0609940128337755, 0.05082834402814625, 0.04574550962533162, 0.0025414172014073125, 0.0025414172014073125, 0.09885842636425067, 0.09885842636425067, 0.09885842636425067, 0.09885842636425067, 0.09885842636425067, 0.593150558185504, 0.15040992327834393, 0.15040992327834393, 0.15040992327834393, 0.15040992327834393, 0.15040992327834393, 0.30081984655668786, 0.2575282662222919, 0.22401431376870595, 0.4392091663654156, 0.024694491281589633, 0.03704173692238445, 0.012347245640794816, 0.0017638922343992595, 0.005291676703197778, 0.053195956739498736, 0.15958787021849621, 0.053195956739498736, 0.053195956739498736, 0.6383514808739849, 0.19848519797707487, 0.19848519797707487, 0.19848519797707487, 0.19848519797707487, 0.19848519797707487, 0.19848519797707487, 0.7179952354565167, 0.13204510077361226, 0.08252818798350765, 0.024758456395052298, 0.024758456395052298, 0.008252818798350766, 0.008252818798350766, 0.25740630923349833, 0.23554168064995795, 0.38958792748853804, 0.06658773250441849, 0.02087078182974311, 0.019876935075945817, 0.009938467537972909, 0.000993846753797291, 0.20955840498265946, 0.6931547241734121, 0.03223975461271684, 0.01611987730635842, 0.04835963191907526, 0.01611987730635842, 0.024361215260024556, 0.024361215260024556, 0.45068248231045427, 0.012180607630012278, 0.012180607630012278, 0.3654182289003683, 0.09744486104009822, 0.11079742404962076, 0.8309806803721557, 0.03323922721488623, 0.011079742404962076, 0.011079742404962076, 0.028972243742727756, 0.8981395560245604, 0.028972243742727756, 0.028972243742727756, 0.028972243742727756, 0.04521376109699354, 0.04521376109699354, 0.8138476997458838, 0.04521376109699354, 0.04521376109699354, 0.370020139934248, 0.2808912011179693, 0.23227541630908996, 0.05671841561035918, 0.03511140013974616, 0.016205261602959764, 0.006752192334566569, 0.004051315400739941, 0.06454823069510734, 0.1290964613902147, 0.06454823069510734, 0.06454823069510734, 0.6454823069510733, 0.8367704046707424, 0.06275778035030567, 0.02091926011676856, 0.02091926011676856, 0.04183852023353712, 0.1406482580590139, 0.09376550537267593, 0.046882752686337965, 0.046882752686337965, 0.7032412902950694, 0.29037319065825107, 0.6024160224104015, 0.07367677971925773, 0.010834820546949668, 0.006500892328169801, 0.0021669641093899333, 0.0021669641093899333, 0.010834820546949668, 0.08684175196404215, 0.08684175196404215, 0.08684175196404215, 0.08684175196404215, 0.6947340157123372, 0.056032234712355744, 0.056032234712355744, 0.7844512859729804, 0.056032234712355744, 0.056032234712355744, 0.2077445794484157, 0.12275816058315474, 0.6232337383452471, 0.00944293542947344, 0.00944293542947344, 0.00944293542947344, 0.00944293542947344, 0.07554156915459201, 0.07554156915459201, 0.07554156915459201, 0.6798741223913282, 0.07554156915459201, 0.1430125600022606, 0.1430125600022606, 0.1430125600022606, 0.1430125600022606, 0.1430125600022606, 0.4290376800067817, 0.08076425389390192, 0.08076425389390192, 0.08076425389390192, 0.08076425389390192, 0.08076425389390192, 0.6461140311512154, 0.056134037258365445, 0.056134037258365445, 0.056134037258365445, 0.056134037258365445, 0.056134037258365445, 0.7858765216171162, 0.04052519315666659, 0.04052519315666659, 0.8510290562899984, 0.04052519315666659, 0.04052519315666659, 0.14574368402331594, 0.11659494721865277, 0.08744621041398958, 0.18946678923031074, 0.3935079468629531, 0.04372310520699479, 0.040869661213518024, 0.8582628854838785, 0.040869661213518024, 0.040869661213518024, 0.040869661213518024, 0.09889446513600283, 0.2966833954080085, 0.19778893027200567, 0.09889446513600283, 0.04944723256800142, 0.14834169770400424, 0.14834169770400424, 0.1395171992912762, 0.1395171992912762, 0.1395171992912762, 0.1395171992912762, 0.1395171992912762, 0.41855159787382856, 0.1482802403043787, 0.729044514829862, 0.06178343346015779, 0.01235668669203156, 0.04942674676812624, 0.01235668669203156, 0.1339105332787314, 0.31427982300110435, 0.3334098991837802, 0.10931472104386238, 0.09838324893947614, 0.008198604078289679, 0.6937198172672417, 0.09720914636865807, 0.1899996951751044, 0.00883719512442346, 0.00441859756221173, 0.00441859756221173, 0.09489519684992052, 0.3389114173211447, 0.10845165354276631, 0.01355645669284579, 0.01355645669284579, 0.40669370078537365, 0.01355645669284579, 0.2682932066904277, 0.40950015758012653, 0.12002590825624398, 0.04589225903915212, 0.10237503939503163, 0.04236208526690964, 0.014120695088969881, 0.0035301737722424702, 0.19360328351561562, 0.3234591444102359, 0.10388468871569619, 0.13929992350513806, 0.17943718959983887, 0.033054219136812425, 0.014166093915776752, 0.009444062610517836, 0.8290025379690757, 0.051812658623067234, 0.051812658623067234, 0.051812658623067234, 0.051812658623067234, 0.2165723586349868, 0.5243330788004944, 0.12538399710446604, 0.05699272595657547, 0.02279709038263019, 0.011398545191315095, 0.05699272595657547, 0.08373818617825371, 0.08373818617825371, 0.08373818617825371, 0.6699054894260297, 0.08373818617825371, 0.413300967499097, 0.16432448105385783, 0.298771783734287, 0.01991811891561913, 0.004979529728904783, 0.0896315351202861, 0.004979529728904783, 0.28342223479477796, 0.5438642883899792, 0.12256096639774182, 0.007660060399858864, 0.02298018119957659, 0.015320120799717727, 0.007660060399858864, 0.194632341646314, 0.194632341646314, 0.194632341646314, 0.194632341646314, 0.194632341646314, 0.194632341646314, 0.1806986806481959, 0.1806986806481959, 0.1806986806481959, 0.1806986806481959, 0.1806986806481959, 0.1806986806481959, 0.0988937474835062, 0.0988937474835062, 0.0988937474835062, 0.0988937474835062, 0.0988937474835062, 0.494468737417531, 0.30306670038643935, 0.10102223346214645, 0.10102223346214645, 0.2020444669242929, 0.10102223346214645, 0.2020444669242929, 0.06598065331171596, 0.021993551103905322, 0.08797420441562129, 0.08797420441562129, 0.3738903687663905, 0.35189681766248515, 0.10671893348559514, 0.10671893348559514, 0.10671893348559514, 0.10671893348559514, 0.10671893348559514, 0.5335946674279757, 0.15600381731944388, 0.24336595501833247, 0.018720458078333266, 0.11856290116277735, 0.18720458078333266, 0.26208641309666575, 0.01248030538555551, 0.24770692949109485, 0.2958226639965593, 0.3029509209603318, 0.062372248433009495, 0.03920541330074882, 0.04455160602357821, 0.004455160602357821, 0.0035641284818862568, 0.08344488481062122, 0.08344488481062122, 0.3337795392424849, 0.08344488481062122, 0.08344488481062122, 0.3337795392424849, 0.056737067340307874, 0.11347413468061575, 0.7943189427643103, 0.011347413468061575, 0.011347413468061575, 0.011347413468061575, 0.3152710908325667, 0.24142380829520874, 0.3834378131747433, 0.02556252087831622, 0.022722240780725527, 0.005680560195181382, 0.002840280097590691, 0.002840280097590691, 0.23662744237448935, 0.19186008841174812, 0.274999460056839, 0.07034869908430764, 0.18546475213135652, 0.019186008841174815, 0.006395336280391605, 0.006395336280391605, 0.09170164151288498, 0.09170164151288498, 0.09170164151288498, 0.09170164151288498, 0.6419114905901949, 0.053673196331315794, 0.053673196331315794, 0.8050979449697369, 0.053673196331315794, 0.053673196331315794, 0.7420815062624996, 0.07765969251584297, 0.15100495766969468, 0.01294328208597383, 0.008628854723982553, 0.004314427361991276, 0.004314427361991276, 0.8145302969395499, 0.06265617668765769, 0.052213480573048074, 0.031328088343828844, 0.02088539222921923, 0.010442696114609615, 0.4202039846129946, 0.2651287045772466, 0.2951432749067462, 0.005002428388249935, 0.005002428388249935, 0.0025012141941249677, 0.0025012141941249677, 0.0025012141941249677, 0.13204157947207126, 0.04062817829909885, 0.7566998208207162, 0.05078522287387357, 0.005078522287387356, 0.010157044574774713, 0.005078522287387356, 0.1854074704819969, 0.1854074704819969, 0.1854074704819969, 0.1854074704819969, 0.1854074704819969, 0.1854074704819969, 0.04089353059548916, 0.8587641425052724, 0.04089353059548916, 0.04089353059548916, 0.04089353059548916, 0.08682554077833567, 0.08682554077833567, 0.08682554077833567, 0.08682554077833567, 0.08682554077833567, 0.6946043262266853, 0.22553504754484632, 0.16618371924357098, 0.1543134535833159, 0.1187026566025507, 0.29675664150637676, 0.023740531320510138, 0.05917088326118483, 0.1479272081529621, 0.05917088326118483, 0.029585441630592416, 0.6212942742424408, 0.029585441630592416, 0.029585441630592416, 0.3683439751722322, 0.3223009782757032, 0.23213344268666716, 0.03645070587641881, 0.007673832816088171, 0.030695331264352685, 0.045998271593845064, 0.8279688886892111, 0.045998271593845064, 0.045998271593845064, 0.045998271593845064, 0.5168881703916645, 0.23971625293526466, 0.15356822453665392, 0.044946797425362124, 0.022473398712681062, 0.01872783226056755, 0.0037455664521135103, 0.0037455664521135103, 0.17380632969964663, 0.17380632969964663, 0.17380632969964663, 0.17380632969964663, 0.17380632969964663, 0.34761265939929326, 0.04390855193481734, 0.7464453828918948, 0.08781710386963468, 0.04390855193481734, 0.04390855193481734, 0.364550894478023, 0.20505987814388793, 0.26142136511910863, 0.11032461280255959, 0.014390166887290381, 0.03717459779216682, 0.0035975417218225953, 0.0035975417218225953, 0.11410877585209715, 0.11410877585209715, 0.11410877585209715, 0.11410877585209715, 0.11410877585209715, 0.5705438792604858, 0.07120882029873785, 0.10681323044810677, 0.7120882029873784, 0.053406615224053385, 0.01780220507468446, 0.01780220507468446, 0.01780220507468446, 0.18411928695615998, 0.18411928695615998, 0.18411928695615998, 0.18411928695615998, 0.18411928695615998, 0.18411928695615998, 0.08853006962430018, 0.04426503481215009, 0.8189031440247767, 0.022132517406075046, 0.022132517406075046, 0.8968744561279565, 0.029895815204265215, 0.029895815204265215, 0.029895815204265215, 0.029895815204265215, 0.03824320919184469, 0.879593811412428, 0.03824320919184469, 0.03824320919184469, 0.03824320919184469, 0.4965519253525556, 0.27708823488809275, 0.10360157454886654, 0.023295028596786557, 0.08888892490879081, 0.004291189478355419, 0.004291189478355419, 0.0024521082733459537, 0.10316845839010398, 0.10316845839010398, 0.10316845839010398, 0.10316845839010398, 0.6190107503406238, 0.1203147994873108, 0.1203147994873108, 0.1203147994873108, 0.1203147994873108, 0.1203147994873108, 0.4812591979492432, 0.06582376745480695, 0.7898852094576834, 0.06582376745480695, 0.06582376745480695, 0.06582376745480695, 0.19107509617382057, 0.19107509617382057, 0.19107509617382057, 0.19107509617382057, 0.19107509617382057, 0.19107509617382057, 0.04188522641189879, 0.7958193018260771, 0.04188522641189879, 0.04188522641189879, 0.04188522641189879, 0.04188522641189879, 0.09449875174686459, 0.09449875174686459, 0.09449875174686459, 0.09449875174686459, 0.09449875174686459, 0.6614912622280521, 0.15321997826930947, 0.03830499456732737, 0.11491498370198211, 0.6128799130772379, 0.03830499456732737, 0.03830499456732737, 0.33950877818388603, 0.4321020813249459, 0.06172886876070655, 0.030864434380353276, 0.030864434380353276, 0.030864434380353276, 0.1234577375214131, 0.04939833422918398, 0.8397716818961277, 0.04939833422918398, 0.04939833422918398, 0.04939833422918398, 0.03170292922410272, 0.06340585844820544, 0.03170292922410272, 0.03170292922410272, 0.8559790890507735, 0.114325019723162, 0.114325019723162, 0.114325019723162, 0.114325019723162, 0.114325019723162, 0.457300078892648, 0.17345529120499822, 0.7285122230609925, 0.03469105824099965, 0.03469105824099965, 0.017345529120499824, 0.017345529120499824, 0.017345529120499824, 0.09569805584123345, 0.47849027920616727, 0.09569805584123345, 0.09569805584123345, 0.09569805584123345, 0.1913961116824669, 0.012012287964571532, 0.1081105916811438, 0.16817203150400145, 0.564577534334862, 0.060061439822857665, 0.08408601575200073, 0.5308946574288694, 0.11682640093838631, 0.05027971685955866, 0.11534758573663459, 0.04288564085080004, 0.13900862896466218, 0.0044364456052551765, 0.0014788152017517254, 0.24052647926103038, 0.1860071439618635, 0.1314878086626966, 0.25976859760191284, 0.07055443391656892, 0.09941761142789256, 0.009621059170441216, 0.12404130326637489, 0.28684551380349194, 0.03101032581659372, 0.046515488724890586, 0.44189714288646054, 0.01550516290829686, 0.046515488724890586, 0.05117804014233168, 0.05117804014233168, 0.8188486422773069, 0.05117804014233168, 0.05117804014233168, 0.6475295596969158, 0.19634767294035513, 0.05430893081328972, 0.04177610062560748, 0.037598490563046726, 0.004177610062560747, 0.004177610062560747, 0.008355220125121495, 0.04054983799613407, 0.04054983799613407, 0.8515465979188155, 0.04054983799613407, 0.04054983799613407, 0.09854435943137846, 0.09854435943137846, 0.09854435943137846, 0.09854435943137846, 0.09854435943137846, 0.5912661565882708, 0.01779986464292909, 0.20469844339368454, 0.7208945180386283, 0.008899932321464545, 0.01779986464292909, 0.008899932321464545, 0.01779986464292909, 0.11378630024219323, 0.11378630024219323, 0.11378630024219323, 0.11378630024219323, 0.11378630024219323, 0.5689315012109661, 0.10327897199292094, 0.10327897199292094, 0.10327897199292094, 0.10327897199292094, 0.6196738319575257, 0.3250272750804731, 0.31900825146787176, 0.20916107053789704, 0.08125681877011827, 0.03761889757875846, 0.024076094450405414, 0.0015047559031503384, 0.0030095118063006767, 0.04243591958582234, 0.04243591958582234, 0.04243591958582234, 0.8487183917164468, 0.04243591958582234, 0.10543021633000059, 0.03953633112375022, 0.26357554082500145, 0.04612571964437526, 0.533740470170628, 0.006589388520625037, 0.05503006896557553, 0.05503006896557553, 0.05503006896557553, 0.05503006896557553, 0.7704209655180574, 0.06783184993102932, 0.13566369986205865, 0.06783184993102932, 0.06783184993102932, 0.6104866493792639, 0.1717626044807442, 0.1717626044807442, 0.1717626044807442, 0.1717626044807442, 0.1717626044807442, 0.3435252089614884, 0.1910808697104738, 0.1910808697104738, 0.1910808697104738, 0.1910808697104738, 0.1910808697104738, 0.1910808697104738, 0.10380496014079321, 0.20760992028158642, 0.10380496014079321, 0.10380496014079321, 0.10380496014079321, 0.10380496014079321, 0.31141488042237964, 0.1910488298160505, 0.1910488298160505, 0.1910488298160505, 0.1910488298160505, 0.1910488298160505, 0.1910488298160505, 0.20800459388400938, 0.15860350283655716, 0.5876129777223265, 0.013000287117750586, 0.018200401964850822, 0.005200114847100234, 0.005200114847100234, 0.002600057423550117, 0.2679755872853496, 0.18036818374975452, 0.4947241611421838, 0.025766883392822074, 0.005153376678564415, 0.025766883392822074, 0.005153376678564415, 0.17392910855040986, 0.4562488209800606, 0.23190547806721312, 0.06553850467116892, 0.05797636951680328, 0.0075621351543656455, 0.005041423436243764, 0.002520711718121882, 0.14134509170669302, 0.32307449532958404, 0.17836404429654118, 0.23220979351813853, 0.06730718652699667, 0.03701895258984817, 0.010096077979049501, 0.010096077979049501, 0.15497850102118238, 0.15497850102118238, 0.15497850102118238, 0.15497850102118238, 0.15497850102118238, 0.30995700204236476, 0.1732466015716502, 0.1732466015716502, 0.1732466015716502, 0.1732466015716502, 0.1732466015716502, 0.1732466015716502, 0.47766485689180826, 0.2461250216808936, 0.19325372072722014, 0.018231483087473598, 0.036462966174947195, 0.01276203816123152, 0.00546944492624208, 0.01093888985248416, 0.12746792496630552, 0.12746792496630552, 0.12746792496630552, 0.12746792496630552, 0.12746792496630552, 0.3824037748989165, 0.8721135715695169, 0.037917981372587686, 0.037917981372587686, 0.037917981372587686, 0.037917981372587686, 0.035663479174896665, 0.035663479174896665, 0.8559235001975201, 0.035663479174896665, 0.035663479174896665, 0.01545170108435071, 0.06180680433740284, 0.35538912494006636, 0.06180680433740284, 0.49445443469922273, 0.01545170108435071, 0.09762323322158223, 0.2778507407075802, 0.13517063061449847, 0.3304170970576629, 0.11264219217874873, 0.030037917914332996, 0.007509479478583249, 0.007509479478583249, 0.06482459593087944, 0.03241229796543972, 0.03241229796543972, 0.8427197471014327, 0.03241229796543972, 0.1697590477878439, 0.2498340703292797, 0.26264607393590944, 0.13132303696795472, 0.14733804147624188, 0.03523300991823175, 0.003203000901657432, 0.04366695440205332, 0.04366695440205332, 0.04366695440205332, 0.8296721336390132, 0.04366695440205332, 0.12815485843109922, 0.12815485843109922, 0.06407742921554961, 0.6407742921554962, 0.06407742921554961, 0.09465738972082215, 0.8045878126269882, 0.04732869486041107, 0.04732869486041107, 0.04732869486041107, 0.09639094429665612, 0.09639094429665612, 0.04819547214832806, 0.7229320822249209, 0.04819547214832806, 0.2683996656937198, 0.10735986627748792, 0.05367993313874396, 0.05367993313874396, 0.05367993313874396, 0.5367993313874396, 0.2422811008347653, 0.3115042725018411, 0.2076695150012274, 0.0346115858335379, 0.0692231716670758, 0.0346115858335379, 0.0692231716670758, 0.02879661962835665, 0.02879661962835665, 0.0575932392567133, 0.02879661962835665, 0.02879661962835665, 0.4607459140537064, 0.37435605516863646, 0.25483734655826984, 0.5150209311562236, 0.16751545857676478, 0.032077428238103896, 0.023167031505297257, 0.0035641586931226548, 0.0035641586931226548, 0.03157868292877201, 0.015789341464386004, 0.6947310244329842, 0.015789341464386004, 0.015789341464386004, 0.23684012196579007, 0.29701460546529546, 0.16500811414738634, 0.1320064913179091, 0.0990048684884318, 0.28601406452213635, 0.01100054094315909, 0.845975541616831, 0.056058620227621335, 0.08153981124017648, 0.00509623820251103, 0.00509623820251103, 0.00509623820251103, 0.00509623820251103, 0.1076820708704515, 0.1076820708704515, 0.1076820708704515, 0.1076820708704515, 0.1076820708704515, 0.5384103543522575, 0.10358859643674007, 0.10358859643674007, 0.10358859643674007, 0.10358859643674007, 0.6215315786204404, 0.13189524497958166, 0.13189524497958166, 0.13189524497958166, 0.13189524497958166, 0.13189524497958166, 0.3956857349387449, 0.051175813112038455, 0.051175813112038455, 0.8188130097926153, 0.051175813112038455, 0.051175813112038455, 0.49081645991004025, 0.10016662447143679, 0.383972060473841, 0.010016662447143679, 0.010016662447143679, 0.003338887482381226, 0.003338887482381226, 0.5337759461543541, 0.1435363888818431, 0.26015970484834067, 0.008971024305115195, 0.042612365449297175, 0.004485512152557597, 0.006728268228836396, 0.0022427560762787986, 0.19187407260808484, 0.2817731136202644, 0.43473566101412225, 0.04427863214032727, 0.025493757898976305, 0.018784874241350964, 0.0013417767315250686, 0.0026835534630501373, 0.6628642713059049, 0.12997338653056958, 0.11047737855098413, 0.05523868927549207, 0.022745342642849675, 0.012997338653056958, 0.0032493346632642395, 0.05526524739853933, 0.05526524739853933, 0.6908155924817416, 0.165795742195618, 0.027632623699269665, 0.28900059225199176, 0.3331534605127127, 0.20872264995977183, 0.05218066248994296, 0.04013897114610997, 0.06823625094838694, 0.03020375659986929, 0.09061126979960787, 0.724890158396863, 0.03020375659986929, 0.03020375659986929, 0.09061126979960787, 0.16083914753584905, 0.16083914753584905, 0.16083914753584905, 0.16083914753584905, 0.16083914753584905, 0.3216782950716981, 0.04136743362278609, 0.04136743362278609, 0.04136743362278609, 0.8273486724557217, 0.04136743362278609, 0.08846937108583654, 0.08846937108583654, 0.08846937108583654, 0.7077549686866923, 0.08846937108583654, 0.04962432557168216, 0.7939892091469145, 0.09924865114336431, 0.04962432557168216, 0.04962432557168216, 0.09378247643548236, 0.09378247643548236, 0.09378247643548236, 0.6564773350483765, 0.09378247643548236, 0.027164766122949827, 0.21731812898359862, 0.027164766122949827, 0.027164766122949827, 0.7062839191966955, 0.21340293586410297, 0.14749908802371822, 0.3703168592935905, 0.2196794928012825, 0.025106227748717996, 0.00941483540576925, 0.0031382784685897495, 0.012553113874358998, 0.16617703817273782, 0.16617703817273782, 0.16617703817273782, 0.16617703817273782, 0.16617703817273782, 0.33235407634547565, 0.037460051984949734, 0.037460051984949734, 0.8241211436688941, 0.037460051984949734, 0.07492010396989947, 0.13655278875687094, 0.13655278875687094, 0.13655278875687094, 0.27310557751374187, 0.13655278875687094, 0.27310557751374187, 0.11802975596867295, 0.18294612175144306, 0.6078532432386657, 0.06491636578277012, 0.011802975596867295, 0.01770446339530094, 0.1591004315225149, 0.5820747494726155, 0.15133943486288, 0.06984896993671386, 0.007760996659634873, 0.0038804983298174364, 0.0038804983298174364, 0.027163488308722054, 0.14409292079396638, 0.04803097359798879, 0.28818584158793276, 0.04803097359798879, 0.04803097359798879, 0.4322787623818991, 0.05871387537113923, 0.029356937685569615, 0.8807081305670884, 0.029356937685569615, 0.029356937685569615, 0.19537673577265124, 0.42243618545438105, 0.1161699509999548, 0.04752407086361787, 0.1003285940454155, 0.1161699509999548, 0.053856498226331685, 0.7539909751686436, 0.053856498226331685, 0.053856498226331685, 0.053856498226331685, 0.4015425528501995, 0.10038563821254988, 0.011153959801394431, 0.08923167841115545, 0.31231087443904404, 0.055769799006972154, 0.022307919602788863, 0.2502835753734595, 0.3376841889959375, 0.27809286152606616, 0.055618572305213235, 0.03972755164658088, 0.02648503443105392, 0.003972755164658088, 0.007945510329316176, 0.8297625322120373, 0.05186015826325233, 0.05186015826325233, 0.05186015826325233, 0.05186015826325233, 0.8721494079376497, 0.03791953947554999, 0.03791953947554999, 0.03791953947554999, 0.03791953947554999, 0.056037651255056185, 0.056037651255056185, 0.7845271175707865, 0.056037651255056185, 0.056037651255056185, 0.06136371838010143, 0.06136371838010143, 0.06136371838010143, 0.06136371838010143, 0.7363646205612172, 0.0370219150513729, 0.777460216078831, 0.11106574515411871, 0.0370219150513729, 0.0370219150513729, 0.11354001694126965, 0.04541600677650786, 0.04541600677650786, 0.02270800338825393, 0.7720721152006337, 0.17964144802801318, 0.29274902641602146, 0.299402413380022, 0.019960160892001467, 0.026613547856001955, 0.1197609653520088, 0.0598804826760044, 0.13550723824036814, 0.13550723824036814, 0.13550723824036814, 0.13550723824036814, 0.13550723824036814, 0.4065217147211045, 0.6194092024192386, 0.17274980268476253, 0.14162371211093144, 0.04202022227467196, 0.009337827172149326, 0.009337827172149326, 0.0015563045286915542, 0.004668913586074663, 0.9132995563847134, 0.027675744132870102, 0.027675744132870102, 0.027675744132870102, 0.027675744132870102, 0.043557843638823236, 0.043557843638823236, 0.8275990291376415, 0.043557843638823236, 0.043557843638823236, 0.3405302915022429, 0.30169788983970647, 0.2031233317732677, 0.06272926422409737, 0.06272926422409737, 0.014935539100975566, 0.00896132346058534, 0.005974215640390227, 0.06664619822404451, 0.399877189344267, 0.06664619822404451, 0.06664619822404451, 0.06664619822404451, 0.06664619822404451, 0.33323099112022253, 0.061396002012185674, 0.061396002012185674, 0.061396002012185674, 0.061396002012185674, 0.7981480261584137, 0.05710275626225379, 0.11420551252450759, 0.1713082687867614, 0.5424761844914111, 0.11420551252450759, 0.07169363915112555, 0.07169363915112555, 0.07169363915112555, 0.07169363915112555, 0.07169363915112555, 0.5735491132090044, 0.04702747573576094, 0.04702747573576094, 0.8464945632436969, 0.04702747573576094, 0.04702747573576094, 0.07678973674861043, 0.8446871042347148, 0.03839486837430522, 0.03839486837430522, 0.03839486837430522, 0.19462834215190594, 0.19462834215190594, 0.19462834215190594, 0.19462834215190594, 0.19462834215190594, 0.19462834215190594, 0.09875884706377762, 0.09875884706377762, 0.09875884706377762, 0.09875884706377762, 0.09875884706377762, 0.5925530823826658, 0.07201511679617206, 0.07201511679617206, 0.07201511679617206, 0.7201511679617206, 0.07201511679617206, 0.33208356311792164, 0.20930328792047667, 0.3123068744955144, 0.08075481187482958, 0.02719294685580996, 0.03131309031881147, 0.0024720860778009056, 0.0032961147704012074, 0.1281874961394514, 0.08545833075963427, 0.18515971664587427, 0.1281874961394514, 0.4557777640513828, 0.014243055126605713, 0.014243055126605713, 0.014243055126605713, 0.32029730235425063, 0.30250300777901445, 0.24149399780677627, 0.05338288372570844, 0.05719594684897333, 0.017794294575236146, 0.0025420420821765924, 0.0038130631232648885, 0.06743017017563971, 0.10114525526345956, 0.6700873161204196, 0.12643156907932446, 0.016857542543909927, 0.004214385635977482, 0.016857542543909927, 0.19465049986895608, 0.19465049986895608, 0.19465049986895608, 0.19465049986895608, 0.19465049986895608, 0.19465049986895608, 0.23021206611187933, 0.33341057850685973, 0.2619654545411041, 0.07541429751940874, 0.05556842975114329, 0.023815041321918553, 0.015876694214612366, 0.003969173553653092, 0.1574338688995146, 0.3811556825988248, 0.433633638898663, 0.011047990799965936, 0.005523995399982968, 0.008285993099974453, 0.26965857076196764, 0.275161806899967, 0.2971747514519643, 0.03852265296599538, 0.0908033962769891, 0.027516180689996696, 0.0027516180689996696, 0.05482182610057479, 0.268017816491699, 0.6395879711733725, 0.012182628022349953, 0.012182628022349953, 0.012182628022349953, 0.1884829269384232, 0.7303713418863899, 0.0471207317346058, 0.0235603658673029, 0.0235603658673029, 0.13404744399182542, 0.8042846639509525, 0.026809488798365085, 0.026809488798365085, 0.026809488798365085, 0.053696422739687215, 0.8322945524651518, 0.053696422739687215, 0.026848211369843607, 0.026848211369843607, 0.026848211369843607, 0.15887364100672205, 0.07943682050336102, 0.026478940167787006, 0.026478940167787006, 0.4501419828523791, 0.23831046151008306, 0.16308312440829453, 0.16308312440829453, 0.16308312440829453, 0.16308312440829453, 0.16308312440829453, 0.32616624881658907, 0.0676310443445979, 0.20289313303379367, 0.0676310443445979, 0.0676310443445979, 0.20289313303379367, 0.40578626606758733, 0.14563526906251514, 0.14563526906251514, 0.14563526906251514, 0.14563526906251514, 0.14563526906251514, 0.4369058071875454, 0.13555770889999072, 0.45596683902724144, 0.13555770889999072, 0.012323428081817337, 0.06161714040908668, 0.18485142122726006, 0.8215067543186968, 0.04563926412881649, 0.04563926412881649, 0.04563926412881649, 0.04563926412881649, 0.45888689607294236, 0.19321553518860732, 0.04830388379715183, 0.09660776759430366, 0.09660776759430366, 0.024151941898575915, 0.07245582569572774, 0.3009963007741938, 0.1504981503870969, 0.1504981503870969, 0.1504981503870969, 0.1504981503870969, 0.3009963007741938, 0.0903911835820564, 0.0903911835820564, 0.0903911835820564, 0.0903911835820564, 0.0903911835820564, 0.6327382850743948, 0.14978672681172203, 0.14978672681172203, 0.14978672681172203, 0.14978672681172203, 0.14978672681172203, 0.29957345362344406, 0.5237942072658656, 0.20065748238543107, 0.18502183440734554, 0.046906943934256616, 0.013029706648404617, 0.023453471967128308, 0.00781782398904277, 0.0052118826593618465, 0.30390827243328894, 0.15195413621664447, 0.15195413621664447, 0.15195413621664447, 0.15195413621664447, 0.15195413621664447, 0.15195413621664447, 0.31347557892711475, 0.029854817040677595, 0.014927408520338798, 0.014927408520338798, 0.49260448117118033, 0.10449185964237158, 0.029854817040677595, 0.8042620771668431, 0.09335184824258, 0.05026637982292769, 0.014361822806550769, 0.014361822806550769, 0.014361822806550769, 0.007180911403275384, 0.8677610198323111, 0.02018048883330956, 0.04036097766661912, 0.02018048883330956, 0.04036097766661912, 0.02018048883330956, 0.19366142117272928, 0.04469109719370676, 0.5884327797171389, 0.05213961339265789, 0.06703664579056014, 0.02234554859685338, 0.02234554859685338, 0.800040312553511, 0.05714573661096508, 0.05714573661096508, 0.05714573661096508, 0.05714573661096508, 0.4070182943711982, 0.3512623636354176, 0.09478508225082698, 0.08642169264045989, 0.04739254112541349, 0.008363389610367086, 0.0027877965367890285, 0.0027877965367890285, 0.04707738760203978, 0.04707738760203978, 0.847392976836716, 0.04707738760203978, 0.04707738760203978, 0.03432335529686429, 0.03432335529686429, 0.823760527124743, 0.10297006589059288, 0.03432335529686429, 0.039356303564510337, 0.039356303564510337, 0.039356303564510337, 0.7871260712902067, 0.07871260712902067, 0.2512995394884806, 0.2512995394884806, 0.30329254765851105, 0.034662005446686975, 0.06932401089337395, 0.04332750680835872, 0.008665501361671744, 0.034662005446686975, 0.02523732532560089, 0.7318824344424258, 0.07571197597680268, 0.02523732532560089, 0.05047465065120178, 0.05047465065120178, 0.04332234380147115, 0.04332234380147115, 0.12996703140441346, 0.04332234380147115, 0.7364798446250096, 0.03216328765197221, 0.12865315060788884, 0.06432657530394442, 0.06432657530394442, 0.5789391777354999, 0.09648986295591663, 0.3162113547725519, 0.25009443513829105, 0.1236098932292703, 0.2041000562622835, 0.06324227095451038, 0.04024508151650661, 0.002874648679750472, 0.10984698474068492, 0.12292400673362361, 0.5832351808850652, 0.026154043985877364, 0.08892374955198304, 0.03661566158022831, 0.0026154043985877366, 0.031384852783052836, 0.015028072033697092, 0.9016843220218256, 0.030056144067394184, 0.015028072033697092, 0.015028072033697092, 0.04508421610109128, 0.9170470861263065, 0.024132818055955435, 0.024132818055955435, 0.024132818055955435, 0.024132818055955435, 0.28447012708255087, 0.42101578808217527, 0.034136415249906106, 0.15930327116622847, 0.056894025416510174, 0.011378805083302034, 0.04551522033320814, 0.04802752209512349, 0.7684403535219758, 0.04802752209512349, 0.04802752209512349, 0.04802752209512349, 0.046411613184150574, 0.8818206504988609, 0.023205806592075287, 0.023205806592075287, 0.023205806592075287, 0.4683904950715663, 0.17889914742316768, 0.14637202970986446, 0.08782321782591868, 0.07481237074059739, 0.035779829484633534, 0.0032527117713303214, 0.09390505798369929, 0.14085758697554893, 0.16433385147147375, 0.046952528991849644, 0.44604902542257163, 0.09390505798369929, 0.1543314002718003, 0.07716570013590016, 0.07716570013590016, 0.07716570013590016, 0.07716570013590016, 0.6173256010872012, 0.20280502105070228, 0.2675300277690115, 0.5005400519549248, 0.004315000447887283, 0.004315000447887283, 0.012945001343661848, 0.004315000447887283, 0.5003103787636743, 0.18934823565517522, 0.15240223845416542, 0.08466791025231413, 0.04618249650126225, 0.0061576662001682995, 0.0184729986005049, 0.0015394165500420749, 0.8962589698569343, 0.02636055793696866, 0.02636055793696866, 0.02636055793696866, 0.02636055793696866, 0.035983924669478216, 0.8636141920674771, 0.035983924669478216, 0.035983924669478216, 0.035983924669478216, 0.1729302748925348, 0.1729302748925348, 0.1729302748925348, 0.1729302748925348, 0.1729302748925348, 0.3458605497850696, 0.13708611491080253, 0.13708611491080253, 0.13708611491080253, 0.13708611491080253, 0.13708611491080253, 0.4112583447324076, 0.12289797239979208, 0.12289797239979208, 0.12289797239979208, 0.12289797239979208, 0.12289797239979208, 0.49159188959916833, 0.16159721823799933, 0.16159721823799933, 0.16159721823799933, 0.16159721823799933, 0.16159721823799933, 0.32319443647599866, 0.27865616420277445, 0.13932808210138722, 0.27368016127058203, 0.14430408503357964, 0.024880014660962006, 0.12937607623700242, 0.004976002932192401, 0.17585850495584496, 0.2524086777013304, 0.2730979135784886, 0.18206527571899242, 0.05792986045604304, 0.0537920132806114, 0.002068923587715823, 0.12657560333113962, 0.25315120666227925, 0.12657560333113962, 0.12657560333113962, 0.12657560333113962, 0.25315120666227925, 0.10859790289877572, 0.10859790289877572, 0.10859790289877572, 0.10859790289877572, 0.10859790289877572, 0.5429895144938786, 0.09386155745893894, 0.09386155745893894, 0.09386155745893894, 0.6570309022125725, 0.09386155745893894, 0.25573494950751624, 0.19671919192885864, 0.28852148149565937, 0.03934383838577173, 0.08524498316917209, 0.13114612795257244, 0.844813459419089, 0.04969490937759347, 0.04969490937759347, 0.04969490937759347, 0.04969490937759347, 0.8677676162346899, 0.029923021249472062, 0.029923021249472062, 0.029923021249472062, 0.029923021249472062, 0.062475060274418515, 0.062475060274418515, 0.062475060274418515, 0.062475060274418515, 0.062475060274418515, 0.7497007232930222, 0.03290633361751412, 0.8884710076728811, 0.03290633361751412, 0.03290633361751412, 0.03290633361751412, 0.18735250691326505, 0.18735250691326505, 0.18735250691326505, 0.18735250691326505, 0.18735250691326505, 0.18735250691326505, 0.049680840439140866, 0.049680840439140866, 0.049680840439140866, 0.049680840439140866, 0.049680840439140866, 0.7948934470262539, 0.1945672247347866, 0.1945672247347866, 0.1945672247347866, 0.1945672247347866, 0.1945672247347866, 0.1945672247347866, 0.3564697495568068, 0.23513438025734404, 0.26678708529198647, 0.06029086673265231, 0.04521815004948924, 0.03089906920048431, 0.0015072716683163078, 0.0030145433366326156, 0.21313712635750098, 0.053284281589375246, 0.07992642238406288, 0.5861270974831277, 0.053284281589375246, 0.026642140794687623, 0.6710998171355737, 0.029178252918937986, 0.05835650583787597, 0.029178252918937986, 0.029178252918937986, 0.029178252918937986, 0.1750695175136279, 0.31516663976597076, 0.29546872478059755, 0.25786361435397603, 0.02327935407362284, 0.02327935407362284, 0.08058237948561751, 0.0017907195441248336, 0.005372158632374501, 0.31635912088252577, 0.36603534647564967, 0.2849846626131844, 0.018301767323782483, 0.005229076378223566, 0.002614538189111783, 0.005229076378223566, 0.8306725694764842, 0.05191703559228026, 0.05191703559228026, 0.05191703559228026, 0.05191703559228026, 0.845213487221816, 0.036748412487905044, 0.07349682497581009, 0.036748412487905044, 0.036748412487905044, 0.8854110518361126, 0.05059491724777786, 0.02529745862388893, 0.02529745862388893, 0.02529745862388893, 0.07845925394509669, 0.49037033715685435, 0.16672591463333047, 0.049037033715685435, 0.19124443149117318, 0.024518516857842718, 0.044916120184032515, 0.044916120184032515, 0.044916120184032515, 0.8084901633125853, 0.044916120184032515, 0.21026107140370778, 0.10513053570185389, 0.21026107140370778, 0.21026107140370778, 0.10513053570185389, 0.10513053570185389, 0.030307613905036973, 0.030307613905036973, 0.030307613905036973, 0.7879979615309614, 0.12123045562014789, 0.05385135003641052, 0.8077702505461578, 0.05385135003641052, 0.05385135003641052, 0.05385135003641052, 0.05647872421459966, 0.7907021390043952, 0.05647872421459966, 0.05647872421459966, 0.05647872421459966, 0.0326569655374494, 0.0326569655374494, 0.8817380695111338, 0.0326569655374494, 0.0326569655374494, 0.1442246081285726, 0.1442246081285726, 0.1442246081285726, 0.1442246081285726, 0.1442246081285726, 0.2884492162571452, 0.05600808276935551, 0.05600808276935551, 0.7841131587709771, 0.05600808276935551, 0.05600808276935551, 0.8723757154657972, 0.03355291213329989, 0.03355291213329989, 0.03355291213329989, 0.03355291213329989, 0.1034109602997597, 0.357629571036669, 0.36840154606789394, 0.12064612034971965, 0.025852740074939925, 0.015080765043714956, 0.004308790012489987, 0.0021543950062449936, 0.12245335047019235, 0.12245335047019235, 0.12245335047019235, 0.12245335047019235, 0.12245335047019235, 0.4898134018807694, 0.06234922392118037, 0.8105399109753448, 0.06234922392118037, 0.06234922392118037, 0.06234922392118037, 0.045575002957438646, 0.22787501478719321, 0.045575002957438646, 0.045575002957438646, 0.5924750384467024, 0.08102596654369403, 0.10128245817961753, 0.08102596654369403, 0.6684642239854758, 0.020256491635923506, 0.04051298327184701, 0.020256491635923506, 0.15412256453952103, 0.08807003687972631, 0.16880090401947542, 0.13210505531958947, 0.381636826478814, 0.07339169739977192, 0.007339169739977192, 0.03645652571230632, 0.03645652571230632, 0.03645652571230632, 0.8749566170953518, 0.03645652571230632], \"Term\": [\"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"adaboost\", \"adaboost\", \"adaboost\", \"adaboost\", \"adaboost\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"ado\", \"ado\", \"ado\", \"ado\", \"ado\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversary\", \"adversary\", \"adversary\", \"adversary\", \"adversary\", \"affine_ideal\", \"affine_ideal\", \"affine_ideal\", \"affine_ideal\", \"affine_ideal\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"alternating_minimization\", \"alternating_minimization\", \"alternating_minimization\", \"alternating_minimization\", \"alternating_minimization\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"ard\", \"ard\", \"ard\", \"ard\", \"ard\", \"arxiv_c\", \"arxiv_c\", \"arxiv_c\", \"arxiv_c\", \"arxiv_c\", \"arxiv_c\", \"asthma\", \"asthma\", \"asthma\", \"asthma\", \"asthma\", \"asthma\", \"asymptotic_variance\", \"asymptotic_variance\", \"asymptotic_variance\", \"asymptotic_variance\", \"asymptotic_variance\", \"auditory\", \"auditory\", \"auditory\", \"auditory\", \"auditory\", \"axon\", \"axon\", \"axon\", \"axon\", \"axon\", \"axon_circuit\", \"axon_circuit\", \"axon_circuit\", \"axon_circuit\", \"axon_circuit\", \"backpropagation\", \"backpropagation\", \"backpropagation\", \"backpropagation\", \"backpropagation\", \"backpropagation\", \"band\", \"band\", \"band\", \"band\", \"band\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base_classifier\", \"base_classifier\", \"base_classifier\", \"base_classifier\", \"base_classifier\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian_binne\", \"bayesian_binne\", \"bayesian_binne\", \"bayesian_binne\", \"bayesian_binne\", \"bayesian_binne\", \"bci\", \"bci\", \"bci\", \"bci\", \"bci\", \"bid\", \"bid\", \"bid\", \"bid\", \"bid\", \"bid\", \"bin\", \"bin\", \"bin\", \"bin\", \"bin\", \"bin\", \"bin_boundarie\", \"bin_boundarie\", \"bin_boundarie\", \"bin_boundarie\", \"bin_boundarie\", \"bin_boundarie\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular_disparity\", \"binocular_disparity\", \"binocular_disparity\", \"binocular_disparity\", \"binocular_disparity\", \"borrow\", \"borrow\", \"borrow\", \"borrow\", \"borrow\", \"borrowing\", \"borrowing\", \"borrowing\", \"borrowing\", \"borrowing\", \"capacity\", \"capacity\", \"capacity\", \"capacity\", \"capacity\", \"capacity\", \"capacity\", \"cascade\", \"cascade\", \"cascade\", \"cascade\", \"cascade\", \"cascade\", \"cascade_architecture\", \"cascade_architecture\", \"cascade_architecture\", \"cascade_architecture\", \"cascade_architecture\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causality\", \"causality\", \"causality\", \"causality\", \"causality\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cggm\", \"cggm\", \"cggm\", \"cggm\", \"cggm\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"character\", \"character\", \"character\", \"character\", \"character\", \"cheat\", \"cheat\", \"cheat\", \"cheat\", \"cheat\", \"cheat\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"cl_kcca\", \"cl_kcca\", \"cl_kcca\", \"cl_kcca\", \"cl_kcca\", \"cl_kcca\", \"cl_opca\", \"cl_opca\", \"cl_opca\", \"cl_opca\", \"cl_opca\", \"cl_opca\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"clinical\", \"clinical\", \"clinical\", \"clinical\", \"clinical\", \"clinical\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"coherent\", \"coherent\", \"coherent\", \"coherent\", \"coherent\", \"coherent\", \"community\", \"community\", \"community\", \"community\", \"community\", \"complex_cell\", \"complex_cell\", \"complex_cell\", \"complex_cell\", \"complex_cell\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"comprehensible\", \"comprehensible\", \"comprehensible\", \"comprehensible\", \"comprehensible\", \"comprehensible\", \"compressible\", \"compressible\", \"compressible\", \"compressible\", \"compressible\", \"compressible_prior\", \"compressible_prior\", \"compressible_prior\", \"compressible_prior\", \"compressible_prior\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"conditional_evidence\", \"conditional_evidence\", \"conditional_evidence\", \"conditional_evidence\", \"conditional_evidence\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex_max\", \"convex_max\", \"convex_max\", \"convex_max\", \"convex_max\", \"correlated_equilibrium\", \"correlated_equilibrium\", \"correlated_equilibrium\", \"correlated_equilibrium\", \"correlated_equilibrium\", \"correlated_equilibrium\", \"correlated_equilibrium\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage_risk\", \"coverage_risk\", \"coverage_risk\", \"coverage_risk\", \"coverage_risk\", \"cross_language\", \"cross_language\", \"cross_language\", \"cross_language\", \"cross_language\", \"cross_language\", \"cross_lingual\", \"cross_lingual\", \"cross_lingual\", \"cross_lingual\", \"cross_lingual\", \"cross_lingual\", \"csp\", \"csp\", \"csp\", \"csp\", \"csp\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cyclic_equilibrium\", \"cyclic_equilibrium\", \"cyclic_equilibrium\", \"cyclic_equilibrium\", \"cyclic_equilibrium\", \"cyclic_equilibrium\", \"dag\", \"dag\", \"dag\", \"dag\", \"dag\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep_architecture\", \"deep_architecture\", \"deep_architecture\", \"deep_architecture\", \"deep_architecture\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"dendritic\", \"dendritic\", \"dendritic\", \"dendritic\", \"dendritic\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density_ridge\", \"density_ridge\", \"density_ridge\", \"density_ridge\", \"density_ridge\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"dependent_plasticity\", \"dependent_plasticity\", \"dependent_plasticity\", \"dependent_plasticity\", \"dependent_plasticity\", \"dependent_plasticity\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"detect_rate\", \"detect_rate\", \"detect_rate\", \"detect_rate\", \"detect_rate\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detector\", \"detector\", \"detector\", \"detector\", \"detector\", \"detector\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"direct_connection\", \"direct_connection\", \"direct_connection\", \"direct_connection\", \"direct_connection\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document_term\", \"document_term\", \"document_term\", \"document_term\", \"document_term\", \"document_term\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"dts\", \"dts\", \"dts\", \"dts\", \"dts\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual_objective\", \"dual_objective\", \"dual_objective\", \"dual_objective\", \"dual_objective\", \"dummy_variable\", \"dummy_variable\", \"dummy_variable\", \"dummy_variable\", \"dummy_variable\", \"dummy_variable\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"eep_atch\", \"eep_atch\", \"eep_atch\", \"eep_atch\", \"eep_atch\", \"egood\", \"egood\", \"egood\", \"egood\", \"egood\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"epsp\", \"epsp\", \"epsp\", \"epsp\", \"epsp\", \"epsp\", \"eqn\", \"eqn\", \"eqn\", \"eqn\", \"eqn\", \"eqn\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"expand\", \"expand\", \"expand\", \"expand\", \"expand\", \"expand\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expression\", \"expression\", \"expression\", \"expression\", \"expression\", \"expression\", \"extract\", \"extract\", \"extract\", \"extract\", \"extract\", \"extract\", \"extract\", \"face_detection\", \"face_detection\", \"face_detection\", \"face_detection\", \"face_detection\", \"factorial\", \"factorial\", \"factorial\", \"factorial\", \"factorial\", \"false_positive\", \"false_positive\", \"false_positive\", \"false_positive\", \"false_positive\", \"false_positive\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"fg\", \"fg\", \"fg\", \"fg\", \"fg\", \"fg\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fitnet\", \"fitnet\", \"fitnet\", \"fitnet\", \"fitnet\", \"fitnet\", \"fm_km\", \"fm_km\", \"fm_km\", \"fm_km\", \"fm_km\", \"fm_km\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"food\", \"food\", \"food\", \"food\", \"food\", \"ftrl\", \"ftrl\", \"ftrl\", \"ftrl\", \"ftrl\", \"ftrl\", \"full\", \"full\", \"full\", \"full\", \"full\", \"full\", \"full\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene_expression\", \"gene_expression\", \"gene_expression\", \"gene_expression\", \"gene_expression\", \"ggd\", \"ggd\", \"ggd\", \"ggd\", \"ggd\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"goal_cell\", \"goal_cell\", \"goal_cell\", \"goal_cell\", \"goal_cell\", \"gp\", \"gp\", \"gp\", \"gp\", \"gp\", \"gram\", \"gram\", \"gram\", \"gram\", \"gram\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"grbf\", \"grbf\", \"grbf\", \"grbf\", \"grbf\", \"gsbl\", \"gsbl\", \"gsbl\", \"gsbl\", \"gsbl\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"hand_printe\", \"hand_printe\", \"hand_printe\", \"hand_printe\", \"hand_printe\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"highway\", \"highway\", \"highway\", \"highway\", \"highway\", \"highway\", \"highway_network\", \"highway_network\", \"highway_network\", \"highway_network\", \"highway_network\", \"highway_network\", \"hmax\", \"hmax\", \"hmax\", \"hmax\", \"hmax\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hypercube\", \"hypercube\", \"hypercube\", \"hypercube\", \"hypercube\", \"hyperplane\", \"hyperplane\", \"hyperplane\", \"hyperplane\", \"hyperplane\", \"hyperplane\", \"hyperplane\", \"ic_influence\", \"ic_influence\", \"ic_influence\", \"ic_influence\", \"ic_influence\", \"ic_influence\", \"identity\", \"identity\", \"identity\", \"identity\", \"identity\", \"identity\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"interval\", \"interval\", \"interval\", \"interval\", \"interval\", \"interval\", \"interval\", \"inverter\", \"inverter\", \"inverter\", \"inverter\", \"inverter\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kj\", \"kj\", \"kj\", \"kj\", \"kj\", \"kj\", \"kmj\", \"kmj\", \"kmj\", \"kmj\", \"kmj\", \"kmj\", \"knn_graph\", \"knn_graph\", \"knn_graph\", \"knn_graph\", \"knn_graph\", \"knn_graph\", \"kth\", \"kth\", \"kth\", \"kth\", \"kth\", \"kth\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"latent_semantic\", \"latent_semantic\", \"latent_semantic\", \"latent_semantic\", \"latent_semantic\", \"latent_semantic\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learnability\", \"learnability\", \"learnability\", \"learnability\", \"learnability\", \"learnability\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"lgn\", \"lgn\", \"lgn\", \"lgn\", \"lgn\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"mai\", \"mai\", \"mai\", \"mai\", \"mai\", \"mai\", \"manifold_sculpte\", \"manifold_sculpte\", \"manifold_sculpte\", \"manifold_sculpte\", \"manifold_sculpte\", \"markov_game\", \"markov_game\", \"markov_game\", \"markov_game\", \"markov_game\", \"markov_game\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"matching\", \"matching\", \"matching\", \"matching\", \"matching\", \"matching\", \"matching\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix_factorization\", \"matrix_factorization\", \"matrix_factorization\", \"matrix_factorization\", \"matrix_factorization\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"membrane_potential\", \"membrane_potential\", \"membrane_potential\", \"membrane_potential\", \"membrane_potential\", \"membrane_potential\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"mij_mij\", \"mij_mij\", \"mij_mij\", \"mij_mij\", \"mij_mij\", \"mij_mij\", \"minimal\", \"minimal\", \"minimal\", \"minimal\", \"minimal\", \"minimal\", \"minimal\", \"mirror_descent\", \"mirror_descent\", \"mirror_descent\", \"mirror_descent\", \"mirror_descent\", \"mirror_descent\", \"mistake\", \"mistake\", \"mistake\", \"mistake\", \"mistake\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"monocular\", \"monocular\", \"monocular\", \"monocular\", \"monocular\", \"monolingual\", \"monolingual\", \"monolingual\", \"monolingual\", \"monolingual\", \"monolingual\", \"monomial\", \"monomial\", \"monomial\", \"monomial\", \"monomial\", \"mti\", \"mti\", \"mti\", \"mti\", \"mti\", \"mti\", \"multi_view\", \"multi_view\", \"multi_view\", \"multi_view\", \"multi_view\", \"multi_view\", \"multilingual\", \"multilingual\", \"multilingual\", \"multilingual\", \"multilingual\", \"multilingual\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"mutual_information\", \"mutual_information\", \"mutual_information\", \"mutual_information\", \"mutual_information\", \"mutual_information\", \"mutual_information\", \"mvp\", \"mvp\", \"mvp\", \"mvp\", \"mvp\", \"navigation\", \"navigation\", \"navigation\", \"navigation\", \"navigation\", \"ncut\", \"ncut\", \"ncut\", \"ncut\", \"ncut\", \"ncut\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighborhood_graph\", \"neighborhood_graph\", \"neighborhood_graph\", \"neighborhood_graph\", \"neighborhood_graph\", \"neighborhood_graph\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"newton_direction\", \"newton_direction\", \"newton_direction\", \"newton_direction\", \"newton_direction\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"non_factorial\", \"non_factorial\", \"non_factorial\", \"non_factorial\", \"non_factorial\", \"noop\", \"noop\", \"noop\", \"noop\", \"noop\", \"noop\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"nosde_game\", \"nosde_game\", \"nosde_game\", \"nosde_game\", \"nosde_game\", \"nosde_game\", \"novel_views\", \"novel_views\", \"novel_views\", \"novel_views\", \"novel_views\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"oam\", \"oam\", \"oam\", \"oam\", \"oam\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"observer\", \"observer\", \"observer\", \"observer\", \"observer\", \"obstacle\", \"obstacle\", \"obstacle\", \"obstacle\", \"obstacle\", \"oftrl\", \"oftrl\", \"oftrl\", \"oftrl\", \"oftrl\", \"oftrl\", \"omd\", \"omd\", \"omd\", \"omd\", \"omd\", \"omd\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"pac_learnability\", \"pac_learnability\", \"pac_learnability\", \"pac_learnability\", \"pac_learnability\", \"pac_learnability\", \"pac_learnable\", \"pac_learnable\", \"pac_learnable\", \"pac_learnable\", \"pac_learnable\", \"pac_learnable\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"partial_observation\", \"partial_observation\", \"partial_observation\", \"partial_observation\", \"partial_observation\", \"partial_observation\", \"participant\", \"participant\", \"participant\", \"participant\", \"participant\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"patch\", \"patch\", \"patch\", \"patch\", \"patch\", \"patch\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pedestrian\", \"pedestrian\", \"pedestrian\", \"pedestrian\", \"pedestrian\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"periodic\", \"periodic\", \"periodic\", \"periodic\", \"periodic\", \"periodicity\", \"periodicity\", \"periodicity\", \"periodicity\", \"periodicity\", \"phase_transition\", \"phase_transition\", \"phase_transition\", \"phase_transition\", \"phase_transition\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"plain\", \"plain\", \"plain\", \"plain\", \"plain\", \"plain\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"prefix\", \"prefix\", \"prefix\", \"prefix\", \"prefix\", \"presynaptic\", \"presynaptic\", \"presynaptic\", \"presynaptic\", \"presynaptic\", \"presynaptic\", \"primal\", \"primal\", \"primal\", \"primal\", \"primal\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"program\", \"program\", \"program\", \"program\", \"program\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"proposition\", \"proposition\", \"proposition\", \"proposition\", \"proposition\", \"proposition\", \"psth\", \"psth\", \"psth\", \"psth\", \"psth\", \"psth\", \"pulse\", \"pulse\", \"pulse\", \"pulse\", \"pulse\", \"quadratic_programme\", \"quadratic_programme\", \"quadratic_programme\", \"quadratic_programme\", \"quadratic_programme\", \"random_walk\", \"random_walk\", \"random_walk\", \"random_walk\", \"random_walk\", \"rare_event\", \"rare_event\", \"rare_event\", \"rare_event\", \"rare_event\", \"rat\", \"rat\", \"rat\", \"rat\", \"rat\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"recency_bia\", \"recency_bia\", \"recency_bia\", \"recency_bia\", \"recency_bia\", \"recency_bia\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"refractoriness\", \"refractoriness\", \"refractoriness\", \"refractoriness\", \"refractoriness\", \"refractoriness\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"rejection\", \"rejection\", \"rejection\", \"rejection\", \"rejection\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"request\", \"request\", \"request\", \"request\", \"request\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"retention\", \"retention\", \"retention\", \"retention\", \"retention\", \"retention_interval\", \"retention_interval\", \"retention_interval\", \"retention_interval\", \"retention_interval\", \"reversible_chain\", \"reversible_chain\", \"reversible_chain\", \"reversible_chain\", \"reversible_chain\", \"rigid\", \"rigid\", \"rigid\", \"rigid\", \"rigid\", \"rkh\", \"rkh\", \"rkh\", \"rkh\", \"rkh\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rvu_property\", \"rvu_property\", \"rvu_property\", \"rvu_property\", \"rvu_property\", \"rvu_property\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"scc\", \"scc\", \"scc\", \"scc\", \"scc\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seed\", \"seed\", \"seed\", \"seed\", \"seed\", \"seed\", \"seed\", \"seemore\", \"seemore\", \"seemore\", \"seemore\", \"seemore\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"selective_sample\", \"selective_sample\", \"selective_sample\", \"selective_sample\", \"selective_sample\", \"selective_sample\", \"semi_metric\", \"semi_metric\", \"semi_metric\", \"semi_metric\", \"semi_metric\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"sencitivity_sencitivity\", \"sencitivity_sencitivity\", \"sencitivity_sencitivity\", \"sencitivity_sencitivity\", \"sencitivity_sencitivity\", \"sencitivity_sencitivity\", \"sentiment_classification\", \"sentiment_classification\", \"sentiment_classification\", \"sentiment_classification\", \"sentiment_classification\", \"sentiment_classification\", \"session\", \"session\", \"session\", \"session\", \"session\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"sim\", \"sim\", \"sim\", \"sim\", \"sim\", \"sim\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"specie\", \"specie\", \"specie\", \"specie\", \"specie\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spiketrain\", \"spiketrain\", \"spiketrain\", \"spiketrain\", \"spiketrain\", \"spiketrain\", \"split\", \"split\", \"split\", \"split\", \"split\", \"split\", \"srnn\", \"srnn\", \"srnn\", \"srnn\", \"srnn\", \"stack\", \"stack\", \"stack\", \"stack\", \"stack\", \"stack\", \"stack\", \"stacked_density\", \"stacked_density\", \"stacked_density\", \"stacked_density\", \"stacked_density\", \"stacked_density\", \"stationary_equilibrium\", \"stationary_equilibrium\", \"stationary_equilibrium\", \"stationary_equilibrium\", \"stationary_equilibrium\", \"stationary_equilibrium\", \"stdp\", \"stdp\", \"stdp\", \"stdp\", \"stdp\", \"stdp\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stepsize\", \"stepsize\", \"stepsize\", \"stepsize\", \"stepsize\", \"stepsize\", \"stepsize\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"stratify\", \"stratify\", \"stratify\", \"stratify\", \"stratify\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"subdifferential\", \"subdifferential\", \"subdifferential\", \"subdifferential\", \"subdifferential\", \"subgradient\", \"subgradient\", \"subgradient\", \"subgradient\", \"subgradient\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"supervise\", \"supervise\", \"supervise\", \"supervise\", \"supervise\", \"supervise\", \"surround\", \"surround\", \"surround\", \"surround\", \"surround\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"tempered_transition\", \"tempered_transition\", \"tempered_transition\", \"tempered_transition\", \"tempered_transition\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal_difference\", \"temporal_difference\", \"temporal_difference\", \"temporal_difference\", \"temporal_difference\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text_classification\", \"text_classification\", \"text_classification\", \"text_classification\", \"text_classification\", \"text_classification\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"tissue\", \"tissue\", \"tissue\", \"tissue\", \"tissue\", \"tmax\", \"tmax\", \"tmax\", \"tmax\", \"tmax\", \"tmax\", \"tmin\", \"tmin\", \"tmin\", \"tmin\", \"tmin\", \"tmin\", \"tpost\", \"tpost\", \"tpost\", \"tpost\", \"tpost\", \"tpost\", \"tpre\", \"tpre\", \"tpre\", \"tpre\", \"tpre\", \"tpre\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"trait\", \"trait\", \"trait\", \"trait\", \"trait\", \"trait\", \"transform_gate\", \"transform_gate\", \"transform_gate\", \"transform_gate\", \"transform_gate\", \"transform_gate\", \"transistor\", \"transistor\", \"transistor\", \"transistor\", \"transistor\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree_width\", \"tree_width\", \"tree_width\", \"tree_width\", \"tree_width\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"trepan\", \"trepan\", \"trepan\", \"trepan\", \"trepan\", \"trepan\", \"trmf\", \"trmf\", \"trmf\", \"trmf\", \"trmf\", \"union_support\", \"union_support\", \"union_support\", \"union_support\", \"union_support\", \"union_support\", \"unlabeled_parallel\", \"unlabeled_parallel\", \"unlabeled_parallel\", \"unlabeled_parallel\", \"unlabeled_parallel\", \"unlabeled_parallel\", \"unweighte\", \"unweighte\", \"unweighte\", \"unweighte\", \"unweighte\", \"unweighte\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"utility\", \"utility\", \"utility\", \"utility\", \"utility\", \"utility\", \"utility\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variational_approximation\", \"variational_approximation\", \"variational_approximation\", \"variational_approximation\", \"variational_approximation\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"vertex_cover\", \"vertex_cover\", \"vertex_cover\", \"vertex_cover\", \"vertex_cover\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"viola_jone\", \"viola_jone\", \"viola_jone\", \"viola_jone\", \"viola_jone\", \"vol\", \"vol\", \"vol\", \"vol\", \"vol\", \"vol\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"volterra_functional\", \"volterra_functional\", \"volterra_functional\", \"volterra_functional\", \"volterra_functional\", \"volterra_serie\", \"volterra_serie\", \"volterra_serie\", \"volterra_serie\", \"volterra_serie\", \"vortex\", \"vortex\", \"vortex\", \"vortex\", \"vortex\", \"voter\", \"voter\", \"voter\", \"voter\", \"voter\", \"voter\", \"wavelet_coefficient\", \"wavelet_coefficient\", \"wavelet_coefficient\", \"wavelet_coefficient\", \"wavelet_coefficient\", \"weak_learner\", \"weak_learner\", \"weak_learner\", \"weak_learner\", \"weak_learner\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"welfare\", \"welfare\", \"welfare\", \"welfare\", \"welfare\", \"welfare\", \"wiener_functional\", \"wiener_functional\", \"wiener_functional\", \"wiener_functional\", \"wiener_functional\", \"win\", \"win\", \"win\", \"win\", \"win\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"writer\", \"writer\", \"writer\", \"writer\", \"writer\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 5, 6, 3, 1, 4, 7, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el126151406710323399043450198615\", ldavis_el126151406710323399043450198615_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el126151406710323399043450198615\", ldavis_el126151406710323399043450198615_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el126151406710323399043450198615\", ldavis_el126151406710323399043450198615_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "7     -0.086241  0.003575       1        1  28.013068\n",
       "4     -0.079841 -0.007161       2        1  24.383925\n",
       "5     -0.085072 -0.033491       3        1  24.240630\n",
       "2      0.002539  0.041184       4        1   8.995667\n",
       "0      0.025472  0.058728       5        1   7.429888\n",
       "3      0.041188 -0.016108       6        1   4.258607\n",
       "6      0.096155 -0.003900       7        1   1.416491\n",
       "1      0.085800 -0.042827       8        1   1.261724, topic_info=        Term         Freq        Total Category  logprob  loglift\n",
       "346  network   676.000000   676.000000  Default  30.0000  30.0000\n",
       "332    model  1631.000000  1631.000000  Default  29.0000  29.0000\n",
       "558     task   382.000000   382.000000  Default  28.0000  28.0000\n",
       "574     time   649.000000   649.000000  Default  27.0000  27.0000\n",
       "269    input   423.000000   423.000000  Default  26.0000  26.0000\n",
       "..       ...          ...          ...      ...      ...      ...\n",
       "485      set     4.350755  1213.549976   Topic8  -6.2354  -1.2583\n",
       "595      use     4.145845  1326.900812   Topic8  -6.2837  -1.3958\n",
       "332    model     3.590899  1631.249339   Topic8  -6.4274  -1.7460\n",
       "376   output     3.256585   297.145090   Topic8  -6.5251  -0.1409\n",
       "492     show     3.208679   786.769037   Topic8  -6.5399  -1.1294\n",
       "\n",
       "[562 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "1180      1  0.310902  accuracy\n",
       "1180      2  0.269994  accuracy\n",
       "1180      3  0.130906  accuracy\n",
       "1180      4  0.114543  accuracy\n",
       "1180      5  0.008182  accuracy\n",
       "...     ...       ...       ...\n",
       "1626      1  0.036457    writer\n",
       "1626      2  0.036457    writer\n",
       "1626      3  0.036457    writer\n",
       "1626      4  0.874957    writer\n",
       "1626      5  0.036457    writer\n",
       "\n",
       "[2523 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[8, 5, 6, 3, 1, 4, 7, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_data_filepath = os.path.join('./results/ldavis_tuned_'+str(num_topics))\n",
    "\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_tuned_'+ str(num_topics) +'.html')\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f8c8f",
   "metadata": {},
   "source": [
    "Hierarchical LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c333838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "# Assuming documents is a list of tokenized documents\n",
    "dictionary = Dictionary(data_lemmatized)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in data_lemmatized]\n",
    "\n",
    "# Training the top-level LDA model\n",
    "top_model = LdaModel(corpus, num_topics=10, id2word=dictionary)\n",
    "\n",
    "# For each topic, we collect the documents most relevant to that topic\n",
    "topic_docs = {}\n",
    "for i, doc in enumerate(corpus):\n",
    "    topic = max(top_model[doc], key=lambda x: x[1])[0]\n",
    "    if topic not in topic_docs:\n",
    "        topic_docs[topic] = []\n",
    "    topic_docs[topic].append(data_lemmatized[i])\n",
    "\n",
    "# Now we train a separate LDA model for each set of documents\n",
    "sub_models = {}\n",
    "for topic, docs in topic_docs.items():\n",
    "    sub_dictionary = Dictionary(docs)\n",
    "    sub_corpus = [sub_dictionary.doc2bow(doc) for doc in docs]\n",
    "    sub_model = LdaModel(sub_corpus, num_topics=5, id2word=sub_dictionary)\n",
    "    sub_models[topic] = sub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c258e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el126151406698450657285932770703\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el126151406698450657285932770703_data = {\"mdsDat\": {\"x\": [-0.01566058537739998, 0.0023460250222574076, 0.007087583561335048, 0.013278116536239741, -0.007051139742432214], \"y\": [0.0024467369345363282, 0.0030067455892287247, 0.0036836168764822646, -0.002915575171452859, -0.006221524228794458], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [43.592095287229036, 31.10219818459168, 24.978657052057226, 0.3152925215912936, 0.011756954530772513]}, \"tinfo\": {\"Term\": [\"use\", \"model\", \"prior\", \"distribution\", \"function\", \"prediction\", \"network\", \"set\", \"state\", \"learn\", \"log\", \"show\", \"vector\", \"parameter\", \"expert\", \"problem\", \"approximation\", \"likelihood\", \"stochastic\", \"sample\", \"result\", \"tempered_transition\", \"ard\", \"figure\", \"step\", \"well\", \"give\", \"method\", \"sparse\", \"update\", \"time_serie\", \"error\", \"hierarchical_mixture\", \"bit\", \"connectionist\", \"lag\", \"normalise\", \"expert\", \"overall\", \"gersho\", \"linear\", \"hme\", \"confidence\", \"gain\", \"weigend\", \"code\", \"book\", \"mlp\", \"acoustic_vector\", \"various\", \"switch\", \"quantization\", \"vq\", \"ar\", \"codebook\", \"tar\", \"vector\", \"acoustic\", \"understanding\", \"sunspot\", \"prediction\", \"predict\", \"rate\", \"use\", \"generate\", \"parameter\", \"tempered_transition\", \"consider\", \"learn\", \"problem\", \"probability\", \"training\", \"train\", \"result\", \"speech\", \"value\", \"network\", \"variance\", \"model\", \"stochastic\", \"distribution\", \"likelihood\", \"approximation\", \"method\", \"well\", \"step\", \"prior\", \"update\", \"show\", \"function\", \"state\", \"set\", \"datum\", \"sample\", \"figure\", \"lasso\", \"directly\", \"log\", \"version\", \"residual\", \"mean\", \"path\", \"non_factorial\", \"variational_approximation\", \"ssm\", \"deterministic\", \"sequence\", \"jointly\", \"gmm\", \"recurrent_neural\", \"intractable\", \"filtering\", \"matrix\", \"timit\", \"extension\", \"limitation\", \"fact\", \"parameterizing\", \"one\", \"benefit\", \"xt\", \"independence\", \"filter\", \"arise\", \"outer\", \"sample\", \"introduction\", \"obtain\", \"unit\", \"term\", \"space\", \"posterior\", \"present\", \"prior\", \"ard\", \"model\", \"show\", \"approximation\", \"sparse\", \"average\", \"figure\", \"method\", \"datum\", \"number\", \"state\", \"function\", \"distribution\", \"stochastic\", \"use\", \"set\", \"parameter\", \"follow\", \"well\", \"network\", \"learn\", \"problem\", \"inference\", \"likelihood\", \"result\", \"tempered_transition\", \"prediction\", \"storn\", \"optimize\", \"evidence\", \"propagate\", \"introduce\", \"latent\", \"dynamic\", \"modeling\", \"kalman_filter\", \"ut\", \"marginal\", \"analytically\", \"consequently\", \"flexible\", \"resq\", \"rnns\", \"try\", \"recurrent_neural\", \"inspire\", \"recurrent\", \"tsbn\", \"depend\", \"line\", \"still\", \"speed\", \"exploit\", \"factor\", \"filt\", \"decade\", \"nips_page\", \"also\", \"set\", \"one\", \"variational\", \"generative\", \"inference\", \"blizzard\", \"dependence\", \"state\", \"make\", \"sequence\", \"map\", \"log\", \"estimation\", \"model\", \"solve\", \"network\", \"unit\", \"update\", \"step\", \"posterior\", \"distribution\", \"rnn\", \"function\", \"prior\", \"time\", \"srnn\", \"figure\", \"likelihood\", \"stochastic\", \"use\", \"give\", \"datum\", \"ard\", \"term\", \"show\", \"learn\", \"result\", \"tempered_transition\", \"problem\", \"sample\", \"approximation\", \"parameter\", \"arxiv\", \"speak\", \"negligible\", \"factorial\", \"cancel\", \"try\", \"readily\", \"circumvent\", \"storn\", \"away\", \"symbol\", \"faul\", \"portion\", \"determine\", \"case\", \"knowledge\", \"difficulty\", \"process\", \"resq\", \"lar\", \"reuse\", \"expectation_maximization\", \"featureand\", \"elsewhere\", \"contrive\", \"unlimited\", \"merit\", \"criterion\", \"formalize\", \"extract\", \"ssm\", \"mean\", \"blizzard\", \"variational_approximation\", \"methodology\", \"rnn\", \"situation\", \"lead\", \"sparse\", \"solve\", \"long\", \"sparsity\", \"minimum\", \"posterior\", \"latent\", \"raw\", \"coefficient\", \"respect\", \"timit\", \"dependent\", \"show\", \"recurrent_neural\", \"section\", \"result\", \"inference\", \"depend\", \"deterministic\", \"norm\", \"compute\", \"prior\", \"model\", \"sequence\", \"use\", \"function\", \"distribution\", \"learn\", \"log\", \"set\", \"network\", \"ard\", \"step\", \"state\", \"stochastic\", \"test\", \"figure\", \"time\", \"sample\", \"parameter\", \"well\", \"unit\", \"datum\", \"term\", \"approximation\", \"problem\", \"likelihood\", \"situation\", \"abut\", \"cost\", \"upper\", \"sivp\", \"solid\", \"disparate\", \"utilise\", \"quantization\", \"contrive\", \"dp\", \"unimodal\", \"cone\", \"sigial\", \"vertical\", \"showmg\", \"sparsity\", \"popular\", \"crucial\", \"underway\", \"voicing\", \"aim\", \"waterhouse_robinson\", \"loose\", \"respectively\", \"degree\", \"attractive\", \"fljt\", \"multivariate\", \"elsewhere\", \"sin\", \"prediction\", \"regression\", \"particular\", \"often\", \"handle\", \"function\", \"vector\", \"follow\", \"procedure\", \"equivalent\", \"ard\", \"convex\", \"solve\", \"train\", \"exist\", \"low\", \"associate\", \"use\", \"describe\", \"generate\", \"variance\", \"expert\", \"solution\", \"give\", \"prior\", \"sparse\", \"image\", \"log\", \"likelihood\", \"distribution\", \"well\", \"linear\", \"also\", \"problem\", \"set\", \"number\", \"model\", \"approximation\", \"state\", \"sample\", \"show\", \"learn\", \"tempered_transition\", \"parameter\", \"network\", \"update\", \"step\", \"method\", \"stochastic\"], \"Freq\": [127.0, 129.0, 57.0, 60.0, 42.0, 39.0, 58.0, 49.0, 49.0, 48.0, 42.0, 41.0, 34.0, 48.0, 36.0, 43.0, 42.0, 37.0, 51.0, 37.0, 35.0, 40.0, 27.0, 34.0, 30.0, 27.0, 28.0, 31.0, 22.0, 28.0, 7.548900327312119, 14.817025464934868, 5.384069435906808, 4.3582044812261955, 3.076481497752155, 2.4579798854856656, 1.8211563395638435, 24.553474722519546, 4.962089612401527, 2.4188341522914265, 9.686292942328647, 10.032957016821854, 1.7943919939399984, 2.3794173690434297, 4.357213223569053, 14.602047384134435, 1.6821432445972169, 2.907103408025754, 6.5760911845888534, 3.707276027162596, 2.2743584459831436, 2.695718782062835, 1.691093924026649, 2.370743961763681, 2.7643374170135195, 2.263483000067236, 21.314565799511346, 1.5894657091073248, 1.7004255123910246, 4.050355007759689, 23.52436650033773, 3.4878215372247086, 10.492263582665633, 69.78089913672149, 8.90177531098104, 26.459923358590625, 21.81052906573864, 8.460081943178572, 25.205707483441543, 22.672228685994995, 14.522137006162321, 10.766131468115628, 11.647060475829962, 17.484573318813684, 13.609240425106384, 10.117200306844136, 26.25967453437, 11.108396520789457, 48.93936351337975, 22.519625561324432, 25.15810533856296, 17.014568636787875, 18.927822690277548, 14.309873314709419, 12.934607341090338, 13.955965165034865, 20.581098909709073, 13.178728941444158, 16.32482285953061, 16.57408468888094, 17.24621882362088, 17.14629974067611, 14.674877016943247, 14.138477904819649, 13.053842143074052, 2.0330946884017536, 4.134809345808349, 19.242800068811704, 1.3712916218684565, 3.6788663250194746, 7.025480095669348, 1.3408258428148039, 2.1069035717479982, 5.639467428229432, 3.192866917103303, 6.813780492366102, 10.212508148863312, 0.9758471831780244, 0.9917460455759014, 4.837509292358593, 2.9439380360728644, 0.9453397851552402, 4.379985028202521, 4.664850501778932, 2.4022083313516323, 1.8521121039958168, 1.5922922323931825, 0.9398699427722006, 3.1853186234018427, 1.7505966405194324, 0.6100973934081892, 1.91996059604286, 1.339894965205232, 1.3176089783446598, 0.9768875186764118, 14.897330206629421, 1.862331225676335, 8.021744990183636, 8.804025122529573, 10.61537089134162, 8.274387670559566, 9.955133114237354, 3.1018803591676716, 21.99298376869139, 10.514543111965182, 45.35117183009618, 15.141056439058643, 15.50362758006107, 8.37496684596039, 6.2092877174359895, 12.310854444368209, 11.123610643982216, 12.754632517939777, 8.652366153934427, 16.170511074156234, 14.028726783109127, 18.406645013304583, 16.029714656504378, 33.48525746091769, 15.148661057098328, 14.556117920585217, 7.587328410068687, 9.161276249437833, 15.64522308192025, 12.489647316078248, 11.275215785377284, 9.190680328588945, 10.153150620168557, 9.352806745380425, 9.494931640526957, 9.029485621786417, 2.1289578864886294, 3.0469918041283415, 1.7701263107940075, 1.1557673028107385, 2.7837883576377225, 4.787526993826248, 1.4766877579821274, 1.8323046441090085, 0.904510395035546, 1.2197315252562047, 1.2138735994459562, 0.8543349769972054, 1.6428580064669285, 0.5549334886735693, 2.1909010203554793, 0.82942918266253, 0.5167809293989659, 4.193653178138543, 0.8979163428615203, 2.499165383194412, 0.5683269886552853, 4.663133114209186, 1.7526290762438304, 1.0864644651319217, 0.8322426070419637, 1.1013753970814693, 2.5430740339374305, 1.452525833432189, 0.5266421481374537, 0.8518146327448968, 7.862458843436219, 17.11583129234067, 2.763040446110163, 3.0467567160963194, 5.262859841981338, 9.77385958012389, 3.985034053031839, 3.1552784768196367, 16.055748718127425, 4.241772021561206, 7.82776207823234, 4.476872532189715, 13.0207020600129, 5.285893121145312, 34.69268291691532, 4.603846363688057, 16.80560600563274, 6.996316542176673, 8.643347751168445, 9.272929990510624, 7.802081997509732, 16.302953477001846, 6.360241416505526, 11.71757634217267, 15.185143086743329, 8.228958188539272, 5.490423274320638, 9.47470370865646, 9.887538793454933, 12.43413446839528, 24.07551554832186, 7.7895338674062, 9.40368082877937, 7.525983916754638, 7.390516610916435, 9.706247816449828, 10.746350359096033, 8.540728148458557, 9.226379440518645, 9.542185338291944, 8.285075373024874, 8.165522301377147, 7.577804895309068, 0.034462647072912724, 0.012623949070072936, 0.007995847854037006, 0.03325620904584664, 0.008203013390367326, 0.008012499008595674, 0.015819591118426537, 0.00785054051308363, 0.028124266956964634, 0.015282217295470931, 0.00788591366891445, 0.007492814927837383, 0.00754990279244887, 0.011804618040503074, 0.04718506578317897, 0.01567675824592299, 0.011497376111945382, 0.011588505321292497, 0.03224705344796045, 0.007835768941976623, 0.012019649981649602, 0.00782628594069376, 0.007642536793635324, 0.007365636812679259, 0.0072473665026710175, 0.007502201594315578, 0.0074123444262943336, 0.007542059592366633, 0.007516070290318982, 0.007632001844412438, 0.03924540432499736, 0.08313940597469095, 0.05906076203335684, 0.06594688637882436, 0.0217474302682626, 0.10084814511421658, 0.027109252515337617, 0.04985134597036081, 0.10570039280963339, 0.06695408996636194, 0.04125261100080392, 0.027519773792584454, 0.0551104049982841, 0.11308862259511544, 0.05702762230940316, 0.027151201048967344, 0.03464871809971578, 0.030271149255107162, 0.051537106607724335, 0.03965666252834121, 0.1599075401777904, 0.051978677225372034, 0.06287007928900562, 0.13868289850242194, 0.11610563178866436, 0.057404416560583614, 0.06905170228571998, 0.04662154514725421, 0.06372516107871365, 0.1920165465538354, 0.3559828731599818, 0.09139693853593654, 0.3368260798651977, 0.13906474997926058, 0.17900284795928856, 0.14877993361119604, 0.13292086772441583, 0.14763655058124078, 0.16182809334521125, 0.09543196331670607, 0.10292849311150011, 0.13598670530363005, 0.13436743677670013, 0.08681734787102786, 0.10163190820882502, 0.08834481003228296, 0.09879117623799584, 0.11109479309685634, 0.08437274461699337, 0.07713515715175678, 0.08906009525376889, 0.08112871155705115, 0.09227559633535923, 0.09116772076742234, 0.08402160214445735, 0.0011536502172454688, 0.00032952061637259644, 0.001927918141936465, 0.0007065037960743689, 0.0003148031103391365, 0.0006771538438683643, 0.00042279685605386676, 0.0004925519203176248, 0.0008512131168279743, 0.00026720758198076777, 0.00027474875221463314, 0.0002730919990358638, 0.0002798850410478941, 0.00030161335177676934, 0.0003058817101364931, 0.00030204751366858006, 0.0010564236497387042, 0.00026918178883897625, 0.0002775767303833411, 0.0003033551648164539, 0.000305536777192492, 0.0003025552245461699, 0.0006301690736296928, 0.00026601008387719264, 0.0002982342937385006, 0.0005703457182926609, 0.00026250398668166923, 0.000295805053333337, 0.0002982696916460948, 0.00025594388912228097, 0.0006129794301711995, 0.006993066305727056, 0.0015154849017233179, 0.0014868507738708845, 0.0012454153333618795, 0.0012594500006475114, 0.006474750739435491, 0.0052337355495322745, 0.0033562930408194028, 0.0021878847803811106, 0.0011452815225940682, 0.004008159091474582, 0.0009601995509750071, 0.0021319015473839297, 0.0032342905600639374, 0.0014378834586002158, 0.0008421704460159805, 0.0007666540707535374, 0.014665868929336514, 0.0018000825055402344, 0.0022511623946445446, 0.0030056603519581374, 0.004789850612904887, 0.002296373126637285, 0.0036083970435878835, 0.0064229907128003465, 0.00295117673165068, 0.002335866283712723, 0.004793631424084013, 0.004270852470072217, 0.005805164968210763, 0.003267270921672802, 0.0020771016008859417, 0.002762147500024783, 0.004373314466774178, 0.0047428040143209504, 0.0028786035744116684, 0.008716440339359763, 0.0042094684078790206, 0.00457167993585905, 0.0037162609183127517, 0.003931232253808209, 0.004111647679938119, 0.0036441402249948102, 0.003910815789534773, 0.004142009540329217, 0.002963514082377507, 0.0030158604032450996, 0.003024100197071513, 0.003049731848181135], \"Total\": [127.0, 129.0, 57.0, 60.0, 42.0, 39.0, 58.0, 49.0, 49.0, 48.0, 42.0, 41.0, 34.0, 48.0, 36.0, 43.0, 42.0, 37.0, 51.0, 37.0, 35.0, 40.0, 27.0, 34.0, 30.0, 27.0, 28.0, 31.0, 22.0, 28.0, 10.785913777172272, 21.423427234617666, 7.836679230335981, 6.4699218538143715, 4.580209839236204, 3.671362660681485, 2.740992397696653, 36.97943250657737, 7.511847073070651, 3.6950967776485792, 14.827980910560774, 15.379364707079876, 2.754532501903874, 3.6736137888491243, 6.73959371905082, 22.67580990872912, 2.619039482427342, 4.534632333103338, 10.278346428541104, 5.799278374903447, 3.5617691206400477, 4.24346477427313, 2.6627681547919444, 3.7605457965265336, 4.388122575075249, 3.5997084649026845, 34.08405690818292, 2.5435825924230127, 2.7228191380534073, 6.493911173423006, 39.07019770606115, 5.668120208210097, 17.672529192121583, 127.69316409475557, 15.159887492655397, 48.708851783371294, 40.60501015342257, 14.826519472388819, 48.59459673990696, 43.58517084489842, 27.993005921541513, 20.05477741621734, 22.245543272686152, 35.51964594936096, 26.806878218096923, 19.045111427631173, 58.876473724808534, 21.34397175695832, 129.34791757389058, 51.12089185484897, 60.05251184179689, 37.1435505050259, 42.693457636459, 31.42353112435661, 27.547437876978986, 30.95911834976293, 57.957665302410426, 28.48067520925855, 41.33596588747067, 42.465927314881434, 49.61303700114403, 49.56317144471067, 36.924745111088555, 37.42339092163025, 34.943978080058315, 4.375303776127671, 9.01662649555936, 42.129842377693365, 3.033807407966906, 8.348182762933208, 16.052173352886648, 3.0639219408598466, 4.827480298759191, 13.01580876557554, 7.438250987026133, 15.91567065429024, 23.85641655791726, 2.282724421317106, 2.3223545402446346, 11.40166540031091, 6.983452349434897, 2.262207343578242, 10.498982689746969, 11.199001296288216, 5.778661225785842, 4.457316386618063, 3.8515156201508547, 2.285762083215096, 7.7681042296612635, 4.273385589964671, 1.4895507611007759, 4.688798350083621, 3.2791889595886228, 3.2270589642790486, 2.395774529763867, 37.42339092163025, 4.584407600178553, 20.07993403801527, 22.179767853499467, 26.89859600802062, 20.92390856625647, 25.518652747492197, 7.691758191982114, 57.957665302410426, 27.411047188151418, 129.34791757389058, 41.33596588747067, 42.693457636459, 22.33241700262361, 16.44249403687241, 34.943978080058315, 31.42353112435661, 36.924745111088555, 23.88765992229307, 49.61303700114403, 42.465927314881434, 60.05251184179689, 51.12089185484897, 127.69316409475557, 49.56317144471067, 48.708851783371294, 21.069842592239105, 27.547437876978986, 58.876473724808534, 48.59459673990696, 43.58517084489842, 29.0206843096136, 37.1435505050259, 35.51964594936096, 40.60501015342257, 39.07019770606115, 5.067897286506595, 7.66102271377416, 4.477863176561462, 2.930063500702163, 7.170028115532643, 12.3459524285739, 3.8086501800293093, 4.7530167716007306, 2.3571342196890748, 3.186698690988816, 3.1937471848854115, 2.253922857759522, 4.360670303850947, 1.4913960139240603, 5.919130167671127, 2.2476370171482083, 1.4026203773022887, 11.40166540031091, 2.4415268185311776, 6.838960672790906, 1.560137344906128, 12.80364990261857, 4.840251020337558, 3.0018968437525424, 2.301265594817791, 3.0459990845619536, 7.0447991098737655, 4.027574073680155, 1.4616739404145593, 2.364430490146019, 22.21297428276769, 49.56317144471067, 7.7681042296612635, 8.599605906352048, 15.042289695462934, 29.0206843096136, 11.470657515674972, 9.056836098796555, 49.61303700114403, 12.49706309287982, 23.85641655791726, 13.233676603306739, 42.129842377693365, 15.952553232375205, 129.34791757389058, 13.864197554808873, 58.876473724808534, 22.179767853499467, 28.48067520925855, 30.95911834976293, 25.518652747492197, 60.05251184179689, 20.287196714707818, 42.465927314881434, 57.957665302410426, 28.68184118771678, 17.59098344527816, 34.943978080058315, 37.1435505050259, 51.12089185484897, 127.69316409475557, 28.34269576947508, 36.924745111088555, 27.411047188151418, 26.89859600802062, 41.33596588747067, 48.59459673990696, 35.51964594936096, 40.60501015342257, 43.58517084489842, 37.42339092163025, 42.693457636459, 48.708851783371294, 4.913655738541642, 2.1068409284378684, 1.3403006513841536, 5.6254264605814095, 1.4262442971316691, 1.4026203773022887, 2.7694961390242656, 1.3832702007265811, 5.067897286506595, 2.756707415491029, 1.426589002450339, 1.3561258959223657, 1.3667843208164228, 2.1389815230897247, 8.5628530890606, 2.8544390074191535, 2.095661902664325, 2.1265997633743243, 5.919130167671127, 1.4413044764932954, 2.211738523056784, 1.440237073409654, 1.4098436651637316, 1.3604271505649874, 1.3406408095011717, 1.3890144536564488, 1.3725520451585818, 1.4023057918014836, 1.3997216326639867, 1.4224125835885473, 7.438250987026133, 16.052173352886648, 11.470657515674972, 13.01580876557554, 4.15888509263099, 20.287196714707818, 5.23258970242382, 9.952081592889792, 22.33241700262361, 13.864197554808873, 8.373321150598438, 5.466342355279235, 11.596047303570971, 25.518652747492197, 12.3459524285739, 5.420853208123831, 7.1284332011232765, 6.1371988866852405, 11.199001296288216, 8.358506393293304, 41.33596588747067, 11.40166540031091, 14.205612527340127, 35.51964594936096, 29.0206843096136, 12.80364990261857, 15.91567065429024, 10.099510387681011, 14.598162670453748, 57.957665302410426, 129.34791757389058, 23.85641655791726, 127.69316409475557, 42.465927314881434, 60.05251184179689, 48.59459673990696, 42.129842377693365, 49.56317144471067, 58.876473724808534, 27.411047188151418, 30.95911834976293, 49.61303700114403, 51.12089185484897, 25.357974202771036, 34.943978080058315, 28.68184118771678, 37.42339092163025, 48.708851783371294, 27.547437876978986, 22.179767853499467, 36.924745111088555, 26.89859600802062, 42.693457636459, 43.58517084489842, 37.1435505050259, 5.23258970242382, 1.4979536098466881, 9.0966040814089, 3.3742810377904, 1.528114302216282, 3.3047504538889467, 2.09705911321307, 2.4483020683456447, 4.24346477427313, 1.3406408095011717, 1.3902265782932446, 1.3896109671118522, 1.4330638565128906, 1.555290834299428, 1.5810645330081687, 1.5626776408172356, 5.466342355279235, 1.3929878177382313, 1.4368031908703944, 1.5705576111927713, 1.5823722870434513, 1.5675769147195857, 3.2866302191282175, 1.3925162365351094, 1.5710833003487448, 3.014555779209632, 1.391921789959831, 1.5704089082545474, 1.5841419931713245, 1.3604271505649874, 3.2840583731663413, 39.07019770606115, 8.341889259582521, 8.427282659543932, 7.064452180184978, 7.228770871269698, 42.465927314881434, 34.08405690818292, 21.069842592239105, 13.26520426214556, 6.780326818443304, 27.411047188151418, 5.647524042573356, 13.864197554808873, 22.245543272686152, 8.95409947908891, 4.916118355957118, 4.42908699009767, 127.69316409475557, 11.71480540256902, 15.159887492655397, 21.34397175695832, 36.97943250657737, 15.900342469990633, 28.34269576947508, 57.957665302410426, 22.33241700262361, 16.853265911246517, 42.129842377693365, 37.1435505050259, 60.05251184179689, 27.547437876978986, 14.827980910560774, 22.21297428276769, 43.58517084489842, 49.56317144471067, 23.88765992229307, 129.34791757389058, 42.693457636459, 49.61303700114403, 37.42339092163025, 41.33596588747067, 48.59459673990696, 40.60501015342257, 48.708851783371294, 58.876473724808534, 28.48067520925855, 30.95911834976293, 31.42353112435661, 51.12089185484897], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.0925, -5.4181, -6.4304, -6.6418, -6.9901, -7.2145, -7.5144, -4.913, -6.512, -7.2306, -5.8432, -5.808, -7.5292, -7.247, -6.642, -5.4327, -7.5938, -7.0467, -6.2304, -6.8036, -7.2922, -7.1222, -7.5885, -7.2507, -7.0971, -7.297, -5.0545, -7.6505, -7.583, -6.7151, -4.9558, -6.8646, -5.7632, -3.8685, -5.9276, -4.8382, -5.0315, -5.9785, -4.8868, -4.9927, -5.4382, -5.7375, -5.6588, -5.2525, -5.5031, -5.7996, -4.8458, -5.7062, -4.2233, -4.9995, -4.8887, -5.2798, -5.1732, -5.4529, -5.554, -5.478, -5.0895, -5.5353, -5.3212, -5.306, -5.2663, -5.2721, -5.4277, -5.465, -5.5448, -7.0667, -6.3568, -4.8191, -7.4605, -6.4737, -5.8267, -7.483, -7.031, -6.0465, -6.6153, -5.8573, -5.4527, -7.8007, -7.7846, -6.1999, -6.6965, -7.8325, -6.2992, -6.2362, -6.8999, -7.1599, -7.3111, -7.8383, -6.6177, -7.2163, -8.2704, -7.124, -7.4837, -7.5004, -7.7997, -5.0751, -7.1544, -5.6941, -5.6011, -5.414, -5.6631, -5.4782, -6.6443, -4.6855, -5.4235, -3.9618, -5.0589, -5.0352, -5.651, -5.9502, -5.2658, -5.3672, -5.2304, -5.6184, -4.9931, -5.1352, -4.8636, -5.0018, -4.2652, -5.0584, -5.0983, -5.7498, -5.5613, -5.0261, -5.2514, -5.3537, -5.5581, -5.4585, -5.5406, -5.5255, -5.5758, -6.8014, -6.4429, -6.986, -7.4122, -6.5332, -5.991, -7.1672, -6.9514, -7.6574, -7.3584, -7.3632, -7.7144, -7.0606, -8.1459, -6.7727, -7.744, -8.2171, -6.1234, -7.6647, -6.6411, -8.1221, -6.0173, -6.9959, -7.4741, -7.7406, -7.4605, -6.6236, -7.1837, -8.1982, -7.7174, -5.4949, -4.717, -6.5407, -6.4429, -5.8963, -5.2773, -6.1745, -6.4079, -4.7809, -6.112, -5.4993, -6.0581, -4.9905, -5.892, -4.0105, -6.0301, -4.7353, -5.6116, -5.4002, -5.3299, -5.5026, -4.7657, -5.7069, -5.0959, -4.8367, -5.4494, -5.854, -5.3084, -5.2657, -5.0366, -4.3758, -5.5042, -5.3159, -5.5386, -5.5568, -5.2842, -5.1824, -5.4122, -5.3349, -5.3013, -5.4426, -5.4571, -5.5318, -6.5526, -7.5569, -8.0136, -6.5882, -7.988, -8.0115, -7.3312, -8.0319, -6.7559, -7.3658, -8.0274, -8.0785, -8.071, -7.624, -6.2384, -7.3403, -7.6504, -7.6425, -6.6191, -8.0338, -7.6059, -8.035, -8.0588, -8.0957, -8.1119, -8.0773, -8.0893, -8.072, -8.0754, -8.0601, -6.4227, -5.672, -6.0139, -5.9036, -7.013, -5.4789, -6.7926, -6.1834, -5.4319, -5.8885, -6.3728, -6.7776, -6.0832, -5.3643, -6.049, -6.7911, -6.5472, -6.6823, -6.1502, -6.4122, -5.0179, -6.1417, -5.9514, -5.1603, -5.338, -6.0424, -5.8576, -6.2504, -5.9379, -4.8349, -4.2176, -5.5773, -4.2729, -5.1575, -4.9051, -5.09, -5.2027, -5.0977, -5.006, -5.5341, -5.4585, -5.1799, -5.1919, -5.6287, -5.4711, -5.6112, -5.4995, -5.3821, -5.6572, -5.7469, -5.6032, -5.6965, -5.5677, -5.5798, -5.6614, -6.6605, -7.9135, -6.147, -7.1509, -7.9592, -7.1933, -7.6643, -7.5116, -6.9645, -8.1232, -8.0953, -8.1014, -8.0768, -8.002, -7.988, -8.0006, -6.7485, -8.1158, -8.0851, -7.9963, -7.9891, -7.9989, -7.2652, -8.1277, -8.0133, -7.3649, -8.1409, -8.0215, -8.0132, -8.1662, -7.2929, -4.8585, -6.3877, -6.4068, -6.584, -6.5728, -4.9355, -5.1483, -5.5926, -6.0205, -6.6678, -5.4151, -6.844, -6.0464, -5.6296, -6.4403, -6.9752, -7.0692, -4.1179, -6.2156, -5.992, -5.7029, -5.2369, -5.9721, -5.5202, -4.9435, -5.7212, -5.9551, -5.2361, -5.3516, -5.0447, -5.6195, -6.0725, -5.7874, -5.3279, -5.2468, -5.7461, -4.6382, -5.3661, -5.2836, -5.4907, -5.4345, -5.3896, -5.5103, -5.4397, -5.3823, -5.7171, -5.6995, -5.6968, -5.6884], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4735, 0.4616, 0.4549, 0.4352, 0.4323, 0.4291, 0.4214, 0.4208, 0.4156, 0.4066, 0.4045, 0.4031, 0.4017, 0.396, 0.3941, 0.3902, 0.3876, 0.3857, 0.3837, 0.3829, 0.3817, 0.3766, 0.3763, 0.3689, 0.3682, 0.3663, 0.3609, 0.3601, 0.3595, 0.3582, 0.323, 0.3447, 0.3089, 0.226, 0.2979, 0.2201, 0.2088, 0.2692, 0.1739, 0.1767, 0.174, 0.2082, 0.1832, 0.1215, 0.1524, 0.1977, 0.0229, 0.1772, -0.1416, 0.0105, -0.0397, 0.0496, 0.0169, 0.0437, 0.0743, 0.0335, -0.205, 0.0597, -0.0988, -0.1106, -0.2264, -0.2312, -0.0925, -0.1431, -0.1544, 0.4015, 0.3883, 0.3843, 0.3738, 0.3485, 0.3416, 0.3415, 0.3388, 0.3315, 0.3222, 0.3195, 0.3195, 0.3181, 0.317, 0.3105, 0.3041, 0.2953, 0.2937, 0.2921, 0.2901, 0.2897, 0.2846, 0.2792, 0.2764, 0.2754, 0.2753, 0.275, 0.2729, 0.2721, 0.2708, 0.2468, 0.2671, 0.2503, 0.2439, 0.2381, 0.2402, 0.2266, 0.2598, 0.1989, 0.2097, 0.1198, 0.1636, 0.1549, 0.1871, 0.1941, 0.1246, 0.1294, 0.1049, 0.1524, 0.0468, 0.0603, -0.0146, 0.0081, -0.1706, -0.0174, -0.04, 0.1465, 0.067, -0.1574, -0.1907, -0.1842, 0.0181, -0.1291, -0.1665, -0.2852, -0.297, 0.5199, 0.4652, 0.4591, 0.4569, 0.4411, 0.4398, 0.4397, 0.4339, 0.4293, 0.4268, 0.4198, 0.417, 0.411, 0.3985, 0.3933, 0.3903, 0.3887, 0.387, 0.3868, 0.3805, 0.3773, 0.3771, 0.3713, 0.3708, 0.3701, 0.3699, 0.3682, 0.3673, 0.3663, 0.3662, 0.3486, 0.3239, 0.3535, 0.3495, 0.337, 0.2989, 0.3299, 0.3327, 0.259, 0.3066, 0.2728, 0.3033, 0.2129, 0.2826, 0.0712, 0.2847, 0.1334, 0.2334, 0.1947, 0.1816, 0.2021, 0.0833, 0.2272, 0.0995, 0.0478, 0.1385, 0.2228, 0.082, 0.0636, -0.0266, -0.2813, 0.0956, 0.0194, 0.0946, 0.0953, -0.0618, -0.1218, -0.0381, -0.0947, -0.1318, -0.1207, -0.267, -0.4735, 0.7995, 0.6421, 0.6377, 0.6286, 0.6011, 0.5943, 0.5943, 0.5878, 0.5654, 0.5643, 0.5615, 0.561, 0.5607, 0.5598, 0.5583, 0.555, 0.5539, 0.5472, 0.5469, 0.5448, 0.5444, 0.5443, 0.5419, 0.5407, 0.5392, 0.5383, 0.5381, 0.534, 0.5324, 0.5317, 0.5149, 0.4963, 0.4904, 0.4744, 0.5059, 0.4553, 0.4966, 0.4629, 0.4062, 0.4264, 0.4463, 0.468, 0.4103, 0.3404, 0.3819, 0.4628, 0.4328, 0.4475, 0.3781, 0.4086, 0.2045, 0.3687, 0.3391, 0.2138, 0.2382, 0.3521, 0.3192, 0.3812, 0.3254, 0.0495, -0.136, 0.1948, -0.1784, 0.0379, -0.0561, -0.0294, 0.0007, -0.0568, -0.1372, 0.0991, 0.053, -0.14, -0.1819, 0.0824, -0.0807, -0.0233, -0.1776, -0.3238, -0.029, 0.098, -0.2679, -0.0444, -0.3776, -0.4103, -0.332, 0.6287, 0.6265, 0.5893, 0.5771, 0.5609, 0.5555, 0.5393, 0.5372, 0.5343, 0.5278, 0.5194, 0.5138, 0.5075, 0.5005, 0.4981, 0.4972, 0.497, 0.4969, 0.4966, 0.4964, 0.4961, 0.4957, 0.4891, 0.4854, 0.4791, 0.4758, 0.4726, 0.4713, 0.4709, 0.4701, 0.4622, 0.4203, 0.4352, 0.4059, 0.4051, 0.3933, 0.2599, 0.267, 0.3037, 0.3385, 0.3624, 0.2181, 0.3689, 0.2684, 0.2124, 0.3118, 0.3764, 0.3868, -0.0234, 0.2677, 0.2335, 0.1805, 0.0969, 0.2057, 0.0796, -0.0591, 0.1169, 0.1646, -0.0327, -0.0223, -0.1957, 0.0088, 0.1752, 0.0561, -0.1585, -0.2059, 0.0247, -0.5566, -0.176, -0.2436, -0.1689, -0.2121, -0.329, -0.27, -0.3814, -0.5135, -0.1221, -0.1881, -0.2002, -0.6784]}, \"token.table\": {\"Topic\": [1, 1, 2, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 3, 1, 2, 1, 1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2], \"Freq\": [0.6675774159003145, 0.7862925332001125, 0.39314626660005625, 0.6810434001876284, 0.19458382862503668, 0.09729191431251834, 0.6379272306257993, 0.36014987899239653, 0.2701124092442974, 0.36014987899239653, 0.44367090761661426, 0.44367090761661426, 0.44367090761661426, 0.44503305779981006, 0.3747646802524716, 0.1873823401262358, 0.5318376927751606, 0.2659188463875803, 0.2659188463875803, 0.32833477459738575, 0.4012980578412492, 0.291853132975454, 0.30987968025040663, 0.30987968025040663, 0.30987968025040663, 0.4070289223382983, 0.4070289223382983, 0.4070289223382983, 0.4515603338727596, 0.2257801669363798, 0.2257801669363798, 0.7184311699214498, 0.3649081451113777, 0.3649081451113777, 0.24327209674091846, 0.3627515906768359, 0.3627515906768359, 0.3627515906768359, 0.23400649881637925, 0.4680129976327585, 0.23400649881637925, 0.6182454889531288, 0.1545613722382822, 0.1545613722382822, 0.2615368819006597, 0.34871584253421295, 0.34871584253421295, 0.7636387360401256, 0.3818193680200628, 0.7011421549667948, 0.3503505162120117, 0.3503505162120117, 0.2335670108080078, 0.7229245591170378, 0.6614978719779135, 0.22049929065930451, 0.1322995743955827, 0.6836636736266546, 0.22788789120888486, 0.22788789120888486, 0.2805665626052084, 0.2805665626052084, 0.2805665626052084, 0.4110106275321773, 0.34250885627681443, 0.27400708502145155, 0.6978056110027955, 0.6978056110027955, 0.7260760214728426, 0.3630380107364213, 0.6549918246759368, 0.21833060822531222, 0.21833060822531222, 0.22932254225156418, 0.45864508450312835, 0.45864508450312835, 0.5395737020342682, 0.2697868510171341, 0.13489342550856706, 0.7459119496534512, 0.35413749192091587, 0.35413749192091587, 0.35413749192091587, 0.32979340126841644, 0.4397245350245552, 0.2198622675122776, 0.7131112242753713, 0.6959895456483602, 0.406231646416849, 0.35206742689460246, 0.24373898785010942, 0.6841471085653894, 0.6634476674120019, 0.33172383370600095, 0.33172383370600095, 0.31241091645140423, 0.31241091645140423, 0.3905136455642553, 0.3312415028023562, 0.3312415028023562, 0.3312415028023562, 0.3589157989287583, 0.3589157989287583, 0.23927719928583885, 0.5975344668094036, 0.25608620006117294, 0.25608620006117294, 0.4675122198136223, 0.4675122198136223, 0.4675122198136223, 0.2513246275878269, 0.4398180982786971, 0.31415578448478365, 0.4771762080174515, 0.4771762080174515, 0.4771762080174515, 0.22181244847892828, 0.44362489695785656, 0.22181244847892828, 0.4768582791487556, 0.4768582791487556, 0.4768582791487556, 0.4163023199738975, 0.2997376703812062, 0.2664334847832944, 0.7193072090649292, 0.2625602123407156, 0.2625602123407156, 0.2625602123407156, 0.7350632480281641, 0.4424565482359404, 0.2949710321572936, 0.2949710321572936, 0.7001680840198068, 0.23338936133993562, 0.09335574453597424, 0.313429450895212, 0.37611534107425443, 0.313429450895212, 0.2233208029299138, 0.2233208029299138, 0.4466416058598276, 0.4467227563577398, 0.3350420672683048, 0.2233613781788699, 0.6943301338803719, 0.6760514779547621, 0.24337853206371432, 0.10816823647276193, 0.3282995077274655, 0.3282995077274655, 0.3282995077274655, 0.3461009257776691, 0.3461009257776691, 0.17305046288883455, 0.7030309008354948, 0.2596380486601356, 0.5192760973202712, 0.2596380486601356, 0.2838973785919408, 0.2838973785919408, 0.42584606788791124, 0.3555286010784136, 0.3555286010784136, 0.3555286010784136, 0.7373946644679714, 0.7092985021739027, 0.37202404288991886, 0.34340680882146357, 0.2575551066160977, 0.2482884192087025, 0.2482884192087025, 0.2482884192087025, 0.3049534541386877, 0.3049534541386877, 0.3049534541386877, 0.44204612934296816, 0.44204612934296816, 0.44204612934296816, 0.6705127214125158, 0.6367768259232965, 0.4271507943450452, 0.3796895949733735, 0.18984479748668676, 0.7144277666815607, 0.40032094139723756, 0.32967606938596034, 0.28257948804510885, 0.5444230436173758, 0.2722115218086879, 0.2722115218086879, 0.5936719520088974, 0.26385420089284334, 0.1978906506696325, 0.3988754452594889, 0.265916963506326, 0.33239620438290746, 0.5412578128123412, 0.2706289064061706, 0.423389507392022, 0.28225967159468135, 0.28225967159468135, 0.43059747453317826, 0.43059747453317826, 0.43059747453317826, 0.2766722082655678, 0.2766722082655678, 0.2766722082655678, 0.6380253488805405, 0.2552101395522162, 0.1276050697761081, 0.6502219168647785, 0.19506657505943356, 0.1300443833729557, 0.47468544329211837, 0.29667840205757395, 0.1780070412345444, 0.2132742603405339, 0.4265485206810678, 0.4265485206810678, 0.34458181252077946, 0.3101236312687015, 0.34458181252077946, 0.4095797729560062, 0.4095797729560062, 0.4095797729560062, 0.2863913004521096, 0.4295869506781644, 0.2863913004521096, 0.2789389340980883, 0.2789389340980883, 0.4184084011471324, 0.43626138302408024, 0.43626138302408024, 0.21813069151204012, 0.4380730282909101, 0.4380730282909101, 0.4380730282909101, 0.42424397883117076, 0.42424397883117076, 0.42424397883117076, 0.35033153533876066, 0.35033153533876066, 0.35033153533876066, 0.5447568613743967, 0.27237843068719836, 0.27237843068719836, 0.6938159259957393, 0.6938159259957393, 0.22855555892053792, 0.45711111784107583, 0.22855555892053792, 0.24299461846756318, 0.40499103077927195, 0.40499103077927195, 0.4019259652028755, 0.3014444739021566, 0.3014444739021566, 0.5144604889676848, 0.24694103470448872, 0.22636261514578135, 0.45768376390673066, 0.2692257434745474, 0.2692257434745474, 0.4487004795092584, 0.4487004795092584, 0.2243502397546292, 0.41320171032380065, 0.20660085516190033, 0.41320171032380065, 0.6744006524096485, 0.20232019572289456, 0.1348801304819297, 0.23736143872436455, 0.4509867335762926, 0.3085698703416739, 0.3582807760556982, 0.3582807760556982, 0.3582807760556982, 0.7181244812543247, 0.610237545718309, 0.20341251523943635, 0.20341251523943635, 0.3200752024912952, 0.3200752024912952, 0.3200752024912952, 0.30225916197774605, 0.3778239524721826, 0.30225916197774605, 0.31311182197907095, 0.31311182197907095, 0.31311182197907095, 0.3809892937442687, 0.3809892937442687, 0.19049464687213435, 0.31148430122708926, 0.436078021717925, 0.24918744098167142, 0.72856982256324, 0.4455259959358449, 0.35005613966387816, 0.19093971254393355, 0.24044905731391125, 0.4808981146278225, 0.24044905731391125, 0.34494512615244427, 0.34494512615244427, 0.2587088446143332, 0.661575135452472, 0.220525045150824, 0.220525045150824, 0.378823261472366, 0.3478989135970708, 0.27058804390883284, 0.21039269332584704, 0.21039269332584704, 0.42078538665169407, 0.6312565441170338, 0.7461012564362192, 0.4416025341722272, 0.27175540564444756, 0.28874011849722553, 0.42293482687166817, 0.42293482687166817, 0.42293482687166817, 0.2071474015662022, 0.4142948031324044, 0.2071474015662022, 0.2970441026190025, 0.39605880349200334, 0.2970441026190025, 0.7296627315277002, 0.3648313657638501, 0.4186261874344392, 0.37676356869099525, 0.2093130937172196, 0.34860672284817373, 0.3984076832550557, 0.24900480203440983, 0.4246613783323036, 0.2831075855548691, 0.2831075855548691, 0.2574630747568139, 0.3861946121352208, 0.3861946121352208, 0.2610617504636938, 0.3915926256955407, 0.3915926256955407, 0.4174015490925861, 0.4174015490925861, 0.4174015490925861, 0.665615254326008, 0.2662461017304032, 0.1331230508652016, 0.533783882150064, 0.30795223970196, 0.16424119450771202, 0.43749085145091954, 0.43749085145091954, 0.43749085145091954, 0.4746488472734427, 0.355986635455082, 0.23732442363672135, 0.3263790720854214, 0.3263790720854214, 0.3263790720854214, 0.7178813678526504, 0.7316443309816936, 0.31349617392266865, 0.39187021740333583, 0.31349617392266865, 0.5292760015312648, 0.17642533384375492, 0.17642533384375492, 0.6142789494069225, 0.23035460602759597, 0.15356973735173063, 0.2600185744378703, 0.3900278616568055, 0.2600185744378703, 0.36233343580053806, 0.37958740893389703, 0.2588095970003843, 0.5358481344247857, 0.32150888065487143, 0.1786160448082619, 0.5277024169951628, 0.2523794168237735, 0.22943583347615776, 0.37692597122445537, 0.30154077697956433, 0.30154077697956433, 0.47023422894267475, 0.47023422894267475, 0.47023422894267475, 0.3412895316979851, 0.3412895316979851, 0.3412895316979851, 0.7069694600007312, 0.23565648666691041, 0.23565648666691041, 0.5658499635953637, 0.22633998543814549, 0.16975498907860911, 0.36894561118215635, 0.36894561118215635, 0.36894561118215635, 0.36107650987818846, 0.36107650987818846, 0.36107650987818846, 0.2924420969339807, 0.2924420969339807, 0.2924420969339807, 0.17541297080560375, 0.4385324270140094, 0.3508259416112075, 0.59938460514282, 0.239753842057128, 0.239753842057128, 0.35935964570880136, 0.4791461942784018, 0.2395730971392009, 0.32588156859948514, 0.32588156859948514, 0.16294078429974257, 0.636503487611397, 0.16894374201496037, 0.33788748402992075, 0.33788748402992075, 0.4786083742004712, 0.25338090398848473, 0.25338090398848473, 0.4521330119158602, 0.4521330119158602, 0.4521330119158602, 0.3943373799988915, 0.2957530349991686, 0.2957530349991686, 0.44491169720491414, 0.44491169720491414, 0.44491169720491414, 0.37409758055644754, 0.4008188363104795, 0.21377004603225574, 0.28157884725502674, 0.3519735590687834, 0.3519735590687834, 0.2515046627155231, 0.4191744378592051, 0.33533955028736406, 0.3429966143099631, 0.3026440714499674, 0.3429966143099631, 0.3870721212504618, 0.36288011367230794, 0.24192007578153862, 0.6399272465926041, 0.642966561588749, 0.60900257326172, 0.30450128663086, 0.30450128663086, 0.3822199166645089, 0.3822199166645089, 0.3822199166645089, 0.6544013092146721, 0.6051894168427908, 0.3025947084213954, 0.3025947084213954, 0.37735036281916856, 0.37735036281916856, 0.25156690854611236, 0.43276936701748503, 0.21638468350874251, 0.3606411391812375, 0.33454552613027316, 0.3823377441488836, 0.2867533081116627, 0.4030016096754185, 0.35822365304481646, 0.22388978315301028, 0.36587536418542427, 0.36587536418542427, 0.36587536418542427, 0.4746442821107794, 0.4746442821107794, 0.5222540232435126, 0.2984308704248643, 0.18651929401554018, 0.4345434973919982, 0.4345434973919982, 0.4345434973919982, 0.34108382960308814, 0.34108382960308814, 0.2842365246692401, 0.26888041335099055, 0.40332062002648583, 0.26888041335099055, 0.3426518719184233, 0.3224958794526337, 0.3224958794526337, 0.45220926002588197, 0.25840529144336116, 0.29070595287378126, 0.33312270609203976, 0.33312270609203976, 0.33312270609203976, 0.449913903405783, 0.312983584977936, 0.23473768873345202, 0.19732049476664126, 0.3946409895332825, 0.3946409895332825, 0.6159616128367151, 0.30798080641835757, 0.15399040320917878, 0.5615187094554296, 0.2807593547277148, 0.5556005491833819, 0.27780027459169093, 0.27780027459169093, 0.5418050609241292, 0.2216475249235074, 0.2216475249235074, 0.3345899539632619, 0.40894327706620903, 0.26023663086031484, 0.43378859494217625, 0.3154826145034009, 0.23661196087755068, 0.4183831826367929, 0.3137873869775947, 0.27892212175786196, 0.7417081357475258, 0.18542703393688145, 0.09271351696844073, 0.2678810298016767, 0.44646838300279457, 0.2678810298016767, 0.5394338925736202, 0.22476412190567505, 0.2697169462868101, 0.5484977355622419, 0.24931715252829179, 0.19945372202263342, 0.7129512847398786, 0.6409692090667627, 0.6409692090667627, 0.7345328127191865, 0.36726640635959323, 0.6367165348621263, 0.7196258691584637, 0.2705168079138996, 0.40577521187084936, 0.3156029425662162, 0.7199349131087835, 0.45644985255735565, 0.24578068983857612, 0.31600374407816934, 0.29635942851246194, 0.29635942851246194, 0.29635942851246194, 0.54818909450827, 0.2584320016967559, 0.18795054668854974, 0.31380437781198106, 0.31380437781198106, 0.31380437781198106, 0.4084463322271812, 0.4084463322271812, 0.5250691253762749, 0.26253456268813746, 0.21002765015051, 0.5153679982927218, 0.32796145345900485, 0.18740654483371705, 0.34885319544516197, 0.34885319544516197, 0.34885319544516197, 0.23048894264138678, 0.46097788528277356, 0.3073185901885157, 0.6897409886909587, 0.17243524717273967, 0.17243524717273967, 0.6161238392651054, 0.23471384352956395, 0.14669615220597748, 0.32961881409279903, 0.32961881409279903, 0.32961881409279903, 0.6324852522606257, 0.6319625338411531, 0.7510980617673303, 0.37554903088366515, 0.6085260180351236, 0.3042630090175618, 0.3042630090175618, 0.5935075861758838, 0.14837689654397096, 0.14837689654397096, 0.47191321596060015, 0.3267091495111847, 0.18150508306176927, 0.6713433513746128], \"Term\": [\"abut\", \"acoustic\", \"acoustic\", \"acoustic_vector\", \"acoustic_vector\", \"acoustic_vector\", \"aim\", \"also\", \"also\", \"also\", \"analytically\", \"analytically\", \"analytically\", \"approximation\", \"approximation\", \"approximation\", \"ar\", \"ar\", \"ar\", \"ard\", \"ard\", \"ard\", \"arise\", \"arise\", \"arise\", \"arxiv\", \"arxiv\", \"arxiv\", \"associate\", \"associate\", \"associate\", \"attractive\", \"average\", \"average\", \"average\", \"away\", \"away\", \"away\", \"benefit\", \"benefit\", \"benefit\", \"bit\", \"bit\", \"bit\", \"blizzard\", \"blizzard\", \"blizzard\", \"book\", \"book\", \"cancel\", \"case\", \"case\", \"case\", \"circumvent\", \"code\", \"code\", \"code\", \"codebook\", \"codebook\", \"codebook\", \"coefficient\", \"coefficient\", \"coefficient\", \"compute\", \"compute\", \"compute\", \"cone\", \"cone\", \"confidence\", \"confidence\", \"connectionist\", \"connectionist\", \"connectionist\", \"consequently\", \"consequently\", \"consequently\", \"consider\", \"consider\", \"consider\", \"contrive\", \"convex\", \"convex\", \"convex\", \"cost\", \"cost\", \"cost\", \"criterion\", \"crucial\", \"datum\", \"datum\", \"datum\", \"decade\", \"degree\", \"degree\", \"degree\", \"depend\", \"depend\", \"depend\", \"dependence\", \"dependence\", \"dependence\", \"dependent\", \"dependent\", \"dependent\", \"describe\", \"describe\", \"describe\", \"determine\", \"determine\", \"determine\", \"deterministic\", \"deterministic\", \"deterministic\", \"difficulty\", \"difficulty\", \"difficulty\", \"directly\", \"directly\", \"directly\", \"disparate\", \"disparate\", \"disparate\", \"distribution\", \"distribution\", \"distribution\", \"dp\", \"dynamic\", \"dynamic\", \"dynamic\", \"elsewhere\", \"equivalent\", \"equivalent\", \"equivalent\", \"error\", \"error\", \"error\", \"estimation\", \"estimation\", \"estimation\", \"evidence\", \"evidence\", \"evidence\", \"exist\", \"exist\", \"exist\", \"expectation_maximization\", \"expert\", \"expert\", \"expert\", \"exploit\", \"exploit\", \"exploit\", \"extension\", \"extension\", \"extension\", \"extract\", \"fact\", \"fact\", \"fact\", \"factor\", \"factor\", \"factor\", \"factorial\", \"factorial\", \"factorial\", \"faul\", \"featureand\", \"figure\", \"figure\", \"figure\", \"filt\", \"filt\", \"filt\", \"filter\", \"filter\", \"filter\", \"filtering\", \"filtering\", \"filtering\", \"flexible\", \"fljt\", \"follow\", \"follow\", \"follow\", \"formalize\", \"function\", \"function\", \"function\", \"gain\", \"gain\", \"gain\", \"generate\", \"generate\", \"generate\", \"generative\", \"generative\", \"generative\", \"gersho\", \"gersho\", \"give\", \"give\", \"give\", \"gmm\", \"gmm\", \"gmm\", \"handle\", \"handle\", \"handle\", \"hierarchical_mixture\", \"hierarchical_mixture\", \"hierarchical_mixture\", \"hme\", \"hme\", \"hme\", \"image\", \"image\", \"image\", \"independence\", \"independence\", \"independence\", \"inference\", \"inference\", \"inference\", \"inspire\", \"inspire\", \"inspire\", \"intractable\", \"intractable\", \"intractable\", \"introduce\", \"introduce\", \"introduce\", \"introduction\", \"introduction\", \"introduction\", \"jointly\", \"jointly\", \"jointly\", \"kalman_filter\", \"kalman_filter\", \"kalman_filter\", \"knowledge\", \"knowledge\", \"knowledge\", \"lag\", \"lag\", \"lag\", \"lar\", \"lar\", \"lasso\", \"lasso\", \"lasso\", \"latent\", \"latent\", \"latent\", \"lead\", \"lead\", \"lead\", \"learn\", \"learn\", \"learn\", \"likelihood\", \"likelihood\", \"likelihood\", \"limitation\", \"limitation\", \"limitation\", \"line\", \"line\", \"line\", \"linear\", \"linear\", \"linear\", \"log\", \"log\", \"log\", \"long\", \"long\", \"long\", \"loose\", \"low\", \"low\", \"low\", \"make\", \"make\", \"make\", \"map\", \"map\", \"map\", \"marginal\", \"marginal\", \"marginal\", \"matrix\", \"matrix\", \"matrix\", \"mean\", \"mean\", \"mean\", \"merit\", \"method\", \"method\", \"method\", \"methodology\", \"methodology\", \"methodology\", \"minimum\", \"minimum\", \"minimum\", \"mlp\", \"mlp\", \"mlp\", \"model\", \"model\", \"model\", \"modeling\", \"modeling\", \"modeling\", \"multivariate\", \"negligible\", \"network\", \"network\", \"network\", \"nips_page\", \"nips_page\", \"nips_page\", \"non_factorial\", \"non_factorial\", \"non_factorial\", \"norm\", \"norm\", \"norm\", \"normalise\", \"normalise\", \"number\", \"number\", \"number\", \"obtain\", \"obtain\", \"obtain\", \"often\", \"often\", \"often\", \"one\", \"one\", \"one\", \"optimize\", \"optimize\", \"optimize\", \"outer\", \"outer\", \"outer\", \"overall\", \"overall\", \"overall\", \"parameter\", \"parameter\", \"parameter\", \"parameterizing\", \"parameterizing\", \"parameterizing\", \"particular\", \"particular\", \"particular\", \"path\", \"path\", \"path\", \"popular\", \"portion\", \"posterior\", \"posterior\", \"posterior\", \"predict\", \"predict\", \"predict\", \"prediction\", \"prediction\", \"prediction\", \"present\", \"present\", \"present\", \"prior\", \"prior\", \"prior\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"procedure\", \"procedure\", \"procedure\", \"process\", \"process\", \"process\", \"propagate\", \"propagate\", \"propagate\", \"quantization\", \"quantization\", \"quantization\", \"rate\", \"rate\", \"rate\", \"raw\", \"raw\", \"raw\", \"readily\", \"readily\", \"readily\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent_neural\", \"recurrent_neural\", \"recurrent_neural\", \"regression\", \"regression\", \"regression\", \"residual\", \"residual\", \"residual\", \"respect\", \"respect\", \"respect\", \"respectively\", \"resq\", \"resq\", \"resq\", \"result\", \"result\", \"result\", \"reuse\", \"reuse\", \"reuse\", \"rnn\", \"rnn\", \"rnn\", \"rnns\", \"rnns\", \"rnns\", \"sample\", \"sample\", \"sample\", \"section\", \"section\", \"section\", \"sequence\", \"sequence\", \"sequence\", \"set\", \"set\", \"set\", \"show\", \"show\", \"show\", \"showmg\", \"sigial\", \"sin\", \"sin\", \"sin\", \"situation\", \"situation\", \"situation\", \"sivp\", \"solid\", \"solid\", \"solid\", \"solution\", \"solution\", \"solution\", \"solve\", \"solve\", \"solve\", \"space\", \"space\", \"space\", \"sparse\", \"sparse\", \"sparse\", \"sparsity\", \"sparsity\", \"sparsity\", \"speak\", \"speak\", \"speech\", \"speech\", \"speech\", \"speed\", \"speed\", \"speed\", \"srnn\", \"srnn\", \"srnn\", \"ssm\", \"ssm\", \"ssm\", \"state\", \"state\", \"state\", \"step\", \"step\", \"step\", \"still\", \"still\", \"still\", \"stochastic\", \"stochastic\", \"stochastic\", \"storn\", \"storn\", \"storn\", \"sunspot\", \"sunspot\", \"sunspot\", \"switch\", \"switch\", \"tar\", \"tar\", \"tar\", \"tempered_transition\", \"tempered_transition\", \"tempered_transition\", \"term\", \"term\", \"term\", \"test\", \"test\", \"test\", \"time\", \"time\", \"time\", \"time_serie\", \"time_serie\", \"time_serie\", \"timit\", \"timit\", \"timit\", \"train\", \"train\", \"train\", \"training\", \"training\", \"training\", \"try\", \"tsbn\", \"tsbn\", \"understanding\", \"understanding\", \"underway\", \"unimodal\", \"unit\", \"unit\", \"unit\", \"unlimited\", \"update\", \"update\", \"update\", \"upper\", \"upper\", \"upper\", \"use\", \"use\", \"use\", \"ut\", \"ut\", \"ut\", \"utilise\", \"utilise\", \"value\", \"value\", \"value\", \"variance\", \"variance\", \"variance\", \"variational\", \"variational\", \"variational\", \"variational_approximation\", \"variational_approximation\", \"variational_approximation\", \"various\", \"various\", \"various\", \"vector\", \"vector\", \"vector\", \"version\", \"version\", \"version\", \"vertical\", \"voicing\", \"vq\", \"vq\", \"waterhouse_robinson\", \"waterhouse_robinson\", \"waterhouse_robinson\", \"weigend\", \"weigend\", \"weigend\", \"well\", \"well\", \"well\", \"xt\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 2, 1, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el126151406698450657285932770703\", ldavis_el126151406698450657285932770703_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el126151406698450657285932770703\", ldavis_el126151406698450657285932770703_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el126151406698450657285932770703\", ldavis_el126151406698450657285932770703_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "vis = gensimvis.prepare(sub_model, sub_corpus, sub_dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c7e77f",
   "metadata": {},
   "source": [
    "Correlated Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b689cff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'idx2token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m ctm \u001b[38;5;241m=\u001b[39m CombinedTM(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprodLDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, bow_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_lemmatized), contextual_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# fit the CTM to the data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mctm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lemmatized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# visualize\u001b[39;00m\n\u001b[1;32m     12\u001b[0m topics \u001b[38;5;241m=\u001b[39m ctm\u001b[38;5;241m.\u001b[39mget_topic_lists(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# get top 5 words for each topic\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/contextualized_topic_models/models/ctm.py:331\u001b[0m, in \u001b[0;36mCTM.fit\u001b[0;34m(self, train_dataset, validation_dataset, save_dir, verbose, patience, delta, n_samples, do_train_predictions)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSettings: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124m           N Components: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m=\u001b[39m save_dir\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx2token \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx2token\u001b[49m\n\u001b[1;32m    332\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_dataset\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_data \u001b[38;5;241m=\u001b[39m validation_dataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'idx2token'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "# initialize the CTM\n",
    "ctm = CombinedTM(n_components=10, model_type=\"prodLDA\", bow_size=len(data_lemmatized), contextual_size=768)\n",
    "\n",
    "# fit the CTM to the data\n",
    "ctm.fit(data_lemmatized)\n",
    "\n",
    "# visualize\n",
    "topics = ctm.get_topic_lists(5)  # get top 5 words for each topic\n",
    "topic_word_distributions = ctm.get_topic_word_matrix()\n",
    "vis_data = gensimvis.prepare(topic_word_distributions, data_lemmatized, ctm.vectorizer)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31efe2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
